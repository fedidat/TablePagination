{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e236f174",
   "metadata": {},
   "source": [
    "# Strategy Planning for Pagination\n",
    "\n",
    "This notebook determines the pagination strategy for each table and outputs a plan for the next step (fetching pages).\n",
    "\n",
    "## Strategies Implemented:\n",
    "1. **Full Table** - Fetch entire table in one query\n",
    "2. **Row by Row** - Fetch all keys, then fetch each row individually\n",
    "3. **Attribute-based** - Ask LLM which column to partition by, then fetch pages by distinct values\n",
    "4. **Classic Pagination** - Offset-based pagination with configurable page size\n",
    "5. **Range-based** - Generate alphabetic (by starting letter), semantic (by categories), and unrestricted (original LLM choice) pagination plans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165da3fd",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adad6ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output base: /Users/bef/Desktop/TablePagination/processing/1_strategy\n",
      "Data directory: /Users/bef/Desktop/TablePagination/processing/0_data/20251004_213355\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import openai\n",
    "\n",
    "# ===== CONFIGURATION =====\n",
    "# MAX_TABLES: Set to a number to process only that many tables (for testing/sampling)\n",
    "# Set to None to process all tables\n",
    "MAX_TABLES = None  # e.g., 1 for single table test, 3 for sampling first 3 tables, None for all\n",
    "\n",
    "# PARALLEL_STRATEGIES: Set to True to run strategies in parallel (faster)\n",
    "PARALLEL_STRATEGIES = True\n",
    "MAX_WORKERS = 5  # Number of parallel strategy workers (set to number of strategies)\n",
    "\n",
    "# Paths\n",
    "ROOT = Path('.')\n",
    "PROCESSING_ROOT = ROOT / 'processing'\n",
    "DATA_DIR = PROCESSING_ROOT / '0_data'\n",
    "OUTPUT_ROOT = PROCESSING_ROOT / '1_strategy'\n",
    "\n",
    "# Find the most recent data directory\n",
    "data_subdirs = sorted([d for d in DATA_DIR.iterdir() if d.is_dir()], reverse=True)\n",
    "if not data_subdirs:\n",
    "    raise FileNotFoundError(f\"No data found in {DATA_DIR}\")\n",
    "\n",
    "LATEST_DATA_DIR = data_subdirs[0]\n",
    "\n",
    "print('Output base:', OUTPUT_ROOT.resolve())\n",
    "print('Data directory:', LATEST_DATA_DIR.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efd02f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ API key loaded from api_key.txt\n",
      "Using model: openai/gpt-5-mini\n"
     ]
    }
   ],
   "source": [
    "# Configure OpenRouter\n",
    "# Read API key from file\n",
    "api_key_file = ROOT / 'api_key.txt'\n",
    "if not api_key_file.exists():\n",
    "    raise ValueError('No API key found. Please create api_key.txt or set OPENROUTER_API_KEY environment variable')\n",
    "with open(api_key_file, 'r') as f:\n",
    "    OPENROUTER_API_KEY = f.read().strip()\n",
    "print('âœ“ API key loaded from api_key.txt')\n",
    "\n",
    "# Create OpenAI client configured for OpenRouter\n",
    "client = openai.OpenAI(\n",
    "    api_key=OPENROUTER_API_KEY,\n",
    "    base_url=\"https://openrouter.ai/api/v1\"\n",
    ")\n",
    "\n",
    "# Model to use for LLM queries\n",
    "MODEL = 'openai/gpt-5-mini'  # OpenRouter format: provider/model\n",
    "print(f'Using model: {MODEL}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3818b2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 48 tables\n",
      "Sample table ID: 10_men_butterfly_100m_2009\n"
     ]
    }
   ],
   "source": [
    "# Load all table data from step 0\n",
    "def load_all_tables(data_dir: Path) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Load all JSON files from the data directory.\"\"\"\n",
    "    tables = []\n",
    "    for json_file in sorted(data_dir.glob('*.json')):\n",
    "        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            # Add file info\n",
    "            data['file_path'] = str(json_file)\n",
    "            data['table_id'] = json_file.stem  # e.g., \"0_republican_straw_polls_2012\"\n",
    "            tables.append(data)\n",
    "    return tables\n",
    "\n",
    "tables = load_all_tables(LATEST_DATA_DIR)\n",
    "print(f'Loaded {len(tables)} tables')\n",
    "print(f'Sample table ID: {tables[0][\"table_id\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d753aa21",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "654fb79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(prompt: str, response_format: str = \"text\") -> str:\n",
    "    \"\"\"Make a simple LLM call and return the response.\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"LLM call failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def normalize_field(s: str) -> str:\n",
    "    \"\"\"Normalize field names (from ChatGPT35_RowByRow_FirstExample).\"\"\"\n",
    "    import re\n",
    "    s = s.lower().replace(\" \", \"_\").replace(\"-\", \"_\").replace(\".\", \"\").replace(\",\", \"_\")\\\n",
    "            .replace(\"(\", \"\").replace(\")\", \"\").replace(\":\", \"\").replace('\"', '').replace(\"'\", \"\")\\\n",
    "            .replace(\"/\", \"\")\n",
    "    return re.sub('_+', '_', s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71b154f",
   "metadata": {},
   "source": [
    "## Strategy 1: Full Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d7b515f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_full_table(table_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Strategy: Fetch the entire table in one query.\n",
    "    No LLM calls needed.\n",
    "    \"\"\"\n",
    "    meta = table_data['meta']\n",
    "    \n",
    "    return {\n",
    "        \"table_id\": table_data['table_id'],\n",
    "        \"table_name\": meta.get('name', ''),\n",
    "        \"strategy\": \"full_table\",\n",
    "        \"metadata\": {\n",
    "            \"table_title\": meta.get('table_title', ''),\n",
    "            \"columns\": meta.get('columns', []),\n",
    "            \"key_columns\": meta.get('keys', [])\n",
    "        },\n",
    "        \"pagination_config\": {}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce03667",
   "metadata": {},
   "source": [
    "## Strategy 2: Row by Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebab05fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_row_by_row(table_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Strategy: Fetch all key values first, then fetch each row individually.\n",
    "    Makes 1 LLM call to get all key combinations.\n",
    "    \"\"\"\n",
    "    meta = table_data['meta']\n",
    "    table_title = meta.get('table_title', '')\n",
    "    keys = meta.get('keys', [])\n",
    "    \n",
    "    if not keys:\n",
    "        print(f\"Warning: No keys defined for {table_data['table_id']}\")\n",
    "        return None\n",
    "    \n",
    "    # Normalize key names\n",
    "    norm_keys = [normalize_field(k) for k in keys]\n",
    "    \n",
    "    # Build prompt to fetch all keys (inspired by ChatGPT35_RowByRow_FirstExample)\n",
    "    key_columns_desc = f\"The key column{'s' if len(keys) > 1 else ''} in the table {'are' if len(keys) > 1 else 'is'} {', '.join(keys)}\"\n",
    "    \n",
    "    keys_json_format = ', '.join([f'\"{nk}\": \"{nk}\"' for nk in norm_keys])\n",
    "    \n",
    "    keys_prompt = f\"\"\"You are a retriever of facts.\n",
    "We want to create a table with the detailed information about {table_title}.\n",
    "{key_columns_desc}.\n",
    "List all {', '.join(keys)} entities for the table.\n",
    "The response will be formatted as JSON list shown below.\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "[{{\n",
    "    {keys_json_format}\n",
    "}}]\"\"\"\n",
    "    \n",
    "    print(f\"Fetching keys for {table_data['table_id']}...\")\n",
    "    response = call_llm(keys_prompt)\n",
    "    \n",
    "    if not response:\n",
    "        print(f\"Failed to fetch keys for {table_data['table_id']}\")\n",
    "        return None\n",
    "    \n",
    "    # Parse the response to extract key values\n",
    "    try:\n",
    "        # Clean up response to extract JSON\n",
    "        if not response.startswith(\"[\") and \"[\" in response:\n",
    "            response = response[response.find(\"[\"):]\n",
    "        if not response.endswith(\"]\") and \"]\" in response:\n",
    "            response = response[:response.rfind(\"]\") + 1]\n",
    "        \n",
    "        key_values = json.loads(response)\n",
    "        \n",
    "        if not isinstance(key_values, list):\n",
    "            print(f\"Invalid response format for {table_data['table_id']}\")\n",
    "            return None\n",
    "            \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Failed to parse keys response for {table_data['table_id']}: {e}\")\n",
    "        return None\n",
    "    \n",
    "    return {\n",
    "        \"table_id\": table_data['table_id'],\n",
    "        \"table_name\": meta.get('name', ''),\n",
    "        \"strategy\": \"row_by_row\",\n",
    "        \"metadata\": {\n",
    "            \"table_title\": table_title,\n",
    "            \"columns\": meta.get('columns', []),\n",
    "            \"key_columns\": keys\n",
    "        },\n",
    "        \"pagination_config\": {\n",
    "            \"key_columns\": keys,\n",
    "            \"key_values\": key_values,\n",
    "            \"total_rows\": len(key_values)\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698c51e8",
   "metadata": {},
   "source": [
    "## Strategy 3: Attribute-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58a7b854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_attribute_based(table_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Strategy: Ask LLM which column to partition by, then get distinct values.\n",
    "    Makes 2 LLM calls:\n",
    "    1. Ask which column to use for partitioning\n",
    "    2. Get all distinct values for that column\n",
    "    \"\"\"\n",
    "    meta = table_data['meta']\n",
    "    table_title = meta.get('table_title', '')\n",
    "    columns = meta.get('columns', [])\n",
    "    \n",
    "    if not columns:\n",
    "        print(f\"Warning: No columns defined for {table_data['table_id']}\")\n",
    "        return None\n",
    "    \n",
    "    # Call 1: Ask which column to partition by\n",
    "    partition_prompt = f\"\"\"You are helping to paginate a table about {table_title}.\n",
    "The table has the following columns: {', '.join(columns)}.\n",
    "\n",
    "Which single column would be best to use for partitioning/grouping this table's data?\n",
    "Choose a column that would create meaningful, balanced groups.\n",
    "\n",
    "Respond with ONLY the column name, nothing else.\"\"\"\n",
    "    \n",
    "    print(f\"Asking LLM for partition column for {table_data['table_id']}...\")\n",
    "    partition_column = call_llm(partition_prompt)\n",
    "    \n",
    "    if not partition_column or partition_column not in columns:\n",
    "        print(f\"Invalid partition column '{partition_column}' for {table_data['table_id']}\")\n",
    "        return None\n",
    "    \n",
    "    # Call 2: Get all distinct values for that column\n",
    "    values_prompt = f\"\"\"You are a retriever of facts.\n",
    "We want to paginate a table about {table_title}.\n",
    "List all distinct values of the column \"{partition_column}\" in this table.\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "[\"{partition_column}_value1\", \"{partition_column}_value2\", ...]\"\"\"\n",
    "    \n",
    "    print(f\"Fetching distinct values for column '{partition_column}'...\")\n",
    "    response = call_llm(values_prompt)\n",
    "    \n",
    "    if not response:\n",
    "        print(f\"Failed to fetch values for {table_data['table_id']}\")\n",
    "        return None\n",
    "    \n",
    "    # Parse the response\n",
    "    try:\n",
    "        if not response.startswith(\"[\") and \"[\" in response:\n",
    "            response = response[response.find(\"[\"):]\n",
    "        if not response.endswith(\"]\") and \"]\" in response:\n",
    "            response = response[:response.rfind(\"]\") + 1]\n",
    "        \n",
    "        partition_values = json.loads(response)\n",
    "        \n",
    "        if not isinstance(partition_values, list):\n",
    "            print(f\"Invalid response format for {table_data['table_id']}\")\n",
    "            return None\n",
    "            \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Failed to parse values response for {table_data['table_id']}: {e}\")\n",
    "        return None\n",
    "    \n",
    "    return {\n",
    "        \"table_id\": table_data['table_id'],\n",
    "        \"table_name\": meta.get('name', ''),\n",
    "        \"strategy\": \"attribute_based\",\n",
    "        \"metadata\": {\n",
    "            \"table_title\": table_title,\n",
    "            \"columns\": columns,\n",
    "            \"key_columns\": meta.get('keys', [])\n",
    "        },\n",
    "        \"pagination_config\": {\n",
    "            \"partition_column\": partition_column,\n",
    "            \"partition_values\": partition_values,\n",
    "            \"total_partitions\": len(partition_values)\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53949aef",
   "metadata": {},
   "source": [
    "## Strategy 4: Classic Pagination (Offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f3b8534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_classic_pagination(table_data: Dict[str, Any], page_size: int = 10) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Strategy: Classic offset-based pagination.\n",
    "    No LLM calls - just configuration.\n",
    "    The fetch notebook will iteratively fetch pages.\n",
    "    \"\"\"\n",
    "    meta = table_data['meta']\n",
    "    keys = meta.get('keys', [])\n",
    "    \n",
    "    if not keys:\n",
    "        print(f\"Warning: No keys defined for {table_data['table_id']}\")\n",
    "        return None\n",
    "    \n",
    "    # Default sort order: ascending by key columns\n",
    "    sort_order = [f\"{key} ASC\" for key in keys]\n",
    "    \n",
    "    return {\n",
    "        \"table_id\": table_data['table_id'],\n",
    "        \"table_name\": meta.get('name', ''),\n",
    "        \"strategy\": \"classic_pagination\",\n",
    "        \"metadata\": {\n",
    "            \"table_title\": meta.get('table_title', ''),\n",
    "            \"columns\": meta.get('columns', []),\n",
    "            \"key_columns\": keys\n",
    "        },\n",
    "        \"pagination_config\": {\n",
    "            \"page_size\": page_size,\n",
    "            \"primary_keys\": keys,\n",
    "            \"sort_order\": sort_order\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b58976",
   "metadata": {},
   "source": [
    "## Strategy 5: Range-based Pagination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "035156f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_range_based(table_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Strategy: Generate alphabetic, semantic, and unrestricted range-based pagination plans.\n",
    "    Makes up to 6 LLM calls: 2 for alphabetic, 2 for semantic, 2 for unrestricted.\n",
    "    Returns all three configs or None if any fails.\n",
    "    \"\"\"\n",
    "    meta = table_data['meta']\n",
    "    table_title = meta.get('table_title', '')\n",
    "    columns = meta.get('columns', [])\n",
    "    \n",
    "    if not columns:\n",
    "        print(f\"Warning: No columns defined for {table_data['table_id']}\")\n",
    "        return None\n",
    "    \n",
    "    configs = {}\n",
    "    \n",
    "    # 1. Alphabetic strategy\n",
    "    alphabetic_prompt = f\"\"\"You are helping to paginate a table about {table_title}.\n",
    "The table has the following columns: {', '.join(columns)}.\n",
    "\n",
    "Suggest a column that contains text data (like names, titles, or categories) that can be alphabetized.\n",
    "Then suggest bucketing by starting letter (e.g., A-F, G-M, etc.).\n",
    "\n",
    "Respond in the format: \"<column_name>, <bucketing_description>\"\n",
    "Example: \"Title, by starting letter ranges A-F, G-M, N-S, T-Z\"\n",
    "\"\"\"\n",
    "    \n",
    "    print(f\"Asking LLM for alphabetic strategy for {table_data['table_id']}...\")\n",
    "    alphabetic_response = call_llm(alphabetic_prompt)\n",
    "    \n",
    "    if alphabetic_response:\n",
    "        parts = alphabetic_response.split(',', 1)\n",
    "        if len(parts) == 2:\n",
    "            partition_column = parts[0].strip().strip('\"').strip(\"'\")\n",
    "            bucketing_criteria = parts[1].strip().strip('\"').strip(\"'\")\n",
    "            \n",
    "            # Get ranges for alphabetic\n",
    "            ranges_prompt = f\"\"\"You are a retriever of facts.\n",
    "For a table about {table_title}, we want to paginate by {partition_column} using {bucketing_criteria}.\n",
    "\n",
    "List all the alphabetic ranges needed. For each range, provide the lower bound (inclusive) and upper bound (exclusive).\n",
    "\n",
    "RESPONSE FORMAT (JSON array of objects):\n",
    "[\n",
    "    {{\"gte\": \"A\", \"lt\": \"G\"}},\n",
    "    {{\"gte\": \"G\", \"lt\": \"M\"}}\n",
    "]\n",
    "\n",
    "Example for starting letters:\n",
    "[\n",
    "    {{\"gte\": \"A\", \"lt\": \"F\"}},\n",
    "    {{\"gte\": \"F\", \"lt\": \"K\"}}\n",
    "]\n",
    "\"\"\"\n",
    "            \n",
    "            print(f\"Fetching alphabetic ranges for {partition_column}...\")\n",
    "            ranges_response = call_llm(ranges_prompt)\n",
    "            \n",
    "            if ranges_response:\n",
    "                try:\n",
    "                    if not ranges_response.startswith(\"[\") and \"[\" in ranges_response:\n",
    "                        ranges_response = ranges_response[ranges_response.find(\"[\"):]\n",
    "                    if not ranges_response.endswith(\"]\") and \"]\" in ranges_response:\n",
    "                        ranges_response = ranges_response[:ranges_response.rfind(\"]\") + 1]\n",
    "                    \n",
    "                    ranges = json.loads(ranges_response)\n",
    "                    \n",
    "                    if isinstance(ranges, list):\n",
    "                        configs['alphabetic'] = {\n",
    "                            \"partition_column\": partition_column,\n",
    "                            \"bucketing_criteria\": bucketing_criteria,\n",
    "                            \"ranges\": ranges,\n",
    "                            \"total_ranges\": len(ranges)\n",
    "                        }\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Failed to parse alphabetic ranges for {table_data['table_id']}: {e}\")\n",
    "    \n",
    "    # 2. Semantic strategy\n",
    "    semantic_prompt = f\"\"\"You are helping to paginate a table about {table_title}.\n",
    "The table has the following columns: {', '.join(columns)}.\n",
    "\n",
    "Choose a column that contains truly categorical data that can be divided into meaningful semantic groups.\n",
    "ABSOLUTELY DO NOT choose any date, time, year, or temporal columns.\n",
    "ABSOLUTELY DO NOT choose numeric columns like ranks, scores, counts, or measurements.\n",
    "Choose columns like: countries, regions, types, categories, names of things, or qualitative attributes.\n",
    "\n",
    "Then suggest bucketing by meaningful semantic categories (like continents for countries, or product types for items).\n",
    "\n",
    "Respond in the format: \"<column_name>, <bucketing_description>\"\n",
    "Example: \"Country, by continent (Asia, Europe, Americas, Africa, Oceania)\"\n",
    "Example: \"Type, by category (food, clothing, electronics, books)\"\n",
    "Example: \"Genre, by type (fiction, non-fiction, biography, poetry)\"\n",
    "\"\"\"\n",
    "    \n",
    "    print(f\"Asking LLM for semantic strategy for {table_data['table_id']}...\")\n",
    "    semantic_response = call_llm(semantic_prompt)\n",
    "    \n",
    "    if semantic_response:\n",
    "        parts = semantic_response.split(',', 1)\n",
    "        if len(parts) == 2:\n",
    "            partition_column = parts[0].strip().strip('\"').strip(\"'\")\n",
    "            bucketing_criteria = parts[1].strip().strip('\"').strip(\"'\")\n",
    "            \n",
    "            # Stronger validation - reject any temporal or numeric columns, and unique identifier columns\n",
    "            forbidden_keywords = ['year', 'date', 'time', 'rank', 'score', 'points', 'count', 'number', 'id', 'age', 'population', 'gdp', 'earnings', 'price', 'cost', 'salary', 'wage']\n",
    "            identifier_keywords = ['name', 'title', 'id', 'code', 'key', 'identifier']\n",
    "            if any(keyword in partition_column.lower() for keyword in forbidden_keywords):\n",
    "                print(f\"Rejected forbidden column '{partition_column}' for semantic\")\n",
    "            elif any(keyword in partition_column.lower() for keyword in identifier_keywords):\n",
    "                print(f\"Rejected identifier column '{partition_column}' for semantic\")\n",
    "            elif 'decade' in bucketing_criteria.lower() or 'year' in bucketing_criteria.lower() or 'date' in bucketing_criteria.lower():\n",
    "                print(f\"Rejected temporal bucketing '{bucketing_criteria}' for semantic\")\n",
    "            else:\n",
    "                # Get ranges for semantic (actually categories)\n",
    "                ranges_prompt = f\"\"\"You are a retriever of facts.\n",
    "For a table about {table_title}, we want to paginate by {partition_column} using {bucketing_criteria}.\n",
    "\n",
    "List all the semantic categories needed. These should be meaningful qualitative groups, NOT dates, numbers, or column names.\n",
    "\n",
    "RESPONSE FORMAT (JSON array of strings):\n",
    "[\"category1\", \"category2\", \"category3\"]\n",
    "\n",
    "Example for \"Country, by continent\":\n",
    "[\"Asia\", \"Europe\", \"North America\", \"South America\", \"Africa\", \"Oceania\"]\n",
    "\n",
    "Example for \"Type, by category\":\n",
    "[\"Food\", \"Clothing\", \"Electronics\", \"Books\", \"Home Goods\"]\n",
    "\"\"\"\n",
    "                \n",
    "                print(f\"Fetching semantic categories for {partition_column}...\")\n",
    "                ranges_response = call_llm(ranges_prompt)\n",
    "                \n",
    "                if ranges_response:\n",
    "                    try:\n",
    "                        if not ranges_response.startswith(\"[\") and \"[\" in ranges_response:\n",
    "                            ranges_response = ranges_response[ranges_response.find(\"[\"):]\n",
    "                        if not ranges_response.endswith(\"]\") and \"]\" in ranges_response:\n",
    "                            ranges_response = ranges_response[:ranges_response.rfind(\"]\") + 1]\n",
    "                        \n",
    "                        categories = json.loads(ranges_response)\n",
    "                        \n",
    "                        if isinstance(categories, list) and len(categories) > 0:\n",
    "                            # Validate that categories are not column names or temporal\n",
    "                            column_names = [col.lower() for col in columns]\n",
    "                            temporal_indicators = ['decade', 'year', 'century', 'period', 'era', 'age']\n",
    "                            \n",
    "                            valid_categories = True\n",
    "                            for cat in categories:\n",
    "                                cat_lower = cat.lower()\n",
    "                                if cat_lower in column_names:\n",
    "                                    valid_categories = False\n",
    "                                    break\n",
    "                                if any(indicator in cat_lower for indicator in temporal_indicators):\n",
    "                                    valid_categories = False\n",
    "                                    break\n",
    "                            \n",
    "                            if valid_categories:\n",
    "                                # Convert categories to range-like format for consistency\n",
    "                                ranges = [{\"category\": cat} for cat in categories]\n",
    "                                configs['semantic'] = {\n",
    "                                    \"partition_column\": partition_column,\n",
    "                                    \"bucketing_criteria\": bucketing_criteria,\n",
    "                                    \"ranges\": ranges,\n",
    "                                    \"total_ranges\": len(ranges)\n",
    "                                }\n",
    "                            else:\n",
    "                                print(f\"Categories contain invalid content: {categories}\")\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"Failed to parse semantic categories for {table_data['table_id']}: {e}\")\n",
    "    \n",
    "    # 3. Unrestricted strategy (original logic from 1_Strategy.ipynb)\n",
    "    unrestricted_prompt = f\"\"\"You are helping to paginate a table about {table_title}.\n",
    "The table has the following columns: {', '.join(columns)}.\n",
    "\n",
    "Suggest the best column to use for range-based pagination and describe how to bucket the data.\n",
    "For example: \"year, by decade\" or \"price, by $100 ranges\" or \"date, by month\".\n",
    "\n",
    "Respond in the format: \"<column_name>, <bucketing_description>\"\n",
    "Example: \"year, by decade\"\n",
    "\"\"\"\n",
    "    \n",
    "    print(f\"Asking LLM for unrestricted range strategy for {table_data['table_id']}...\")\n",
    "    unrestricted_response = call_llm(unrestricted_prompt)\n",
    "    \n",
    "    if unrestricted_response:\n",
    "        parts = unrestricted_response.split(',', 1)\n",
    "        if len(parts) == 2:\n",
    "            partition_column = parts[0].strip().strip('\"').strip(\"'\")\n",
    "            bucketing_criteria = parts[1].strip().strip('\"').strip(\"'\")\n",
    "            \n",
    "            # Get ranges for unrestricted (same as original)\n",
    "            ranges_prompt = f\"\"\"You are a retriever of facts.\n",
    "For a table about {table_title}, we want to paginate by {partition_column} using {bucketing_criteria}.\n",
    "\n",
    "List all the ranges needed. For each range, provide the lower bound (inclusive) and upper bound (exclusive).\n",
    "\n",
    "RESPONSE FORMAT (JSON array of objects):\n",
    "[\n",
    "    {{\"gte\": \"lower_value\", \"lt\": \"upper_value\"}},\n",
    "    {{\"gte\": \"lower_value\", \"lt\": \"upper_value\"}}\n",
    "]\n",
    "\n",
    "Example for \"year by decade\":\n",
    "[\n",
    "    {{\"gte\": \"1980\", \"lt\": \"1990\"}},\n",
    "    {{\"gte\": \"1990\", \"lt\": \"2000\"}}\n",
    "]\n",
    "\"\"\"\n",
    "            \n",
    "            print(f\"Fetching unrestricted ranges for {partition_column} {bucketing_criteria}...\")\n",
    "            ranges_response = call_llm(ranges_prompt)\n",
    "            \n",
    "            if ranges_response:\n",
    "                try:\n",
    "                    if not ranges_response.startswith(\"[\") and \"[\" in ranges_response:\n",
    "                        ranges_response = ranges_response[ranges_response.find(\"[\"):]\n",
    "                    if not ranges_response.endswith(\"]\") and \"]\" in ranges_response:\n",
    "                        ranges_response = ranges_response[:ranges_response.rfind(\"]\") + 1]\n",
    "                    \n",
    "                    ranges = json.loads(ranges_response)\n",
    "                    \n",
    "                    if isinstance(ranges, list):\n",
    "                        configs['unrestricted'] = {\n",
    "                            \"partition_column\": partition_column,\n",
    "                            \"bucketing_criteria\": bucketing_criteria,\n",
    "                            \"ranges\": ranges,\n",
    "                            \"total_ranges\": len(ranges)\n",
    "                        }\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Failed to parse unrestricted ranges for {table_data['table_id']}: {e}\")\n",
    "    \n",
    "    # Only return if we have all three configs\n",
    "    if len(configs) == 3:\n",
    "        return {\n",
    "            \"table_id\": table_data['table_id'],\n",
    "            \"table_name\": meta.get('name', ''),\n",
    "            \"strategy\": \"range_based\",\n",
    "            \"metadata\": {\n",
    "                \"table_title\": table_title,\n",
    "                \"columns\": columns,\n",
    "                \"key_columns\": meta.get('keys', [])\n",
    "            },\n",
    "            \"pagination_config_alphabetic\": configs['alphabetic'],\n",
    "            \"pagination_config_semantic\": configs['semantic'],\n",
    "            \"pagination_config_unrestricted\": configs['unrestricted']\n",
    "        }\n",
    "    else:\n",
    "        print(f\"Could not generate all three configs for {table_data['table_id']} (got {len(configs)})\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfeb1de0",
   "metadata": {},
   "source": [
    "## Main Execution: Generate Plans for All Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d48ebb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active strategies: ['range_based']\n",
      "Processing 48 table(s) out of 48 total...\n"
     ]
    }
   ],
   "source": [
    "# Configuration: which strategies to run\n",
    "STRATEGIES_TO_RUN = {\n",
    "    'full_table': plan_full_table,\n",
    "    'row_by_row': plan_row_by_row,\n",
    "    'attribute_based': plan_attribute_based,\n",
    "    'classic_pagination': plan_classic_pagination,\n",
    "    'range_based': plan_range_based\n",
    "}\n",
    "\n",
    "# Choose which strategies to execute (comment out ones you don't want)\n",
    "ACTIVE_STRATEGIES = [\n",
    "    # 'full_table',\n",
    "    # 'row_by_row',\n",
    "    # 'attribute_based',\n",
    "    # 'classic_pagination',\n",
    "    'range_based',\n",
    "]\n",
    "\n",
    "# Apply MAX_TABLES limit if set\n",
    "if MAX_TABLES is not None:\n",
    "    print(f\"ðŸ“Š LIMITED RUN: Processing first {MAX_TABLES} table(s)\")\n",
    "    tables_to_process = tables[:MAX_TABLES]\n",
    "else:\n",
    "    tables_to_process = tables\n",
    "\n",
    "print(f\"Active strategies: {ACTIVE_STRATEGIES}\")\n",
    "print(f\"Processing {len(tables_to_process)} table(s) out of {len(tables)} total...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9e40a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: processing/1_strategy/20251015_230052\n",
      "\n",
      "âš¡ Running 1 strategies in PARALLEL with 5 workers\n",
      "\n",
      "============================================================\n",
      "Running strategy: RANGE_BASED\n",
      "============================================================\n",
      "\n",
      "[range_based] [1/48] Processing 10_men_butterfly_100m_2009...\n",
      "Asking LLM for alphabetic strategy for 10_men_butterfly_100m_2009...\n",
      "Fetching alphabetic ranges for Name...\n",
      "Asking LLM for semantic strategy for 10_men_butterfly_100m_2009...\n",
      "Fetching semantic categories for Nationality...\n",
      "Asking LLM for unrestricted range strategy for 10_men_butterfly_100m_2009...\n",
      "Fetching unrestricted ranges for Time by 0.5-second ranges (e.g., 50.00â€“50.49, 50.50â€“50.99, 51.00â€“51.49, etc.)...\n",
      "Failed to parse unrestricted ranges for 10_men_butterfly_100m_2009: Expecting value: line 1 column 1 (char 0)\n",
      "Could not generate all three configs for 10_men_butterfly_100m_2009 (got 2)\n",
      "[range_based]   âš  Attempt 1/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 10_men_butterfly_100m_2009...\n",
      "Fetching alphabetic ranges for Name...\n",
      "Asking LLM for semantic strategy for 10_men_butterfly_100m_2009...\n",
      "Fetching semantic categories for Nationality...\n",
      "Asking LLM for unrestricted range strategy for 10_men_butterfly_100m_2009...\n",
      "Fetching unrestricted ranges for Time by 0.5-second ranges (e.g., 49.00â€“49.49, 49.50â€“49.99, 50.00â€“50.49, 50.50â€“50.99, ...)...\n",
      "[range_based]   âœ“ Success (after 2 attempts) - Saved to 10_men_butterfly_100m_2009.json\n",
      "[range_based] [2/48] Processing 11_playstation_3_cooperative_games...\n",
      "Asking LLM for alphabetic strategy for 11_playstation_3_cooperative_games...\n",
      "Fetching alphabetic ranges for Title...\n",
      "Asking LLM for semantic strategy for 11_playstation_3_cooperative_games...\n",
      "Fetching semantic categories for Co-op modes...\n",
      "Asking LLM for unrestricted range strategy for 11_playstation_3_cooperative_games...\n",
      "Fetching unrestricted ranges for Release Date by year (bucket games into calendar-year buckets; if the span is large, group years into decades)...\n",
      "[range_based]   âœ“ Success - Saved to 11_playstation_3_cooperative_games.json\n",
      "[range_based] [3/48] Processing 12_rock_band_downloadable_2011...\n",
      "Asking LLM for alphabetic strategy for 12_rock_band_downloadable_2011...\n",
      "Fetching alphabetic ranges for Artist...\n",
      "Asking LLM for semantic strategy for 12_rock_band_downloadable_2011...\n",
      "Fetching semantic categories for Genre...\n",
      "Asking LLM for unrestricted range strategy for 12_rock_band_downloadable_2011...\n",
      "Fetching unrestricted ranges for Release date by month (group songs into monthly buckets â€” Jan 2011, Feb 2011, â€¦ â€” sorted newestâ†’oldest; optionally switch to weekly buckets for very large monthly volumes)...\n",
      "[range_based]   âœ“ Success - Saved to 12_rock_band_downloadable_2011.json\n",
      "[range_based] [4/48] Processing 13_figure_skating_ladies_2009_2010...\n",
      "Asking LLM for alphabetic strategy for 13_figure_skating_ladies_2009_2010...\n",
      "Fetching alphabetic ranges for Name...\n",
      "Asking LLM for semantic strategy for 13_figure_skating_ladies_2009_2010...\n",
      "Rejected forbidden column 'Country' for semantic\n",
      "Asking LLM for unrestricted range strategy for 13_figure_skating_ladies_2009_2010...\n",
      "Fetching unrestricted ranges for Rank by groups of 10 (1â€“10, 11â€“20, 21â€“30, etc.)...\n",
      "Could not generate all three configs for 13_figure_skating_ladies_2009_2010 (got 2)\n",
      "[range_based]   âš  Attempt 1/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 13_figure_skating_ladies_2009_2010...\n",
      "Fetching alphabetic ranges for Name...\n",
      "Asking LLM for semantic strategy for 13_figure_skating_ladies_2009_2010...\n",
      "Fetching semantic categories for Event...\n",
      "Asking LLM for unrestricted range strategy for 13_figure_skating_ladies_2009_2010...\n",
      "Fetching unrestricted ranges for Points by 5-point ranges (e.g., 120â€“124, 125â€“129, 130â€“134, â€¦; lower bound inclusive)...\n",
      "[range_based]   âœ“ Success (after 2 attempts) - Saved to 13_figure_skating_ladies_2009_2010.json\n",
      "[range_based] [5/48] Processing 14_minor_planets_discovered_by_nikolai_chernykh...\n",
      "Asking LLM for alphabetic strategy for 14_minor_planets_discovered_by_nikolai_chernykh...\n",
      "Fetching alphabetic ranges for Name...\n",
      "Asking LLM for semantic strategy for 14_minor_planets_discovered_by_nikolai_chernykh...\n",
      "Rejected identifier column 'Name' for semantic\n",
      "Asking LLM for unrestricted range strategy for 14_minor_planets_discovered_by_nikolai_chernykh...\n",
      "Fetching unrestricted ranges for Discovery Date by year (bucket records into calendar years; optionally group those year-buckets into decades for coarser pagination)...\n",
      "Failed to parse unrestricted ranges for 14_minor_planets_discovered_by_nikolai_chernykh: Expecting value: line 1 column 1 (char 0)\n",
      "Could not generate all three configs for 14_minor_planets_discovered_by_nikolai_chernykh (got 1)\n",
      "[range_based]   âš  Attempt 1/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 14_minor_planets_discovered_by_nikolai_chernykh...\n",
      "Fetching alphabetic ranges for Name...\n",
      "Asking LLM for semantic strategy for 14_minor_planets_discovered_by_nikolai_chernykh...\n",
      "Rejected identifier column 'Name' for semantic\n",
      "Asking LLM for unrestricted range strategy for 14_minor_planets_discovered_by_nikolai_chernykh...\n",
      "Fetching unrestricted ranges for Discovery Date by decade (e.g., 1950s, 1960s â€” with optional drill-down to individual years)...\n",
      "Could not generate all three configs for 14_minor_planets_discovered_by_nikolai_chernykh (got 2)\n",
      "[range_based]   âš  Attempt 2/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 14_minor_planets_discovered_by_nikolai_chernykh...\n",
      "Fetching alphabetic ranges for Name...\n",
      "Asking LLM for semantic strategy for 14_minor_planets_discovered_by_nikolai_chernykh...\n",
      "Rejected identifier column 'Name' for semantic\n",
      "Asking LLM for unrestricted range strategy for 14_minor_planets_discovered_by_nikolai_chernykh...\n",
      "Fetching unrestricted ranges for Discovery Date by decade...\n",
      "Could not generate all three configs for 14_minor_planets_discovered_by_nikolai_chernykh (got 2)\n",
      "[range_based]   âœ— Failed after 3 attempts: Function returned None\n",
      "[range_based] [6/48] Processing 16_curling_teams_women_2013_2014...\n",
      "Asking LLM for alphabetic strategy for 16_curling_teams_women_2013_2014...\n",
      "Fetching alphabetic ranges for Skip...\n",
      "Asking LLM for semantic strategy for 16_curling_teams_women_2013_2014...\n",
      "Fetching semantic categories for Locale...\n",
      "Asking LLM for unrestricted range strategy for 16_curling_teams_women_2013_2014...\n",
      "Fetching unrestricted ranges for Skip by the skip's surname initial into alphabetical buckets (e.g., Aâ€“F, Gâ€“L, Mâ€“R, Sâ€“Z â€” or finer buckets like Aâ€“C, Dâ€“F, Gâ€“I, Jâ€“L, Mâ€“O, Pâ€“R, Sâ€“U, Vâ€“Z; adjust bucket boundaries to balance row counts)...\n",
      "[range_based]   âœ“ Success - Saved to 16_curling_teams_women_2013_2014.json\n",
      "[range_based] [7/48] Processing 17_scottish_football_transfers_summer_2011...\n",
      "Asking LLM for alphabetic strategy for 17_scottish_football_transfers_summer_2011...\n",
      "Fetching alphabetic ranges for Name...\n",
      "Asking LLM for semantic strategy for 17_scottish_football_transfers_summer_2011...\n",
      "Fetching semantic categories for Moving from...\n",
      "Categories contain invalid content: ['Scotland â€” Premier League (SPL)', 'Scotland â€” First Division (Championship)', 'Scotland â€” Second Division', 'Scotland â€” Third Division & lower / non-league', 'Transfers between Scottish clubs (internal)', 'England â€” Premier League', 'England â€” Championship', 'England â€” League One', 'England â€” League Two', 'England â€” Non-league', 'Republic of Ireland â€” Premier Division', 'Republic of Ireland â€” First Division', 'Northern Ireland â€” Premiership (IFA Premiership)', 'Other Europe â€” country-specific', 'Other Europe â€” grouped (continental)', 'Other â€” Asia', 'Other â€” Africa', 'Other â€” North America & Central America (CONCACAF)', 'Other â€” South America (CONMEBOL)', 'Other â€” Oceania', 'Inbound to Scottish clubs', 'Outbound from Scottish clubs', 'Permanent transfers', 'Loan deals (temporary transfers)', 'Loan returns / recalls', 'Free transfers / released players', 'Undisclosed-fee transfers', 'Trialist / short-term / emergency signings', 'Youth / academy promotions', 'Retirements and contract terminations', 'Manager / coaching / backroom staff appointments']\n",
      "Asking LLM for unrestricted range strategy for 17_scottish_football_transfers_summer_2011...\n",
      "Fetching unrestricted ranges for Name by alphabetical ranges: bucket by initial letter (A, B, C â€¦ Z) or use grouped ranges such as Aâ€“C, Dâ€“F, Gâ€“I, Jâ€“L, Mâ€“O, Pâ€“R, Sâ€“U, Vâ€“Z....\n",
      "Could not generate all three configs for 17_scottish_football_transfers_summer_2011 (got 2)\n",
      "[range_based]   âš  Attempt 1/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 17_scottish_football_transfers_summer_2011...\n",
      "Fetching alphabetic ranges for Name...\n",
      "Asking LLM for semantic strategy for 17_scottish_football_transfers_summer_2011...\n",
      "Fetching semantic categories for Moving to...\n",
      "Categories contain invalid content: ['Scottish Premiership (top tier)', 'Scottish Championship (second tier)', 'Scottish League One (third tier)', 'Scottish League Two (fourth tier)', 'Scottish nonâ€‘league / Junior / Highland (below League Two)', 'English Premier League (top tier)', 'English Football League Championship (second tier)', 'English Football League One (third tier)', 'English Football League Two (fourth tier)', 'English National League / Nonâ€‘League (below League Two)', 'Wales (Cymru Premier and Welsh leagues)', 'Northern Ireland (NIFL Premiership and Irish leagues)', 'European clubs (outside the UK)', 'Nonâ€‘European / Rest of world clubs', 'Returned to parent club (loan end)', 'Loan move (destination specified as temporary)', 'Permanent transfer (destination specified as permanent)', 'Free agent / Released (no club destination)', 'Retired / Left professional football', 'Unknown / Destination not specified']\n",
      "Asking LLM for unrestricted range strategy for 17_scottish_football_transfers_summer_2011...\n",
      "Fetching unrestricted ranges for Name alphabetic by surname initial (bucket by letter ranges such as Aâ€“C, Dâ€“F, Gâ€“I, Jâ€“L, Mâ€“O, Pâ€“R, Sâ€“U, Vâ€“Z)...\n",
      "Could not generate all three configs for 17_scottish_football_transfers_summer_2011 (got 2)\n",
      "[range_based]   âš  Attempt 2/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 17_scottish_football_transfers_summer_2011...\n",
      "Fetching alphabetic ranges for Name...\n",
      "Asking LLM for semantic strategy for 17_scottish_football_transfers_summer_2011...\n",
      "Fetching semantic categories for Moving from...\n",
      "Categories contain invalid content: ['Scottish clubs', 'English clubs', 'Republic of Ireland clubs', 'Northern Irish clubs', 'Welsh clubs', 'Other European clubs', 'Rest of World clubs', 'Free agents / unattached players', 'Youth/internal promotions', 'Undisclosed / unknown origin']\n",
      "Asking LLM for unrestricted range strategy for 17_scottish_football_transfers_summer_2011...\n",
      "Fetching unrestricted ranges for Name by surname initial in alphabetical buckets (e.g., Aâ€“C, Dâ€“F, Gâ€“I, Jâ€“L, Mâ€“O, Pâ€“R, Sâ€“U, Vâ€“Z)...\n",
      "Could not generate all three configs for 17_scottish_football_transfers_summer_2011 (got 2)\n",
      "[range_based]   âœ— Failed after 3 attempts: Function returned None\n",
      "[range_based] [8/48] Processing 19_living_proof_the_farewell_tour...\n",
      "Asking LLM for alphabetic strategy for 19_living_proof_the_farewell_tour...\n",
      "Fetching alphabetic ranges for City...\n",
      "Asking LLM for semantic strategy for 19_living_proof_the_farewell_tour...\n",
      "Rejected forbidden column 'Country' for semantic\n",
      "Asking LLM for unrestricted range strategy for 19_living_proof_the_farewell_tour...\n",
      "Fetching unrestricted ranges for date by month (group shows into calendar-month buckets, e.g., 2025-06 for all concerts in June 2025)...\n",
      "Could not generate all three configs for 19_living_proof_the_farewell_tour (got 2)\n",
      "[range_based]   âš  Attempt 1/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 19_living_proof_the_farewell_tour...\n",
      "Fetching alphabetic ranges for City...\n",
      "Asking LLM for semantic strategy for 19_living_proof_the_farewell_tour...\n",
      "Rejected forbidden column 'Country' for semantic\n",
      "Asking LLM for unrestricted range strategy for 19_living_proof_the_farewell_tour...\n",
      "Fetching unrestricted ranges for date by month...\n",
      "Failed to parse unrestricted ranges for 19_living_proof_the_farewell_tour: Expecting value: line 1 column 1 (char 0)\n",
      "Could not generate all three configs for 19_living_proof_the_farewell_tour (got 1)\n",
      "[range_based]   âš  Attempt 2/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 19_living_proof_the_farewell_tour...\n",
      "Fetching alphabetic ranges for City...\n",
      "Asking LLM for semantic strategy for 19_living_proof_the_farewell_tour...\n",
      "Fetching semantic categories for Venue...\n",
      "Asking LLM for unrestricted range strategy for 19_living_proof_the_farewell_tour...\n",
      "Fetching unrestricted ranges for date by month...\n",
      "[range_based]   âœ“ Success (after 3 attempts) - Saved to 19_living_proof_the_farewell_tour.json\n",
      "[range_based] [9/48] Processing 20_new_zealand_demographics_1921_2011...\n",
      "Asking LLM for alphabetic strategy for 20_new_zealand_demographics_1921_2011...\n",
      "Fetching alphabetic ranges for Source...\n",
      "Asking LLM for semantic strategy for 20_new_zealand_demographics_1921_2011...\n",
      "Fetching semantic categories for Fertility category...\n",
      "Asking LLM for unrestricted range strategy for 20_new_zealand_demographics_1921_2011...\n",
      "Fetching unrestricted ranges for Year by decade (10-year buckets starting 1921â€“1930, 1931â€“1940, 1941â€“1950, â€¦, 2001â€“2010; final bucket for 2011)...\n",
      "[range_based]   âœ“ Success - Saved to 20_new_zealand_demographics_1921_2011.json\n",
      "[range_based] [10/48] Processing 21_liechtenstein_demographics_1901_2011...\n",
      "Asking LLM for alphabetic strategy for 21_liechtenstein_demographics_1901_2011...\n",
      "Fetching alphabetic ranges for Notes...\n",
      "Asking LLM for semantic strategy for 21_liechtenstein_demographics_1901_2011...\n",
      "Fetching semantic categories for Demographic trend...\n",
      "Asking LLM for unrestricted range strategy for 21_liechtenstein_demographics_1901_2011...\n",
      "Fetching unrestricted ranges for year by decade (1901â€“1910, 1911â€“1920, â€¦, 2001â€“2010, 2011)...\n",
      "[range_based]   âœ“ Success - Saved to 21_liechtenstein_demographics_1901_2011.json\n",
      "[range_based] [11/48] Processing 22_usa_demographics_1935_2010...\n",
      "Asking LLM for alphabetic strategy for 22_usa_demographics_1935_2010...\n",
      "Fetching alphabetic ranges for State...\n",
      "Asking LLM for semantic strategy for 22_usa_demographics_1935_2010...\n",
      "Fetching semantic categories for Region...\n",
      "Asking LLM for unrestricted range strategy for 22_usa_demographics_1935_2010...\n",
      "Fetching unrestricted ranges for Year by decade (group rows into decade buckets â€” 1930s (1935â€“1939 partial), 1940s, 1950s, â€¦, 2000s, 2010s (2010 partial))...\n",
      "[range_based]   âœ“ Success - Saved to 22_usa_demographics_1935_2010.json\n",
      "[range_based] [12/48] Processing 23_andorra_demographics_1948_2012...\n",
      "Asking LLM for alphabetic strategy for 23_andorra_demographics_1948_2012...\n",
      "Fetching alphabetic ranges for Notes...\n",
      "Asking LLM for semantic strategy for 23_andorra_demographics_1948_2012...\n",
      "Fetching semantic categories for Natural change category...\n",
      "Asking LLM for unrestricted range strategy for 23_andorra_demographics_1948_2012...\n",
      "Fetching unrestricted ranges for year by decade (group years into decade buckets: 1948â€“1959, 1960â€“1969, 1970â€“1979, 1980â€“1989, 1990â€“1999, 2000â€“2009, 2010â€“2012)...\n",
      "[range_based]   âœ“ Success - Saved to 23_andorra_demographics_1948_2012.json\n",
      "[range_based] [13/48] Processing 25_english_latin_rivalry_1887_2012...\n",
      "Asking LLM for alphabetic strategy for 25_english_latin_rivalry_1887_2012...\n",
      "Fetching alphabetic ranges for Winner...\n",
      "Asking LLM for semantic strategy for 25_english_latin_rivalry_1887_2012...\n",
      "Fetching semantic categories for Winner...\n",
      "Asking LLM for unrestricted range strategy for 25_english_latin_rivalry_1887_2012...\n",
      "Fetching unrestricted ranges for year by decade...\n",
      "[range_based]   âœ“ Success - Saved to 25_english_latin_rivalry_1887_2012.json\n",
      "[range_based] [14/48] Processing 28_equestrian_2012...\n",
      "Asking LLM for alphabetic strategy for 28_equestrian_2012...\n",
      "Fetching alphabetic ranges for Rider...\n",
      "Asking LLM for semantic strategy for 28_equestrian_2012...\n",
      "Fetching semantic categories for Nation...\n",
      "Asking LLM for unrestricted range strategy for 28_equestrian_2012...\n",
      "Fetching unrestricted ranges for Rank by groups of 10 (1â€“10, 11â€“20, 21â€“30, ...)...\n",
      "[range_based]   âœ“ Success - Saved to 28_equestrian_2012.json\n",
      "[range_based] [15/48] Processing 29_tennessee_vanderbilt_rivalry_1900_2012...\n",
      "Asking LLM for alphabetic strategy for 29_tennessee_vanderbilt_rivalry_1900_2012...\n",
      "Fetching alphabetic ranges for Location...\n",
      "Asking LLM for semantic strategy for 29_tennessee_vanderbilt_rivalry_1900_2012...\n",
      "Fetching semantic categories for Location...\n",
      "Asking LLM for unrestricted range strategy for 29_tennessee_vanderbilt_rivalry_1900_2012...\n",
      "Fetching unrestricted ranges for year by decade (1900â€“1909, 1910â€“1919, â€¦, 2000â€“2009, 2010â€“2012)...\n",
      "[range_based]   âœ“ Success - Saved to 29_tennessee_vanderbilt_rivalry_1900_2012.json\n",
      "[range_based] [16/48] Processing 2_belgium_demographics_1900_2011...\n",
      "Asking LLM for alphabetic strategy for 2_belgium_demographics_1900_2011...\n",
      "Fetching alphabetic ranges for Province...\n",
      "Asking LLM for semantic strategy for 2_belgium_demographics_1900_2011...\n",
      "Fetching semantic categories for None (no categorical column present)...\n",
      "Categories contain invalid content: ['Very low', 'Low', 'Moderate (near-replacement)', 'High', 'Very high']\n",
      "Asking LLM for unrestricted range strategy for 2_belgium_demographics_1900_2011...\n",
      "Fetching unrestricted ranges for Year by decade (1900â€“1909, 1910â€“1919, â€¦, 2000â€“2009, 2010â€“2011)...\n",
      "Could not generate all three configs for 2_belgium_demographics_1900_2011 (got 2)\n",
      "[range_based]   âš  Attempt 1/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 2_belgium_demographics_1900_2011...\n",
      "Fetching alphabetic ranges for Province...\n",
      "Asking LLM for semantic strategy for 2_belgium_demographics_1900_2011...\n",
      "Fetching semantic categories for Fertility category...\n",
      "Asking LLM for unrestricted range strategy for 2_belgium_demographics_1900_2011...\n",
      "Fetching unrestricted ranges for Year by decade (group years into 1900â€“1909, 1910â€“1919, â€¦, 2000â€“2009, 2010â€“2011; inclusive ranges, chronological order, final bucket may be shorter)...\n",
      "[range_based]   âœ“ Success (after 2 attempts) - Saved to 2_belgium_demographics_1900_2011.json\n",
      "[range_based] [17/48] Processing 30_classic_100_ten_years_on...\n",
      "Asking LLM for alphabetic strategy for 30_classic_100_ten_years_on...\n",
      "Fetching alphabetic ranges for Composer...\n",
      "Asking LLM for semantic strategy for 30_classic_100_ten_years_on...\n",
      "Fetching semantic categories for Genre...\n",
      "Categories contain invalid content: ['Orchestral', 'Choral/Vocal', 'Opera/Stage', 'Chamber', 'Solo Instrument/Keyboard', 'Film/Media & arrangements', 'Other/Unknown']\n",
      "Asking LLM for unrestricted range strategy for 30_classic_100_ten_years_on...\n",
      "Fetching unrestricted ranges for Rank by groups of 10 (1â€“10, 11â€“20, 21â€“30, â€¦, 91â€“100)...\n",
      "Could not generate all three configs for 30_classic_100_ten_years_on (got 2)\n",
      "[range_based]   âš  Attempt 1/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 30_classic_100_ten_years_on...\n",
      "Fetching alphabetic ranges for Composer...\n",
      "Asking LLM for semantic strategy for 30_classic_100_ten_years_on...\n",
      "Fetching semantic categories for Genre...\n",
      "Categories contain invalid content: ['Orchestral', 'Chamber', 'Vocal/Choral', 'Opera', 'Ballet', 'Solo/Keyboard', 'Film/Media', 'Other/Hybrid']\n",
      "Asking LLM for unrestricted range strategy for 30_classic_100_ten_years_on...\n",
      "Fetching unrestricted ranges for Rank by groups of 10 (1â€“10, 11â€“20, 21â€“30, â€¦, 91â€“100)...\n",
      "Could not generate all three configs for 30_classic_100_ten_years_on (got 2)\n",
      "[range_based]   âš  Attempt 2/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 30_classic_100_ten_years_on...\n",
      "Fetching alphabetic ranges for Composer...\n",
      "Asking LLM for semantic strategy for 30_classic_100_ten_years_on...\n",
      "Fetching semantic categories for Genre...\n",
      "Categories contain invalid content: ['Symphony', 'Concerto', 'Opera', 'Choral/Vocal', 'Chamber', 'Solo Instrumental', 'Orchestral/Programmatic', 'Song/Lieder', 'Other/Arrangements']\n",
      "Asking LLM for unrestricted range strategy for 30_classic_100_ten_years_on...\n",
      "Fetching unrestricted ranges for Rank by groups of 10 (1â€“10, 11â€“20, 21â€“30, â€¦, 91â€“100)...\n",
      "Could not generate all three configs for 30_classic_100_ten_years_on (got 2)\n",
      "[range_based]   âœ— Failed after 3 attempts: Function returned None\n",
      "[range_based] [18/48] Processing 31_udaykumar_films...\n",
      "Asking LLM for alphabetic strategy for 31_udaykumar_films...\n",
      "Fetching alphabetic ranges for Film...\n",
      "Asking LLM for semantic strategy for 31_udaykumar_films...\n",
      "Fetching semantic categories for Director...\n",
      "Asking LLM for unrestricted range strategy for 31_udaykumar_films...\n",
      "Fetching unrestricted ranges for year by decade (bucket films into 1950s: 1950â€“1959, 1960s: 1960â€“1969, 1970s: 1970â€“1979, 1980s: 1980â€“1989)...\n",
      "[range_based]   âœ“ Success - Saved to 31_udaykumar_films.json\n",
      "[range_based] [19/48] Processing 32_fa_cup_qualifying_rounds_1999_2000...\n",
      "Asking LLM for alphabetic strategy for 32_fa_cup_qualifying_rounds_1999_2000...\n",
      "Fetching alphabetic ranges for Home Team...\n",
      "Asking LLM for semantic strategy for 32_fa_cup_qualifying_rounds_1999_2000...\n",
      "Fetching semantic categories for Home Team...\n",
      "Asking LLM for unrestricted range strategy for 32_fa_cup_qualifying_rounds_1999_2000...\n",
      "Fetching unrestricted ranges for Tie by qualifying round (Preliminary, 1st/2nd/3rd/4th Qualifying) and within each round by tie-number ranges (e.g., ties 1â€“25, 26â€“50, 51â€“75, ...)...\n",
      "[range_based]   âœ“ Success - Saved to 32_fa_cup_qualifying_rounds_1999_2000.json\n",
      "[range_based] [20/48] Processing 33_portuguese_grape_varieties...\n",
      "Asking LLM for alphabetic strategy for 33_portuguese_grape_varieties...\n",
      "Fetching alphabetic ranges for Grape...\n",
      "Asking LLM for semantic strategy for 33_portuguese_grape_varieties...\n",
      "Fetching semantic categories for Color...\n",
      "Asking LLM for unrestricted range strategy for 33_portuguese_grape_varieties...\n",
      "Fetching unrestricted ranges for Grape by initial letter (bucket names by letter ranges e.g. Aâ€“C, Dâ€“F, Gâ€“I, Jâ€“L, Mâ€“O, Pâ€“R, Sâ€“U, Vâ€“Z)...\n",
      "[range_based]   âœ“ Success - Saved to 33_portuguese_grape_varieties.json\n",
      "[range_based] [21/48] Processing 34_ramsar_convention_parties...\n",
      "Asking LLM for alphabetic strategy for 34_ramsar_convention_parties...\n",
      "Fetching alphabetic ranges for Country...\n",
      "Asking LLM for semantic strategy for 34_ramsar_convention_parties...\n",
      "Rejected forbidden column 'Country' for semantic\n",
      "Asking LLM for unrestricted range strategy for 34_ramsar_convention_parties...\n",
      "Fetching unrestricted ranges for Entry date by decade (1975â€“1979, 1980s, 1990s, 2000s, 2010â€“2012)...\n",
      "Could not generate all three configs for 34_ramsar_convention_parties (got 2)\n",
      "[range_based]   âš  Attempt 1/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 34_ramsar_convention_parties...\n",
      "Fetching alphabetic ranges for Country...\n",
      "Asking LLM for semantic strategy for 34_ramsar_convention_parties...\n",
      "Rejected forbidden column 'Country' for semantic\n",
      "Asking LLM for unrestricted range strategy for 34_ramsar_convention_parties...\n",
      "Fetching unrestricted ranges for Entry date by decade (1975â€“1979, 1980â€“1989, 1990â€“1999, 2000â€“2009, 2010â€“2012)...\n",
      "Could not generate all three configs for 34_ramsar_convention_parties (got 2)\n",
      "[range_based]   âš  Attempt 2/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 34_ramsar_convention_parties...\n",
      "Fetching alphabetic ranges for Country...\n",
      "Asking LLM for semantic strategy for 34_ramsar_convention_parties...\n",
      "Rejected forbidden column 'Country' for semantic\n",
      "Asking LLM for unrestricted range strategy for 34_ramsar_convention_parties...\n",
      "Fetching unrestricted ranges for Entry date by decade (1975â€“1979, 1980â€“1989, 1990â€“1999, 2000â€“2009, 2010â€“2012)...\n",
      "Could not generate all three configs for 34_ramsar_convention_parties (got 2)\n",
      "[range_based]   âœ— Failed after 3 attempts: Function returned None\n",
      "[range_based] [22/48] Processing 35_guitar_hero_5_songs...\n",
      "Asking LLM for alphabetic strategy for 35_guitar_hero_5_songs...\n",
      "Fetching alphabetic ranges for Song...\n",
      "Asking LLM for semantic strategy for 35_guitar_hero_5_songs...\n",
      "Fetching semantic categories for Genre...\n",
      "Asking LLM for unrestricted range strategy for 35_guitar_hero_5_songs...\n",
      "Fetching unrestricted ranges for year by decade...\n",
      "[range_based]   âœ“ Success - Saved to 35_guitar_hero_5_songs.json\n",
      "[range_based] [23/48] Processing 36_south_cambridgeshire_district_council_1973_2012...\n",
      "Asking LLM for alphabetic strategy for 36_south_cambridgeshire_district_council_1973_2012...\n",
      "Fetching alphabetic ranges for Ward Name...\n",
      "Asking LLM for semantic strategy for 36_south_cambridgeshire_district_council_1973_2012...\n",
      "Fetching semantic categories for Party...\n",
      "Categories contain invalid content: ['Right', 'Centre', 'Left', 'Non-aligned/Other', 'Conservative', 'UKIP', 'Liberal Democrats', 'Liberal', 'Labour', 'Socialist', 'Independent', 'Vacant']\n",
      "Asking LLM for unrestricted range strategy for 36_south_cambridgeshire_district_council_1973_2012...\n",
      "Fetching unrestricted ranges for year by decade (1970s: 1973â€“1979; 1980s: 1980â€“1989; 1990s: 1990â€“1999; 2000s: 2000â€“2009; 2010s: 2010â€“2012)...\n",
      "Could not generate all three configs for 36_south_cambridgeshire_district_council_1973_2012 (got 2)\n",
      "[range_based]   âš  Attempt 1/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 36_south_cambridgeshire_district_council_1973_2012...\n",
      "Fetching alphabetic ranges for Ward...\n",
      "Asking LLM for semantic strategy for 36_south_cambridgeshire_district_council_1973_2012...\n",
      "Fetching semantic categories for Political party...\n",
      "Asking LLM for unrestricted range strategy for 36_south_cambridgeshire_district_council_1973_2012...\n",
      "Fetching unrestricted ranges for year by decade (bucket years into 1973â€“1979, 1980â€“1989, 1990â€“1999, 2000â€“2009, 2010â€“2012)...\n",
      "[range_based]   âœ“ Success (after 2 attempts) - Saved to 36_south_cambridgeshire_district_council_1973_2012.json\n",
      "[range_based] [24/48] Processing 37_dublin_maternity_hospital_mortality_rates_1784_1849...\n",
      "Asking LLM for alphabetic strategy for 37_dublin_maternity_hospital_mortality_rates_1784_1849...\n",
      "Fetching alphabetic ranges for Attending Physician...\n",
      "Asking LLM for semantic strategy for 37_dublin_maternity_hospital_mortality_rates_1784_1849...\n",
      "Fetching semantic categories for Cause of death...\n",
      "Categories contain invalid content: ['Puerperal fever/infection', 'Hemorrhage', 'Eclampsia', 'Obstructed labor/Other obstetric complications', 'Unknown/Other']\n",
      "Asking LLM for unrestricted range strategy for 37_dublin_maternity_hospital_mortality_rates_1784_1849...\n",
      "Fetching unrestricted ranges for year by decade (e.g., 1780s, 1790s, â€¦, 1840s)...\n",
      "Could not generate all three configs for 37_dublin_maternity_hospital_mortality_rates_1784_1849 (got 2)\n",
      "[range_based]   âš  Attempt 1/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 37_dublin_maternity_hospital_mortality_rates_1784_1849...\n",
      "Fetching alphabetic ranges for Attending Physician...\n",
      "Asking LLM for semantic strategy for 37_dublin_maternity_hospital_mortality_rates_1784_1849...\n",
      "Fetching semantic categories for Cause of death...\n",
      "Categories contain invalid content: ['Puerperal fever/infection', 'Hemorrhage', 'Obstructed labour/other obstetric complications', 'Congenital/newborn causes', 'Other/unspecified']\n",
      "Asking LLM for unrestricted range strategy for 37_dublin_maternity_hospital_mortality_rates_1784_1849...\n",
      "Fetching unrestricted ranges for year by decade (10-year buckets aligned to calendar decades; first bucket 1784â€“1789 then 1790â€“1799, 1800â€“1809, â€¦, 1840â€“1849)...\n",
      "Could not generate all three configs for 37_dublin_maternity_hospital_mortality_rates_1784_1849 (got 2)\n",
      "[range_based]   âš  Attempt 2/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 37_dublin_maternity_hospital_mortality_rates_1784_1849...\n",
      "Fetching alphabetic ranges for Attending Physician...\n",
      "Asking LLM for semantic strategy for 37_dublin_maternity_hospital_mortality_rates_1784_1849...\n",
      "Fetching semantic categories for Mortality Category...\n",
      "Categories contain invalid content: ['Very low mortality', 'Low mortality', 'Moderate mortality', 'High mortality', 'Very high mortality', 'Missing or unknown mortality data']\n",
      "Asking LLM for unrestricted range strategy for 37_dublin_maternity_hospital_mortality_rates_1784_1849...\n",
      "Fetching unrestricted ranges for year by decade...\n",
      "Could not generate all three configs for 37_dublin_maternity_hospital_mortality_rates_1784_1849 (got 2)\n",
      "[range_based]   âœ— Failed after 3 attempts: Function returned None\n",
      "[range_based] [25/48] Processing 38_ship_launches_january_1944...\n",
      "Asking LLM for alphabetic strategy for 38_ship_launches_january_1944...\n",
      "Fetching alphabetic ranges for Ship...\n",
      "Asking LLM for semantic strategy for 38_ship_launches_january_1944...\n",
      "Fetching semantic categories for Class / type...\n",
      "Asking LLM for unrestricted range strategy for 38_ship_launches_january_1944...\n",
      "Fetching unrestricted ranges for Date by week ranges within January 1944 (Jan 1â€“7, Jan 8â€“14, Jan 15â€“21, Jan 22â€“31)...\n",
      "[range_based]   âœ“ Success - Saved to 38_ship_launches_january_1944.json\n",
      "[range_based] [26/48] Processing 39_uk_demographics_1960_2012...\n",
      "Asking LLM for alphabetic strategy for 39_uk_demographics_1960_2012...\n",
      "Fetching alphabetic ranges for County...\n",
      "Asking LLM for semantic strategy for 39_uk_demographics_1960_2012...\n",
      "Fetching semantic categories for Fertility category...\n",
      "Asking LLM for unrestricted range strategy for 39_uk_demographics_1960_2012...\n",
      "Fetching unrestricted ranges for Year by decade...\n",
      "[range_based]   âœ“ Success - Saved to 39_uk_demographics_1960_2012.json\n",
      "[range_based] [27/48] Processing 3_australia_demographics_1900_2010...\n",
      "Asking LLM for alphabetic strategy for 3_australia_demographics_1900_2010...\n",
      "Fetching alphabetic ranges for State/Territory...\n",
      "Asking LLM for semantic strategy for 3_australia_demographics_1900_2010...\n",
      "Fetching semantic categories for Region (new column)...\n",
      "Categories contain invalid content: ['New South Wales', 'Victoria', 'Queensland', 'South Australia', 'Western Australia', 'Tasmania', 'Northern Territory', 'Australian Capital Territory', 'Births', 'Stillbirths', 'Deaths', 'Marriages', 'Divorces', 'Male', 'Female', 'Other/Not stated', 'Indigenous (Aboriginal and Torres Strait Islander)', 'Nonâ€‘Indigenous', 'Not stated/Unknown', 'Urban', 'Regional/Rural', 'Remote', 'Infant', 'Child', 'Adolescent', 'Adult', 'Elderly', 'Circulatory diseases', 'Neoplasms (cancer)', 'Respiratory diseases', 'External causes (injury/accident/suicide)', 'Infectious and parasitic diseases', 'Perinatal and congenital conditions', 'Other/unspecified causes', 'Single', 'Married', 'Separated/Divorced', 'Widowed', 'Australia', 'United Kingdom & Ireland', 'Europe', 'Asia', 'Oceania & Pacific Islands', 'Africa', 'North America', 'South America', 'Other/Unknown', 'Low socioeconomic status', 'Middle socioeconomic status', 'High socioeconomic status', 'No schooling', 'Primary education', 'Secondary education', 'Postâ€‘secondary/tertiary', 'Registered on time', 'Late registration', 'Unregistered', 'Resident', 'Temporary resident/Visitor', 'Migrant/Immigrant', 'Emigrant', 'Agriculture', 'Mining', 'Manufacturing', 'Construction', 'Services', 'Public administration', 'Unemployed/Not in labour force']\n",
      "Asking LLM for unrestricted range strategy for 3_australia_demographics_1900_2010...\n",
      "Fetching unrestricted ranges for year by decade (1900â€“1909, 1910â€“1919, â€¦, 2000â€“2009, 2010)...\n",
      "Could not generate all three configs for 3_australia_demographics_1900_2010 (got 2)\n",
      "[range_based]   âš  Attempt 1/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 3_australia_demographics_1900_2010...\n",
      "Fetching alphabetic ranges for State/Territory...\n",
      "Asking LLM for semantic strategy for 3_australia_demographics_1900_2010...\n",
      "Fetching semantic categories for State/Territory...\n",
      "Categories contain invalid content: ['Total population', 'Population density', 'Population growth / natural increase', 'Births', 'Fertility (e.g., total fertility rate)', 'Deaths', 'Mortality rates', 'Infant and child mortality', 'Life expectancy at birth', 'Age structure / age groups', 'Sex composition', 'Migration (internal and international / net migration)', 'Indigenous (Aboriginal and Torres Strait Islander) population', 'Urban versus rural distribution', 'Marital events (marriages and divorces)', 'Household composition and average household size', 'Leading causes of death']\n",
      "Asking LLM for unrestricted range strategy for 3_australia_demographics_1900_2010...\n",
      "Fetching unrestricted ranges for Year by decade...\n",
      "Could not generate all three configs for 3_australia_demographics_1900_2010 (got 2)\n",
      "[range_based]   âš  Attempt 2/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 3_australia_demographics_1900_2010...\n",
      "Fetching alphabetic ranges for State/Territory...\n",
      "Asking LLM for semantic strategy for 3_australia_demographics_1900_2010...\n",
      "Fetching semantic categories for Region (State/Territory)...\n",
      "Categories contain invalid content: ['Population totals', 'Population by age group (age structure)', 'Population by sex (sex composition)', 'Indigenous status', 'Urban vs rural distribution', 'Births', 'Fertility (fertility rates/trends)', 'Infant and child mortality', 'Stillbirths and perinatal mortality', 'Deaths', 'Causes of death (major categories)', 'Life expectancy', 'Natural increase (births minus deaths)', 'Migration (internal and international, net migration)', 'Marriages', 'Divorces']\n",
      "Asking LLM for unrestricted range strategy for 3_australia_demographics_1900_2010...\n",
      "Fetching unrestricted ranges for year by decade (1900â€“1909, 1910â€“1919, â€¦, 2000â€“2009, 2010)...\n",
      "Could not generate all three configs for 3_australia_demographics_1900_2010 (got 2)\n",
      "[range_based]   âœ— Failed after 3 attempts: Function returned None\n",
      "[range_based] [28/48] Processing 40_fukushima_plant_operating_history_1970_2009...\n",
      "Asking LLM for alphabetic strategy for 40_fukushima_plant_operating_history_1970_2009...\n",
      "Fetching alphabetic ranges for Event Description...\n",
      "Asking LLM for semantic strategy for 40_fukushima_plant_operating_history_1970_2009...\n",
      "Fetching semantic categories for Unit 1...\n",
      "Categories contain invalid content: ['Operating / power-generating', 'Planned outage / refueling', 'Maintenance / inspection', 'Emergency shutdown / trip / accident', 'Cold shutdown / safely shut down', 'Decommissioned / retired', 'Under repair / reconstruction']\n",
      "Asking LLM for unrestricted range strategy for 40_fukushima_plant_operating_history_1970_2009...\n",
      "Fetching unrestricted ranges for year by decade...\n",
      "Could not generate all three configs for 40_fukushima_plant_operating_history_1970_2009 (got 2)\n",
      "[range_based]   âš  Attempt 1/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 40_fukushima_plant_operating_history_1970_2009...\n",
      "Fetching alphabetic ranges for Event Category...\n",
      "Asking LLM for semantic strategy for 40_fukushima_plant_operating_history_1970_2009...\n",
      "Fetching semantic categories for Unit 1...\n",
      "Categories contain invalid content: ['Operational', 'Construction/Commissioning', 'Refueling/Maintenance outage', 'Short-term Shutdown', 'Long-term Shutdown/Outage', 'Accident-damaged', 'Decommissioned/Retired']\n",
      "Asking LLM for unrestricted range strategy for 40_fukushima_plant_operating_history_1970_2009...\n",
      "Fetching unrestricted ranges for year by decade...\n",
      "Could not generate all three configs for 40_fukushima_plant_operating_history_1970_2009 (got 2)\n",
      "[range_based]   âš  Attempt 2/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 40_fukushima_plant_operating_history_1970_2009...\n",
      "Fetching alphabetic ranges for Event Type...\n",
      "Asking LLM for semantic strategy for 40_fukushima_plant_operating_history_1970_2009...\n",
      "Fetching semantic categories for Unit 1...\n",
      "Categories contain invalid content: ['Commercial operation', 'Scheduled shutdown/inspection', 'Unplanned outage/maintenance', 'Under construction', 'Decommissioned/retired', 'Accident-affected/cold shutdown']\n",
      "Asking LLM for unrestricted range strategy for 40_fukushima_plant_operating_history_1970_2009...\n",
      "Fetching unrestricted ranges for Year by decade (1970â€“1979, 1980â€“1989, 1990â€“1999, 2000â€“2009)...\n",
      "Could not generate all three configs for 40_fukushima_plant_operating_history_1970_2009 (got 2)\n",
      "[range_based]   âœ— Failed after 3 attempts: Function returned None\n",
      "[range_based] [29/48] Processing 41_new_zealand_football_results_1922_2012...\n",
      "Asking LLM for alphabetic strategy for 41_new_zealand_football_results_1922_2012...\n",
      "Fetching alphabetic ranges for Opponent...\n",
      "Asking LLM for semantic strategy for 41_new_zealand_football_results_1922_2012...\n",
      "Fetching semantic categories for Opponent...\n",
      "Asking LLM for unrestricted range strategy for 41_new_zealand_football_results_1922_2012...\n",
      "Fetching unrestricted ranges for Year by decade...\n",
      "[range_based]   âœ“ Success - Saved to 41_new_zealand_football_results_1922_2012.json\n",
      "[range_based] [30/48] Processing 42_jack_nicklaus_achievements_1962_2005...\n",
      "Asking LLM for alphabetic strategy for 42_jack_nicklaus_achievements_1962_2005...\n",
      "Fetching alphabetic ranges for Tournaments Won...\n",
      "Asking LLM for semantic strategy for 42_jack_nicklaus_achievements_1962_2005...\n",
      "Rejected identifier column 'Tournament type' for semantic\n",
      "Asking LLM for unrestricted range strategy for 42_jack_nicklaus_achievements_1962_2005...\n",
      "Fetching unrestricted ranges for year by decade (1962â€“1969, 1970â€“1979, 1980â€“1989, 1990â€“1999, 2000â€“2005)...\n",
      "Could not generate all three configs for 42_jack_nicklaus_achievements_1962_2005 (got 2)\n",
      "[range_based]   âš  Attempt 1/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 42_jack_nicklaus_achievements_1962_2005...\n",
      "Fetching alphabetic ranges for Tournament Name...\n",
      "Asking LLM for semantic strategy for 42_jack_nicklaus_achievements_1962_2005...\n",
      "Fetching semantic categories for Event type...\n",
      "Asking LLM for unrestricted range strategy for 42_jack_nicklaus_achievements_1962_2005...\n",
      "Fetching unrestricted ranges for year by decade (1962â€“1969, 1970â€“1979, 1980â€“1989, 1990â€“1999, 2000â€“2005)...\n",
      "[range_based]   âœ“ Success (after 2 attempts) - Saved to 42_jack_nicklaus_achievements_1962_2005.json\n",
      "[range_based] [31/48] Processing 47_european_countries_gdp_2007_2012...\n",
      "Asking LLM for alphabetic strategy for 47_european_countries_gdp_2007_2012...\n",
      "Fetching alphabetic ranges for Country...\n",
      "Asking LLM for semantic strategy for 47_european_countries_gdp_2007_2012...\n",
      "Rejected forbidden column 'Country' for semantic\n",
      "Asking LLM for unrestricted range strategy for 47_european_countries_gdp_2007_2012...\n",
      "Fetching unrestricted ranges for 2012 by GDP (USD) ranges: < $10B; $10â€“50B; $50â€“200B; $200â€“500B; $500Bâ€“$1T; > $1T...\n",
      "Could not generate all three configs for 47_european_countries_gdp_2007_2012 (got 2)\n",
      "[range_based]   âš  Attempt 1/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 47_european_countries_gdp_2007_2012...\n",
      "Fetching alphabetic ranges for Country...\n",
      "Asking LLM for semantic strategy for 47_european_countries_gdp_2007_2012...\n",
      "Rejected forbidden column 'Country' for semantic\n",
      "Asking LLM for unrestricted range strategy for 47_european_countries_gdp_2007_2012...\n",
      "Fetching unrestricted ranges for 2012 by nominal GDP ranges (approx.): >$1T; $500Bâ€“$1T; $100Bâ€“$500B; $50Bâ€“$100B; $10Bâ€“$50B; <$10B...\n",
      "Could not generate all three configs for 47_european_countries_gdp_2007_2012 (got 2)\n",
      "[range_based]   âš  Attempt 2/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 47_european_countries_gdp_2007_2012...\n",
      "Fetching alphabetic ranges for Country...\n",
      "Asking LLM for semantic strategy for 47_european_countries_gdp_2007_2012...\n",
      "Rejected forbidden column 'Country' for semantic\n",
      "Asking LLM for unrestricted range strategy for 47_european_countries_gdp_2007_2012...\n",
      "Fetching unrestricted ranges for 2012 by nominal GDP (USD) using buckets: >=$1T; $500Bâ€“$1T; $200Bâ€“$500B; $100Bâ€“$200B; $50Bâ€“$100B; $10Bâ€“$50B; $1Bâ€“$10B; <$1B...\n",
      "Could not generate all three configs for 47_european_countries_gdp_2007_2012 (got 2)\n",
      "[range_based]   âœ— Failed after 3 attempts: Function returned None\n",
      "[range_based] [32/48] Processing 48_royal_dulton_figurines_HN4100_HN4199...\n",
      "Asking LLM for alphabetic strategy for 48_royal_dulton_figurines_HN4100_HN4199...\n",
      "Fetching alphabetic ranges for Title...\n",
      "Asking LLM for semantic strategy for 48_royal_dulton_figurines_HN4100_HN4199...\n",
      "Rejected identifier column 'Title' for semantic\n",
      "Asking LLM for unrestricted range strategy for 48_royal_dulton_figurines_HN4100_HN4199...\n",
      "Fetching unrestricted ranges for HN Number by groups of 10 (HN4100â€“HN4109, HN4110â€“HN4119, â€¦ HN4190â€“HN4199)...\n",
      "Could not generate all three configs for 48_royal_dulton_figurines_HN4100_HN4199 (got 2)\n",
      "[range_based]   âš  Attempt 1/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 48_royal_dulton_figurines_HN4100_HN4199...\n",
      "Fetching alphabetic ranges for Title...\n",
      "Asking LLM for semantic strategy for 48_royal_dulton_figurines_HN4100_HN4199...\n",
      "Rejected identifier column 'Title' for semantic\n",
      "Asking LLM for unrestricted range strategy for 48_royal_dulton_figurines_HN4100_HN4199...\n",
      "Fetching unrestricted ranges for HN Number by groups of 10 (HN4100â€“HN4109, HN4110â€“HN4119, â€¦ HN4190â€“HN4199)...\n",
      "Could not generate all three configs for 48_royal_dulton_figurines_HN4100_HN4199 (got 2)\n",
      "[range_based]   âš  Attempt 2/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 48_royal_dulton_figurines_HN4100_HN4199...\n",
      "Fetching alphabetic ranges for Title...\n",
      "Asking LLM for semantic strategy for 48_royal_dulton_figurines_HN4100_HN4199...\n",
      "Fetching semantic categories for Designer(s)...\n",
      "Categories contain invalid content: [\"Need the list of designers present in HN4100â€“HN4199 (please provide the table or a list of designers) so I can enumerate the exact semantic categories; otherwise I can only supply generic categories such as individual designer names plus 'Unknown/Various' and 'Collaborations/Multiple designers'\"]\n",
      "Asking LLM for unrestricted range strategy for 48_royal_dulton_figurines_HN4100_HN4199...\n",
      "Fetching unrestricted ranges for HN Number by groups of 10 (HN4100â€“HN4109, HN4110â€“HN4119, â€¦ HN4190â€“HN4199)...\n",
      "Could not generate all three configs for 48_royal_dulton_figurines_HN4100_HN4199 (got 2)\n",
      "[range_based]   âœ— Failed after 3 attempts: Function returned None\n",
      "[range_based] [33/48] Processing 49_adaalat_episodes_2012...\n",
      "Asking LLM for alphabetic strategy for 49_adaalat_episodes_2012...\n",
      "Fetching alphabetic ranges for Title...\n",
      "Asking LLM for semantic strategy for 49_adaalat_episodes_2012...\n",
      "Rejected identifier column 'Title' for semantic\n",
      "Asking LLM for unrestricted range strategy for 49_adaalat_episodes_2012...\n",
      "Fetching unrestricted ranges for Original Air Date by month...\n",
      "Could not generate all three configs for 49_adaalat_episodes_2012 (got 2)\n",
      "[range_based]   âš  Attempt 1/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 49_adaalat_episodes_2012...\n",
      "Fetching alphabetic ranges for Title...\n",
      "Asking LLM for semantic strategy for 49_adaalat_episodes_2012...\n",
      "Rejected identifier column 'Title' for semantic\n",
      "Asking LLM for unrestricted range strategy for 49_adaalat_episodes_2012...\n",
      "Fetching unrestricted ranges for Original Air Date by month...\n",
      "Could not generate all three configs for 49_adaalat_episodes_2012 (got 2)\n",
      "[range_based]   âš  Attempt 2/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 49_adaalat_episodes_2012...\n",
      "Fetching alphabetic ranges for Title...\n",
      "Asking LLM for semantic strategy for 49_adaalat_episodes_2012...\n",
      "Rejected identifier column 'Title' for semantic\n",
      "Asking LLM for unrestricted range strategy for 49_adaalat_episodes_2012...\n",
      "Fetching unrestricted ranges for Original Air Date by month...\n",
      "Could not generate all three configs for 49_adaalat_episodes_2012 (got 2)\n",
      "[range_based]   âœ— Failed after 3 attempts: Function returned None\n",
      "[range_based] [34/48] Processing 4_new_brunswick_parishes_2006_2011...\n",
      "Asking LLM for alphabetic strategy for 4_new_brunswick_parishes_2006_2011...\n",
      "Fetching alphabetic ranges for Name...\n",
      "Asking LLM for semantic strategy for 4_new_brunswick_parishes_2006_2011...\n",
      "Rejected forbidden column 'County' for semantic\n",
      "Asking LLM for unrestricted range strategy for 4_new_brunswick_parishes_2006_2011...\n",
      "Fetching unrestricted ranges for Population (2011) by ranges: 0â€“499, 500â€“999, 1,000â€“1,999, 2,000â€“4,999, 5,000+...\n",
      "Could not generate all three configs for 4_new_brunswick_parishes_2006_2011 (got 2)\n",
      "[range_based]   âš  Attempt 1/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 4_new_brunswick_parishes_2006_2011...\n",
      "Fetching alphabetic ranges for Name...\n",
      "Asking LLM for semantic strategy for 4_new_brunswick_parishes_2006_2011...\n",
      "Rejected forbidden column 'County' for semantic\n",
      "Asking LLM for unrestricted range strategy for 4_new_brunswick_parishes_2006_2011...\n",
      "Fetching unrestricted ranges for Population (2011) by population ranges: 0â€“499, 500â€“999, 1,000â€“1,999, 2,000â€“4,999, 5,000â€“9,999, 10,000+...\n",
      "Could not generate all three configs for 4_new_brunswick_parishes_2006_2011 (got 2)\n",
      "[range_based]   âš  Attempt 2/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 4_new_brunswick_parishes_2006_2011...\n",
      "Fetching alphabetic ranges for Name...\n",
      "Asking LLM for semantic strategy for 4_new_brunswick_parishes_2006_2011...\n",
      "Rejected forbidden column 'County' for semantic\n",
      "Asking LLM for unrestricted range strategy for 4_new_brunswick_parishes_2006_2011...\n",
      "Fetching unrestricted ranges for Population (2011) by 500â€‘person ranges (0â€“499, 500â€“999, 1,000â€“1,499, â€¦; collapse high-end sparse values into 5,000+ if needed)...\n",
      "Could not generate all three configs for 4_new_brunswick_parishes_2006_2011 (got 2)\n",
      "[range_based]   âœ— Failed after 3 attempts: Function returned None\n",
      "[range_based] [35/48] Processing 51_just_dance_kids_2_tracks...\n",
      "Asking LLM for alphabetic strategy for 51_just_dance_kids_2_tracks...\n",
      "Fetching alphabetic ranges for Song...\n",
      "Asking LLM for semantic strategy for 51_just_dance_kids_2_tracks...\n",
      "Fetching semantic categories for Song Filters...\n",
      "Asking LLM for unrestricted range strategy for 51_just_dance_kids_2_tracks...\n",
      "Fetching unrestricted ranges for Year by decade...\n",
      "[range_based]   âœ“ Success - Saved to 51_just_dance_kids_2_tracks.json\n",
      "[range_based] [36/48] Processing 52_cross_country_junior_women_1996...\n",
      "Asking LLM for alphabetic strategy for 52_cross_country_junior_women_1996...\n",
      "Fetching alphabetic ranges for Athlete...\n",
      "Asking LLM for semantic strategy for 52_cross_country_junior_women_1996...\n",
      "Rejected forbidden column 'Country' for semantic\n",
      "Asking LLM for unrestricted range strategy for 52_cross_country_junior_women_1996...\n",
      "Fetching unrestricted ranges for Rank by blocks of 10 (1â€“10, 11â€“20, 21â€“30, ...)...\n",
      "Failed to parse unrestricted ranges for 52_cross_country_junior_women_1996: Expecting value: line 1 column 1 (char 0)\n",
      "Could not generate all three configs for 52_cross_country_junior_women_1996 (got 1)\n",
      "[range_based]   âš  Attempt 1/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 52_cross_country_junior_women_1996...\n",
      "Fetching alphabetic ranges for Athlete...\n",
      "Asking LLM for semantic strategy for 52_cross_country_junior_women_1996...\n",
      "Rejected forbidden column 'Country' for semantic\n",
      "Asking LLM for unrestricted range strategy for 52_cross_country_junior_women_1996...\n",
      "Fetching unrestricted ranges for Rank by groups of 10 (1â€“10, 11â€“20, 21â€“30, â€¦)...\n",
      "Failed to parse unrestricted ranges for 52_cross_country_junior_women_1996: Expecting value: line 1 column 1 (char 0)\n",
      "Could not generate all three configs for 52_cross_country_junior_women_1996 (got 1)\n",
      "[range_based]   âš  Attempt 2/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 52_cross_country_junior_women_1996...\n",
      "Fetching alphabetic ranges for Athlete...\n",
      "Asking LLM for semantic strategy for 52_cross_country_junior_women_1996...\n",
      "Rejected forbidden column 'Country' for semantic\n",
      "Asking LLM for unrestricted range strategy for 52_cross_country_junior_women_1996...\n",
      "Fetching unrestricted ranges for Rank by groups of 10 (1â€“10, 11â€“20, 21â€“30, 31â€“40, ...)...\n",
      "Failed to parse unrestricted ranges for 52_cross_country_junior_women_1996: Expecting value: line 1 column 1 (char 0)\n",
      "Could not generate all three configs for 52_cross_country_junior_women_1996 (got 1)\n",
      "[range_based]   âœ— Failed after 3 attempts: Function returned None\n",
      "[range_based] [37/48] Processing 53_metropolitan_opera_us_premieres...\n",
      "Asking LLM for alphabetic strategy for 53_metropolitan_opera_us_premieres...\n",
      "Fetching alphabetic ranges for Opera...\n",
      "Asking LLM for semantic strategy for 53_metropolitan_opera_us_premieres...\n",
      "Fetching semantic categories for Composer...\n",
      "Asking LLM for unrestricted range strategy for 53_metropolitan_opera_us_premieres...\n",
      "Fetching unrestricted ranges for Date of premiere by decade (1880â€“1889, 1890â€“1899, â€¦, 2000â€“2009 â€” final bucket may be partial up to 2005)...\n",
      "[range_based]   âœ“ Success - Saved to 53_metropolitan_opera_us_premieres.json\n",
      "[range_based] [38/48] Processing 54_kasparov_kramnik_1993_2004...\n",
      "Asking LLM for alphabetic strategy for 54_kasparov_kramnik_1993_2004...\n",
      "Fetching alphabetic ranges for Opening...\n",
      "Asking LLM for semantic strategy for 54_kasparov_kramnik_1993_2004...\n",
      "Fetching semantic categories for Opening...\n",
      "Asking LLM for unrestricted range strategy for 54_kasparov_kramnik_1993_2004...\n",
      "Fetching unrestricted ranges for year by single-year buckets (one bucket per year: 1993, 1994, â€¦, 2004)...\n",
      "[range_based]   âœ“ Success - Saved to 54_kasparov_kramnik_1993_2004.json\n",
      "[range_based] [39/48] Processing 55_decathlon_top50_1999...\n",
      "Asking LLM for alphabetic strategy for 55_decathlon_top50_1999...\n",
      "Fetching alphabetic ranges for Athlete...\n",
      "Asking LLM for semantic strategy for 55_decathlon_top50_1999...\n",
      "Fetching semantic categories for Venue...\n",
      "Asking LLM for unrestricted range strategy for 55_decathlon_top50_1999...\n",
      "Fetching unrestricted ranges for Points by 100-point ranges (e.g., 9000+, 8900-8999, 8800-8899, â€¦ down to 7000-7099)...\n",
      "[range_based]   âœ“ Success - Saved to 55_decathlon_top50_1999.json\n",
      "[range_based] [40/48] Processing 56_minor_planets_152601_152700...\n",
      "Asking LLM for alphabetic strategy for 56_minor_planets_152601_152700...\n",
      "Fetching alphabetic ranges for Name...\n",
      "Asking LLM for semantic strategy for 56_minor_planets_152601_152700...\n",
      "Fetching semantic categories for Discovery site...\n",
      "Asking LLM for unrestricted range strategy for 56_minor_planets_152601_152700...\n",
      "Fetching unrestricted ranges for Name by ranges of 10 (152601â€“152610, 152611â€“152620, â€¦, 152691â€“152700)...\n",
      "[range_based]   âœ“ Success - Saved to 56_minor_planets_152601_152700.json\n",
      "[range_based] [41/48] Processing 59_miss_new_york_usa_delegates_2012...\n",
      "Asking LLM for alphabetic strategy for 59_miss_new_york_usa_delegates_2012...\n",
      "Fetching alphabetic ranges for Candidate...\n",
      "Asking LLM for semantic strategy for 59_miss_new_york_usa_delegates_2012...\n",
      "Fetching semantic categories for Represents...\n",
      "Asking LLM for unrestricted range strategy for 59_miss_new_york_usa_delegates_2012...\n",
      "Fetching unrestricted ranges for Candidate by last-name initial (grouped alphabetically: Aâ€“C, Dâ€“F, Gâ€“I, Jâ€“L, Mâ€“O, Pâ€“R, Sâ€“U, Vâ€“Z)...\n",
      "[range_based]   âœ“ Success - Saved to 59_miss_new_york_usa_delegates_2012.json\n",
      "[range_based] [42/48] Processing 5_ice_hockey_2006...\n",
      "Asking LLM for alphabetic strategy for 5_ice_hockey_2006...\n",
      "Fetching alphabetic ranges for Player name...\n",
      "Asking LLM for semantic strategy for 5_ice_hockey_2006...\n",
      "Rejected forbidden column 'Country' for semantic\n",
      "Asking LLM for unrestricted range strategy for 5_ice_hockey_2006...\n",
      "Fetching unrestricted ranges for Pts by 2-point ranges (0, 1â€“2, 3â€“4, 5â€“6, 7â€“8, 9â€“10, 11+)...\n",
      "Could not generate all three configs for 5_ice_hockey_2006 (got 2)\n",
      "[range_based]   âš  Attempt 1/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 5_ice_hockey_2006...\n",
      "Fetching alphabetic ranges for Player name...\n",
      "Asking LLM for semantic strategy for 5_ice_hockey_2006...\n",
      "Rejected forbidden column 'Country' for semantic\n",
      "Asking LLM for unrestricted range strategy for 5_ice_hockey_2006...\n",
      "Fetching unrestricted ranges for Pts by 2-point ranges (0, 1â€“2, 3â€“4, 5â€“6, 7â€“8, 9â€“10, 11+)...\n",
      "Could not generate all three configs for 5_ice_hockey_2006 (got 2)\n",
      "[range_based]   âš  Attempt 2/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 5_ice_hockey_2006...\n",
      "Fetching alphabetic ranges for Player name...\n",
      "Asking LLM for semantic strategy for 5_ice_hockey_2006...\n",
      "Rejected forbidden column 'Country' for semantic\n",
      "Asking LLM for unrestricted range strategy for 5_ice_hockey_2006...\n",
      "Fetching unrestricted ranges for Pts by 2-point ranges (0â€“1, 2â€“3, 4â€“5, 6â€“7, 8+)...\n",
      "Could not generate all three configs for 5_ice_hockey_2006 (got 2)\n",
      "[range_based]   âœ— Failed after 3 attempts: Function returned None\n",
      "[range_based] [43/48] Processing 67_london_heathrow_busiest_routes_2012...\n",
      "Asking LLM for alphabetic strategy for 67_london_heathrow_busiest_routes_2012...\n",
      "Fetching alphabetic ranges for Airport...\n",
      "Asking LLM for semantic strategy for 67_london_heathrow_busiest_routes_2012...\n",
      "Fetching semantic categories for Airport...\n",
      "Categories contain invalid content: ['Continent', 'Country', 'City/Airport', 'Airport pair (route)', 'Direction (to Heathrow / from Heathrow)', 'Airline / carrier', 'Airline alliance', 'Service type (scheduled / charter)', 'Seasonality (yearâ€‘round / seasonal)', 'Aircraft category (regional / narrowâ€‘body / wideâ€‘body)', 'Flight distance category (shortâ€‘haul / mediumâ€‘haul / longâ€‘haul)', 'Stop type (nonstop / oneâ€‘stop / multiâ€‘stop)', 'Market segment (business / leisure / VFR)', 'Airport hub status (hub / major / secondary)']\n",
      "Asking LLM for unrestricted range strategy for 67_london_heathrow_busiest_routes_2012...\n",
      "Fetching unrestricted ranges for Rank by groups of 10 (1â€“10, 11â€“20, 21â€“30, 31â€“40, 41â€“50, 51â€“60)...\n",
      "Could not generate all three configs for 67_london_heathrow_busiest_routes_2012 (got 2)\n",
      "[range_based]   âš  Attempt 1/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 67_london_heathrow_busiest_routes_2012...\n",
      "Fetching alphabetic ranges for Airport...\n",
      "Asking LLM for semantic strategy for 67_london_heathrow_busiest_routes_2012...\n",
      "Fetching semantic categories for Airport...\n",
      "Categories contain invalid content: ['Continent / Region (e.g., Europe, Asia, North America, Middle East, Africa, Oceania, South America)', 'Country (so airports are grouped by the country they serve)', 'City or metropolitan area', 'Airport (name and IATA code)', 'Route pair / Originâ€“Destination (airport-to-airport)', 'Route direction (To Heathrow vs From Heathrow)', 'Airline / Carrier operating the route', 'Route type or distance class (shortâ€‘haul, mediumâ€‘haul, longâ€‘haul, intercontinental, regional)', 'Airport role (hub / focus city / pointâ€‘toâ€‘point)', 'Airline alliance (if applicable)']\n",
      "Asking LLM for unrestricted range strategy for 67_london_heathrow_busiest_routes_2012...\n",
      "Fetching unrestricted ranges for Rank by groups of 10 (1â€“10, 11â€“20, 21â€“30, 31â€“40, 41â€“50, 51â€“60)...\n",
      "Could not generate all three configs for 67_london_heathrow_busiest_routes_2012 (got 2)\n",
      "[range_based]   âš  Attempt 2/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 67_london_heathrow_busiest_routes_2012...\n",
      "Fetching alphabetic ranges for Airport...\n",
      "Asking LLM for semantic strategy for 67_london_heathrow_busiest_routes_2012...\n",
      "Fetching semantic categories for Airport...\n",
      "Asking LLM for unrestricted range strategy for 67_london_heathrow_busiest_routes_2012...\n",
      "Fetching unrestricted ranges for Rank by groups of 10 (1â€“10, 11â€“20, 21â€“30, 31â€“40, 41â€“50, 51â€“60)...\n",
      "[range_based]   âœ“ Success (after 3 attempts) - Saved to 67_london_heathrow_busiest_routes_2012.json\n",
      "[range_based] [44/48] Processing 71_us_president_elections_idaho_2008...\n",
      "Asking LLM for alphabetic strategy for 71_us_president_elections_idaho_2008...\n",
      "Fetching alphabetic ranges for County...\n",
      "Asking LLM for semantic strategy for 71_us_president_elections_idaho_2008...\n",
      "Rejected forbidden column 'County' for semantic\n",
      "Asking LLM for unrestricted range strategy for 71_us_president_elections_idaho_2008...\n",
      "Fetching unrestricted ranges for Obama% by 5 percentage-point ranges (0â€“5%, 5â€“10%, 10â€“15%, â€¦, 95â€“100%)...\n",
      "Could not generate all three configs for 71_us_president_elections_idaho_2008 (got 2)\n",
      "[range_based]   âš  Attempt 1/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 71_us_president_elections_idaho_2008...\n",
      "Fetching alphabetic ranges for County...\n",
      "Asking LLM for semantic strategy for 71_us_president_elections_idaho_2008...\n",
      "Rejected forbidden column 'County' for semantic\n",
      "Asking LLM for unrestricted range strategy for 71_us_president_elections_idaho_2008...\n",
      "Fetching unrestricted ranges for Obama% by 5 percentage-point ranges (0â€“5%, 5â€“10%, 10â€“15%, â€¦ up to 100%)...\n",
      "Could not generate all three configs for 71_us_president_elections_idaho_2008 (got 2)\n",
      "[range_based]   âš  Attempt 2/3 failed (returned None), retrying...\n",
      "Asking LLM for alphabetic strategy for 71_us_president_elections_idaho_2008...\n",
      "Fetching alphabetic ranges for County...\n",
      "Asking LLM for semantic strategy for 71_us_president_elections_idaho_2008...\n",
      "Rejected forbidden column 'County' for semantic\n",
      "Asking LLM for unrestricted range strategy for 71_us_president_elections_idaho_2008...\n",
      "Fetching unrestricted ranges for Obama% by 5-percentage-point ranges (0â€“5%, 5â€“10%, 10â€“15%, â€¦ up to 100%)...\n",
      "Could not generate all three configs for 71_us_president_elections_idaho_2008 (got 2)\n",
      "[range_based]   âœ— Failed after 3 attempts: Function returned None\n",
      "[range_based] [45/48] Processing 78_bafta_best_actor_leading_role_2000s...\n",
      "Asking LLM for alphabetic strategy for 78_bafta_best_actor_leading_role_2000s...\n",
      "Fetching alphabetic ranges for Actor...\n",
      "Asking LLM for semantic strategy for 78_bafta_best_actor_leading_role_2000s...\n",
      "Fetching semantic categories for Actor...\n",
      "Asking LLM for unrestricted range strategy for 78_bafta_best_actor_leading_role_2000s...\n",
      "Fetching unrestricted ranges for year by single-year buckets (one bucket per year: 2000, 2001, â€¦, 2009)...\n",
      "[range_based]   âœ“ Success - Saved to 78_bafta_best_actor_leading_role_2000s.json\n",
      "[range_based] [46/48] Processing 7_anaheim_ducks_draft_picks_1998_2013...\n",
      "Asking LLM for alphabetic strategy for 7_anaheim_ducks_draft_picks_1998_2013...\n",
      "Fetching alphabetic ranges for Player...\n",
      "Asking LLM for semantic strategy for 7_anaheim_ducks_draft_picks_1998_2013...\n",
      "Fetching semantic categories for Nationality...\n",
      "Asking LLM for unrestricted range strategy for 7_anaheim_ducks_draft_picks_1998_2013...\n",
      "Fetching unrestricted ranges for Draft by 4-year ranges (1998â€“2001, 2002â€“2005, 2006â€“2009, 2010â€“2013)...\n",
      "[range_based]   âœ“ Success - Saved to 7_anaheim_ducks_draft_picks_1998_2013.json\n",
      "[range_based] [47/48] Processing 8_south_african_class_15f_4_8_2...\n",
      "Asking LLM for alphabetic strategy for 8_south_african_class_15f_4_8_2...\n",
      "Fetching alphabetic ranges for Builder...\n",
      "Asking LLM for semantic strategy for 8_south_african_class_15f_4_8_2...\n",
      "Fetching semantic categories for Builder...\n",
      "Asking LLM for unrestricted range strategy for 8_south_african_class_15f_4_8_2...\n",
      "Fetching unrestricted ranges for year by single-year buckets (1938, 1939, â€¦, 1946)...\n",
      "[range_based]   âœ“ Success - Saved to 8_south_african_class_15f_4_8_2.json\n",
      "[range_based] [48/48] Processing 9_tour_de_france_2009...\n",
      "Asking LLM for alphabetic strategy for 9_tour_de_france_2009...\n",
      "Fetching alphabetic ranges for Rider...\n",
      "Asking LLM for semantic strategy for 9_tour_de_france_2009...\n",
      "Fetching semantic categories for Nationality...\n",
      "Asking LLM for unrestricted range strategy for 9_tour_de_france_2009...\n",
      "Fetching unrestricted ranges for Age by 5-year ranges (e.g., 20â€“24, 25â€“29, 30â€“34, 35â€“39, 40+)...\n",
      "[range_based]   âœ“ Success - Saved to 9_tour_de_france_2009.json\n",
      "\n",
      "[range_based] Completed: 34 successes, 14 errors\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "range_based: 34 tables processed\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Create output directory with timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "output_dir = OUTPUT_ROOT / timestamp\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "\n",
    "# Create subdirectories for each strategy upfront\n",
    "for strategy_name in ACTIVE_STRATEGIES:\n",
    "    strategy_dir = output_dir / strategy_name\n",
    "    strategy_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Process all tables for each strategy\n",
    "results = {strategy: [] for strategy in ACTIVE_STRATEGIES}\n",
    "errors = {strategy: [] for strategy in ACTIVE_STRATEGIES}\n",
    "\n",
    "def process_strategy(strategy_name: str):\n",
    "    \"\"\"Process all tables for a single strategy with retry logic.\"\"\"\n",
    "    strategy_results = []\n",
    "    strategy_errors = []\n",
    "    MAX_RETRIES = 3\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Running strategy: {strategy_name.upper()}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    strategy_func = STRATEGIES_TO_RUN[strategy_name]\n",
    "    strategy_dir = output_dir / strategy_name\n",
    "    \n",
    "    for i, table in enumerate(tables_to_process):\n",
    "        print(f\"[{strategy_name}] [{i+1}/{len(tables_to_process)}] Processing {table['table_id']}...\")\n",
    "        \n",
    "        plan = None\n",
    "        last_error = None\n",
    "        \n",
    "        # Retry loop\n",
    "        for attempt in range(MAX_RETRIES):\n",
    "            try:\n",
    "                plan = strategy_func(table)\n",
    "                \n",
    "                if plan:\n",
    "                    # Success!\n",
    "                    break\n",
    "                else:\n",
    "                    last_error = 'Function returned None'\n",
    "                    if attempt < MAX_RETRIES - 1:\n",
    "                        print(f\"[{strategy_name}]   âš  Attempt {attempt + 1}/{MAX_RETRIES} failed (returned None), retrying...\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                last_error = str(e)\n",
    "                if attempt < MAX_RETRIES - 1:\n",
    "                    print(f\"[{strategy_name}]   âš  Attempt {attempt + 1}/{MAX_RETRIES} failed: {e}, retrying...\")\n",
    "        \n",
    "        # After all retries, check if we succeeded\n",
    "        if plan:\n",
    "            strategy_results.append(plan)\n",
    "            \n",
    "            # Save immediately after successful processing\n",
    "            table_id = plan['table_id']\n",
    "            output_file = strategy_dir / f\"{table_id}.json\"\n",
    "            with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(plan, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            retry_msg = f\" (after {attempt + 1} attempt{'s' if attempt > 0 else ''})\" if attempt > 0 else \"\"\n",
    "            print(f\"[{strategy_name}]   âœ“ Success{retry_msg} - Saved to {output_file.name}\")\n",
    "        else:\n",
    "            # All retries failed\n",
    "            strategy_errors.append({\n",
    "                'table_id': table['table_id'],\n",
    "                'error': last_error,\n",
    "                'attempts': MAX_RETRIES\n",
    "            })\n",
    "            print(f\"[{strategy_name}]   âœ— Failed after {MAX_RETRIES} attempts: {last_error}\")\n",
    "        \n",
    "        # Save errors incrementally too\n",
    "        if strategy_errors:\n",
    "            errors_file = strategy_dir / '_errors.json'\n",
    "            with open(errors_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(strategy_errors, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\n[{strategy_name}] Completed: {len(strategy_results)} successes, {len(strategy_errors)} errors\")\n",
    "    return strategy_name, strategy_results, strategy_errors\n",
    "\n",
    "# Run strategies in parallel or sequentially\n",
    "if PARALLEL_STRATEGIES:\n",
    "    print(f\"\\nâš¡ Running {len(ACTIVE_STRATEGIES)} strategies in PARALLEL with {MAX_WORKERS} workers\")\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        # Submit all strategy tasks\n",
    "        future_to_strategy = {\n",
    "            executor.submit(process_strategy, strategy_name): strategy_name \n",
    "            for strategy_name in ACTIVE_STRATEGIES\n",
    "        }\n",
    "        \n",
    "        # Collect results as they complete\n",
    "        for future in as_completed(future_to_strategy):\n",
    "            strategy_name, strategy_results, strategy_errors = future.result()\n",
    "            results[strategy_name] = strategy_results\n",
    "            errors[strategy_name] = strategy_errors\n",
    "else:\n",
    "    print(f\"\\nðŸ”„ Running {len(ACTIVE_STRATEGIES)} strategies SEQUENTIALLY\")\n",
    "    \n",
    "    for strategy_name in ACTIVE_STRATEGIES:\n",
    "        strategy_name, strategy_results, strategy_errors = process_strategy(strategy_name)\n",
    "        results[strategy_name] = strategy_results\n",
    "        errors[strategy_name] = strategy_errors\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "for strategy_name in ACTIVE_STRATEGIES:\n",
    "    print(f\"{strategy_name}: {len(results[strategy_name])} tables processed\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3e0841",
   "metadata": {},
   "source": [
    "## Save Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f9110bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final summary saved to processing/1_strategy/20251015_230052/_summary.json\n",
      "\n",
      "All done! Results saved to processing/1_strategy/20251015_230052\n"
     ]
    }
   ],
   "source": [
    "# All individual files have been saved incrementally during processing\n",
    "# Now just save the final summary\n",
    "\n",
    "summary = {\n",
    "    'timestamp': timestamp,\n",
    "    'max_tables_limit': MAX_TABLES,\n",
    "    'total_tables': len(tables),\n",
    "    'processed_tables': len(tables_to_process),\n",
    "    'strategies': {\n",
    "        strategy_name: {\n",
    "            'success_count': len(results[strategy_name]),\n",
    "            'error_count': len(errors[strategy_name])\n",
    "        }\n",
    "        for strategy_name in ACTIVE_STRATEGIES\n",
    "    }\n",
    "}\n",
    "\n",
    "summary_file = output_dir / '_summary.json'\n",
    "with open(summary_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nFinal summary saved to {summary_file}\")\n",
    "print(f\"\\nAll done! Results saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10395346",
   "metadata": {},
   "source": [
    "## Sample Output Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e133d59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Sample output for RANGE_BASED\n",
      "============================================================\n",
      "{\n",
      "  \"table_id\": \"10_men_butterfly_100m_2009\",\n",
      "  \"table_name\": \"men_butterfly_100m_2009\",\n",
      "  \"strategy\": \"range_based\",\n",
      "  \"metadata\": {\n",
      "    \"table_title\": \"men's 100 metre butterfly results in heats at the 2009 World Aquatics Championships\",\n",
      "    \"columns\": [\n",
      "      \"Name\",\n",
      "      \"Nationality\",\n",
      "      \"Time\",\n",
      "      \"Heat\",\n",
      "      \"Lane\"\n",
      "    ],\n",
      "    \"key_columns\": [\n",
      "      \"Name\"\n",
      "    ]\n",
      "  },\n",
      "  \"pagination_config_alphabetic\": {\n",
      "    \"partition_column\": \"Name\",\n",
      "    \"bucketing_criteria\": \"by starting letter ranges A-F, G-L, M-R, S-Z\",\n",
      "    \"ranges\": [\n",
      "      {\n",
      "        \"gte\": \"A\",\n",
      "        \"lt\": \"G\"\n",
      "      },\n",
      "      {\n",
      "        \"gte\": \"G\",\n",
      "        \"lt\": \"M\"\n",
      "      },\n",
      "      {\n",
      "        \"gte\": \"M\",\n",
      "        \"lt\": \"S\"\n",
      "      },\n",
      "      {\n",
      "        \"gte\": \"S\",\n",
      "        \"lt\": \"[\"\n",
      "      }\n",
      "    ],\n",
      "    \"total_ranges\": 4\n",
      "  },\n",
      "  \"pagination_config_semantic\": {\n",
      "    \"partition_column\": \"Nationality\",\n",
      "    \"bucketing_criteria\": \"by continent (Africa, Asia, Europe, North America, South America, Oceania)\",\n",
      "    \"ranges\": [\n",
      "      {\n",
      "        \"category\": \"Africa\"\n",
      "      },\n",
      "      {\n",
      "        \"category\": \"Asia\"\n",
      "      },\n",
      "      {\n",
      "        \"category\": \"Europe\"\n",
      "      },\n",
      "      {\n",
      "        \"category\": \"North America\"\n",
      "      },\n",
      "      {\n",
      "        \"category\": \"South America\"\n",
      "      },\n",
      "      {\n",
      "        \"category\": \"Oceania\"\n",
      "      }\n",
      "    ],\n",
      "    \"total_ranges\": 6\n",
      "  },\n",
      "  \"pagination_config_unrestricted\": {\n",
      "    \"partition_column\": \"Time\",\n",
      "    \"bucketing_criteria\": \"by 0.5-second ranges (e.g., 49.00\\u201349.49, 49.50\\u201349.99, 50.00\\u201350.49, 50.50\\u201350.99, ...)\",\n",
      "    \"ranges\": [\n",
      "      {\n",
      "        \"gte\": \"49.00\",\n",
      "        \"lt\": \"49.50\"\n",
      "      },\n",
      "      {\n",
      "        \"gte\": \"49.50\",\n",
      "        \"lt\": \"50.00\"\n",
      "      },\n",
      "      {\n",
      "        \"gte\": \"50.00\",\n",
      "        \"lt\": \"50.50\"\n",
      "      },\n",
      "      {\n",
      "        \"gte\": \"50.50\",\n",
      "        \"lt\": \"51.00\"\n",
      "      },\n",
      "      {\n",
      "        \"gte\": \"51.00\",\n",
      "        \"lt\": \"51.50\"\n",
      "      },\n",
      "      {\n",
      "        \"gte\": \"51.50\",\n",
      "        \"lt\": \"52.00\"\n",
      "      },\n",
      "      {\n",
      "        \"gte\": \"52.00\",\n",
      "        \"lt\": \"52.50\"\n",
      "      },\n",
      "      {\n",
      "        \"gte\": \"52.50\",\n",
      "        \"lt\": \"53.00\"\n",
      "      },\n",
      "      {\n",
      "        \"gte\": \"53.00\",\n",
      "        \"lt\": \"53.50\"\n",
      "      },\n",
      "      {\n",
      "        \"gte\": \"53.50\",\n",
      "        \"lt\": \"54.00\"\n",
      "      },\n",
      "      {\n",
      "        \"gte\": \"54.00\",\n",
      "        \"lt\": \"54.50\"\n",
      "      },\n",
      "      {\n",
      "        \"gte\": \"54.50\",\n",
      "        \"lt\": \"55.00\"\n",
      "      },\n",
      "      {\n",
      "        \"gte\": \"55.00\",\n",
      "        \"lt\": \"55.50\"\n",
      "      },\n",
      "      {\n",
      "        \"gte\": \"55.50\",\n",
      "        \"lt\": \"56.00\"\n",
      "      },\n",
      "      {\n",
      "        \"gte\": \"56.00\",\n",
      "        \"lt\": \"56.50\"\n",
      "      },\n",
      "      {\n",
      "        \"gte\": \"56.50\",\n",
      "        \"lt\": \"57.00\"\n",
      "      },\n",
      "      {\n",
      "        \"gte\": \"57.00\",\n",
      "        \"lt\": \"57.50\"\n",
      "      },\n",
      "      {\n",
      "        \"gte\": \"57.50\",\n",
      "        \"lt\": \"58.00\"\n",
      "      },\n",
      "      {\n",
      "        \"gte\": \"58.00\",\n",
      "        \"lt\": \"58.50\"\n",
      "      },\n",
      "      {\n",
      "        \"gte\": \"58.50\",\n",
      "        \"lt\": \"59.00\"\n",
      "      },\n",
      "      {\n",
      "        \"gte\": \"59.00\",\n",
      "        \"lt\": \"59.50\"\n",
      "      },\n",
      "      {\n",
      "        \"gte\": \"59.50\",\n",
      "        \"lt\": \"60.00\"\n",
      "      }\n",
      "    ],\n",
      "    \"total_ranges\": 22\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Let's inspect a sample output from each strategy\n",
    "for strategy_name in ACTIVE_STRATEGIES:\n",
    "    if results[strategy_name]:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Sample output for {strategy_name.upper()}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        sample = results[strategy_name][0]\n",
    "        print(json.dumps(sample, indent=2))\n",
    "        break  # Show just one example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9c20d2",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "The pagination plans have been generated and saved to `processing/1_strategy/<timestamp>/`.\n",
    "\n",
    "Each strategy creates a subdirectory with JSON files for each table containing:\n",
    "- **table_id**: Unique identifier\n",
    "- **strategy**: The pagination approach used\n",
    "- **metadata**: Table information (title, columns, keys)\n",
    "- **pagination_config**: Strategy-specific configuration for the fetch notebook\n",
    "\n",
    "### For the next notebook (2_FetchPages.ipynb):\n",
    "1. Load these JSON files\n",
    "2. For each pagination plan, execute the appropriate fetching logic for all three range-based configs:\n",
    "   - **range_based**: Use pagination_config_alphabetic, pagination_config_semantic, and pagination_config_unrestricted to fetch data in buckets\n",
    "   - For alphabetic: Use ranges with gte/lt for letter ranges\n",
    "   - For semantic: Use ranges with category for semantic groups  \n",
    "   - For unrestricted: Use ranges with gte/lt for any type of ranges (benchmark reference)\n",
    "\n",
    "### To enable more strategies:\n",
    "Uncomment the strategies you want in the `ACTIVE_STRATEGIES` list above and re-run the notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
