{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a07c4455",
   "metadata": {},
   "source": [
    "# Stage 3: Fetch Pages\n",
    "\n",
    "\n",
    "This notebook implements the third stage of the pipeline: fetching pages using LLMs, recording metrics, and saving results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74912bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f70d826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pagination folder: processing/1_pagination/20250903_223321\n"
     ]
    }
   ],
   "source": [
    "# Identify Latest Folder Under Pagination\n",
    "pagination_root = 'processing/1_pagination/'\n",
    "folders = [f for f in os.listdir(pagination_root) if os.path.isdir(os.path.join(pagination_root, f))]\n",
    "latest_folder = sorted(folders)[-1] if folders else None\n",
    "pagination_path = os.path.join(pagination_root, latest_folder) if latest_folder else None\n",
    "assert pagination_path and os.path.exists(pagination_path), 'No pagination folder found.'\n",
    "print('Using pagination folder:', pagination_path)\n",
    "\n",
    "# INCREMENT MODE: Build a set of already processed table IDs/names\n",
    "INCREMENT_MODE = False  # Set to False for normal full run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ed3ce2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 26 tables.\n"
     ]
    }
   ],
   "source": [
    "# Load Pagination Criteria\n",
    "json_files = glob.glob(os.path.join(pagination_path, '*.json'))\n",
    "tables = []\n",
    "for jf in json_files:\n",
    "    with open(jf, 'r') as f:\n",
    "        obj = json.load(f)\n",
    "    tables.append({'path': jf, 'meta': obj['meta'], 'criteria': obj['pagination_criteria']})\n",
    "print(f'Loaded {len(tables)} tables.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fcb997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class TableGenerator_JSON():\n",
    "    TEMPLATE = \"\"\"\n",
    "    List %s - as many as possible to fit into response.\n",
    "    The response will be formatted as JSON.\n",
    "    Each element of the response will contain %d fields: %s.\n",
    "    Do not output any additional text that is not in JSON format.\n",
    "    %s\n",
    "    \n",
    "    \"\"\"   \n",
    "\n",
    "    def _norm_field(self, s):\n",
    "        s = s.lower().replace(\" \",\"_\").replace(\"-\",\"_\").replace(\".\", \"\").replace(\",\",\"_\")\\\n",
    "                .replace(\"(\", \"\").replace(\")\", \"\").replace(\":\", \"\").replace('\"','').replace(\"'\",\"\")\\\n",
    "                .replace(\"/\", \"\")\n",
    "        return re.sub('_+', '_', s)\n",
    "        \n",
    "    def generate_prompts(self, query, fields, paging: dict | None):\n",
    "        system_msg = \"You are a retriever of facts.\"\n",
    "\n",
    "        num_fields = len(fields)\n",
    "        fields_json = []\n",
    "        fields = [f for f in fields]\n",
    "        for field in fields:\n",
    "            fields_json.append('\"%s\": \"%s\"' % ('_'.join(field.replace(\"-\", \" \").split()), field))\n",
    "        response_format = ', '.join(fields)\n",
    "        if paging:\n",
    "            paging_criteria = ('Only fetch the results where values for %s match: %s.' % (paging['field'], paging['value']))\n",
    "        else:\n",
    "            paging_criteria = ''\n",
    "        user_msg = self.TEMPLATE % (query, num_fields, response_format, paging_criteria)\n",
    "        return system_msg, user_msg\n",
    "\n",
    "    def parse_llm_response(self, response): \n",
    "        res = []\n",
    "        try:\n",
    "            if not response.startswith(\"[\") and \"[\" in response:\n",
    "                response = response[response.find(\"[\"):]\n",
    "\n",
    "            if not response.endswith(\"]\") and \"]\" in response:\n",
    "                response = response[:response.rfind(\"]\")+1]\n",
    "\n",
    "            if '[' not in response and ']' not in response and '{' in response and '}' in response:\n",
    "                response = '[' + response + ']'    \n",
    "\n",
    "            response_json = json.loads(response)\n",
    "\n",
    "            if isinstance(response_json, dict) and len(response_json.keys()) == 1:\n",
    "                response_json = list(response_json.values())[0]    \n",
    "        except:  \n",
    "            split_response = response.split(\"{\")\n",
    "            response_json = []\n",
    "            for s in split_response[1:]:\n",
    "                split_s = s.split(\"}\")\n",
    "                if len(split_s) > 1:\n",
    "                    content = split_s[0]\n",
    "                    attributes = content.split(\",\")\n",
    "                    elements = {}\n",
    "                    for attr in attributes:\n",
    "                        knv = attr.split(\":\")   \n",
    "                        if len(knv) > 1:\n",
    "                            parsed_k = \"%s\" % knv[0].replace('\"','').strip()\n",
    "                            parsed_v = \"%s\" % knv[1].replace('\"','').strip()\n",
    "                            elements[parsed_k] = parsed_v\n",
    "\n",
    "                    response_json.append(elements)  \n",
    "\n",
    "        df = pd.DataFrame.from_records(response_json) \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "604a0e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(merged_df, source_columns, metrics, source_df):\n",
    "    row_count = len(merged_df) if merged_df is not None else 0\n",
    "    col_consistency = (set(merged_df.columns) == set(source_columns)) if source_columns and not merged_df.empty else None\n",
    "    error_count = sum(1 for m in metrics if m['error'])\n",
    "    total_pages = len(metrics)\n",
    "    error_rate = error_count / total_pages if total_pages > 0 else None\n",
    "    latencies = [m['latency'] for m in metrics if m['latency'] is not None]\n",
    "    avg_latency = sum(latencies) / len(latencies) if latencies else None\n",
    "    token_counts = [m['usage'].get('total_tokens', 0) for m in metrics if m['usage'] and 'total_tokens' in m['usage']]\n",
    "    sum_tokens = sum(token_counts) if token_counts else None\n",
    "    acc_metrics = None\n",
    "    if source_df is not None and not merged_df.empty:\n",
    "        acc_metrics = accuracy_metrics(merged_df, source_df)\n",
    "    return {\n",
    "        'row_count': row_count,\n",
    "        'column_consistency': col_consistency,\n",
    "        'error_rate': error_rate,\n",
    "        'avg_latency': avg_latency,\n",
    "        'sum_tokens': sum_tokens,\n",
    "        'accuracy': acc_metrics\n",
    "    }\n",
    "\n",
    "# Accuracy metric functions (from old/2_Metrics_calculation.ipynb)\n",
    "def accuracy_metrics(merged_df, source_df):\n",
    "    # Only compare columns present in both\n",
    "    common_cols = [col for col in source_df.columns if col in merged_df.columns]\n",
    "    # Cast all columns to string for comparison\n",
    "    src = source_df[common_cols].drop_duplicates().reset_index(drop=True).astype(str)\n",
    "    pred = merged_df[common_cols].drop_duplicates().reset_index(drop=True).astype(str)\n",
    "    # Row-level accuracy: fraction of source rows present in merged\n",
    "    correct_rows = src.merge(pred, how='inner').shape[0]\n",
    "    total_rows = src.shape[0]\n",
    "    row_recall = correct_rows / total_rows if total_rows > 0 else None\n",
    "    # Precision: fraction of merged rows that are correct\n",
    "    correct_pred_rows = pred.merge(src, how='inner').shape[0]\n",
    "    total_pred_rows = pred.shape[0]\n",
    "    row_precision = correct_pred_rows / total_pred_rows if total_pred_rows > 0 else None\n",
    "    # F1 score\n",
    "    if row_precision is not None and row_recall is not None and (row_precision + row_recall) > 0:\n",
    "        row_f1 = 2 * row_precision * row_recall / (row_precision + row_recall)\n",
    "    else:\n",
    "        row_f1 = None\n",
    "    return {\n",
    "        'row_recall': row_recall,\n",
    "        'row_precision': row_precision,\n",
    "        'row_f1': row_f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ec1f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_page_llm(prompt, model, api_key, system_msg: str = ''):\n",
    "    url = 'https://openrouter.ai/api/v1/chat/completions'\n",
    "    headers = {'Authorization': f'Bearer {api_key}', 'Content-Type': 'application/json'}\n",
    "    payload = {\n",
    "        'model': model,\n",
    "        'messages': [\n",
    "            {'role': 'system', 'content': system_msg},\n",
    "            {'role': 'user', 'content': prompt}\n",
    "        ],\n",
    "        'max_tokens': 20000\n",
    "    }\n",
    "    start = time.time()\n",
    "    try:\n",
    "        resp = requests.post(url, headers=headers, json=payload, timeout=LLM_TIMEOUT)\n",
    "        latency = time.time() - start\n",
    "        resp.raise_for_status()\n",
    "        result = resp.json()\n",
    "        raw_response = result['choices'][0]['message']['content'] if 'choices' in result else ''\n",
    "        content = table_generator.parse_llm_response(raw_response)\n",
    "        usage = result.get('usage', {})\n",
    "        return content, latency, usage, None, raw_response\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to fetch page: {e}\")\n",
    "        return None, None, None, str(e), None\n",
    "\n",
    "def fetch_page_task(args):\n",
    "    # args: (meta, crit_obj, page_key, model_name, source_columns, source_csv_str)\n",
    "    meta, crit_obj, page_key, model_name, source_columns, source_csv_str = args\n",
    "    page_content = {'field': crit_obj.get('criteria',''), 'value': page_key} if page_key != 'ALL' else None\n",
    "    system_msg, user_msg = table_generator.generate_prompts(meta.get('query_without_cutoff'), source_columns, page_content)\n",
    "    if PROVIDE_SOURCE_TABLE and source_csv_str:\n",
    "        user_msg += f\"\\n\\nSource table as CSV:\\n{source_csv_str}\"\n",
    "    print(f\"[FETCH] Table: {meta.get('name')}, Page: {page_content}, Model: {model_name}\")\n",
    "    content, latency, usage, error, raw_response = fetch_page_llm(user_msg, LLM_MODEL, OPENROUTER_API_KEY, system_msg)\n",
    "    return {\n",
    "        'content': content,\n",
    "        'latency': latency,\n",
    "        'usage': usage,\n",
    "        'error': error,\n",
    "        'page_key': page_key,\n",
    "        'raw_response': raw_response\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bad1417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FULL RUN] Using new output folder: processing/2_fetched_pages/20250904_215438\n",
      "[PROCESSING] Table: english_latin_rivalry_1887_2012, Source Columns: ['Year', 'Latin', 'English', 'Winner']\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/25_english_latin_rivalry_1887_2012_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/25_english_latin_rivalry_1887_2012_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 0}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 4}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 5}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 6}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 10}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 12}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 22}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 23}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/25_english_latin_rivalry_1887_2012_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/25_english_latin_rivalry_1887_2012_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 0}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 4}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 5}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 6}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 10}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 12}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 22}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 23}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 44}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 44}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/25_english_latin_rivalry_1887_2012_statistical_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/25_english_latin_rivalry_1887_2012_statistical_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1890-1910'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1911-1930'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1931-1950'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1951-1970'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1971-2005'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/25_english_latin_rivalry_1887_2012_statistical_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/25_english_latin_rivalry_1887_2012_statistical_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1890-1910'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1911-1930'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1931-1950'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1951-1970'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1971-2005'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/25_english_latin_rivalry_1887_2012_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/25_english_latin_rivalry_1887_2012_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1890s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1900s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1910s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1920s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1930s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1940s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1950s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1960s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/25_english_latin_rivalry_1887_2012_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/25_english_latin_rivalry_1887_2012_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1890s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1900s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1910s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1920s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1930s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1940s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1950s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1960s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1970s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1970s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1980s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1980s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1990s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1990s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '2000s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '2000s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/25_english_latin_rivalry_1887_2012_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/25_english_latin_rivalry_1887_2012_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1891-1900'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1901-1910'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1911-1920'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1921-1930'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1931-1940'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1941-1950'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1951-1960'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1961-2004'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/25_english_latin_rivalry_1887_2012_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/25_english_latin_rivalry_1887_2012_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1891-1900'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1901-1910'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1911-1920'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1921-1930'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1931-1940'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1941-1950'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1951-1960'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1961-2004'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/25_english_latin_rivalry_1887_2012_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/25_english_latin_rivalry_1887_2012_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/25_english_latin_rivalry_1887_2012_metrics.json\n",
      "[PROCESSING] Table: australia_demographics_1900_2010, Source Columns: ['Year', 'Average population (x 1,000)', 'Live births', 'Deaths', 'Natural change', 'Crude birth rate (per 1,000)', 'Crude death rate (per 1,000)', 'Natural change (per 1,000)', 'Fertility rates']\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/25_english_latin_rivalry_1887_2012_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/25_english_latin_rivalry_1887_2012_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/25_english_latin_rivalry_1887_2012_metrics.json\n",
      "[PROCESSING] Table: australia_demographics_1900_2010, Source Columns: ['Year', 'Average population (x 1,000)', 'Live births', 'Deaths', 'Natural change', 'Crude birth rate (per 1,000)', 'Crude death rate (per 1,000)', 'Natural change (per 1,000)', 'Fertility rates']\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: None, Model: openai_gpt-4o-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_24893/3314864075.py:117: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/3_australia_demographics_1900_2010_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/3_australia_demographics_1900_2010_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': 'NaN'}, Model: openai_gpt-4o-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_24893/3314864075.py:117: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/3_australia_demographics_1900_2010_statistical_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/3_australia_demographics_1900_2010_statistical_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1900-1919'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1920-1939'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1940-1959'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1960-1979'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1980-2009'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/3_australia_demographics_1900_2010_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/3_australia_demographics_1900_2010_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1900-1919'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1920-1939'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1940-1959'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1960-1979'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1980-2009'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/3_australia_demographics_1900_2010_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/3_australia_demographics_1900_2010_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1900-1919'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1920-1939'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1940-1959'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1960-1979'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1980-2009'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/3_australia_demographics_1900_2010_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/3_australia_demographics_1900_2010_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1900-1910'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1911-1920'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1921-1930'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1931-1940'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1941-1950'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/3_australia_demographics_1900_2010_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/3_australia_demographics_1900_2010_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1900-1910'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1911-1920'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1921-1930'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1931-1940'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1941-1950'}, Model: openai_gpt-4o-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_24893/3314864075.py:117: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/3_australia_demographics_1900_2010_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/3_australia_demographics_1900_2010_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/3_australia_demographics_1900_2010_metrics.json\n",
      "[PROCESSING] Table: elements, Source Columns: ['Z', 'Sym', 'Element', 'Group', 'Period', 'Atomic weight u', 'Density g / cm 3', 'Melt K', 'Boil K', 'Heat J / g * K', 'Neg']\n",
      "[FETCH] Table: elements, Page: None, Model: openai_gpt-4o-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_24893/3314864075.py:117: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/15_elements_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/15_elements_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': 1}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': 2}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': 3}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': 4}, Model: openai_gpt-4o-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_24893/3314864075.py:117: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/15_elements_statistical_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/15_elements_statistical_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': '1'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': '2'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': '3'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': '4'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': '5'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': '6'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': '7'}, Model: google_gemini-2.5-flash-lite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_24893/3314864075.py:117: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/15_elements_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/15_elements_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': '1'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': '2'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': '3'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': '4-7'}, Model: deepseek_deepseek-chat-v3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_24893/3314864075.py:117: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/15_elements_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/15_elements_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '1.0'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '2.0'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '3.0'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '4.0'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '5.0'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '6.0'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '7.0'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '8.0'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '9.0'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '9.0'}, Model: openai_gpt-4o-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_24893/3314864075.py:117: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '10.0'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '11.0'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '11.0'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '12.0'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '12.0'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '13.0'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '13.0'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '14.0'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '14.0'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '15.0'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '15.0'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '16.0'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '16.0'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '17.0'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '17.0'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/15_elements_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/15_elements_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/15_elements_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/15_elements_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/15_elements_metrics.json\n",
      "[PROCESSING] Table: rock_band_downloadable_2011, Source Columns: ['Song title', 'Artist', 'Year', 'Genre', 'Single / Pack name', 'Release date', 'Family Friendly']\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/15_elements_metrics.json\n",
      "[PROCESSING] Table: rock_band_downloadable_2011, Source Columns: ['Song title', 'Artist', 'Year', 'Genre', 'Single / Pack name', 'Release date', 'Family Friendly']\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/12_rock_band_downloadable_2011_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/12_rock_band_downloadable_2011_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': 1955}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': 1956}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': 1958}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': 1959}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': 1961}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': 1964}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': 2006}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': 2007}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/12_rock_band_downloadable_2011_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/12_rock_band_downloadable_2011_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': 1955}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': 1956}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': 1958}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': 1959}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': 1961}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': 1964}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': 2006}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': 2007}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': 2008}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': 2008}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': 2009}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': 2009}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': 2000}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': 2000}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': 2003}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': 2003}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/12_rock_band_downloadable_2011_statistical_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/12_rock_band_downloadable_2011_statistical_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '2011'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/12_rock_band_downloadable_2011_statistical_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/12_rock_band_downloadable_2011_statistical_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '2011'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/12_rock_band_downloadable_2011_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/12_rock_band_downloadable_2011_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Release date', 'value': 'Jan-Mar 2011'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Release date', 'value': 'Apr-Jun 2011'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Release date', 'value': 'Jul-Sep 2011'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Release date', 'value': 'Oct-Dec 2011'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Release date', 'value': 'Unknown date'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/12_rock_band_downloadable_2011_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/12_rock_band_downloadable_2011_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Release date', 'value': 'Jan-Mar 2011'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Release date', 'value': 'Apr-Jun 2011'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Release date', 'value': 'Jul-Sep 2011'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Release date', 'value': 'Oct-Dec 2011'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Release date', 'value': 'Unknown date'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/12_rock_band_downloadable_2011_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/12_rock_band_downloadable_2011_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '2011'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/12_rock_band_downloadable_2011_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/12_rock_band_downloadable_2011_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '2011'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/12_rock_band_downloadable_2011_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/12_rock_band_downloadable_2011_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/12_rock_band_downloadable_2011_metrics.json\n",
      "[PROCESSING] Table: living_proof_the_farewell_tour, Source Columns: ['Date', 'City', 'Country', 'Venue']\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/12_rock_band_downloadable_2011_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/12_rock_band_downloadable_2011_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/12_rock_band_downloadable_2011_metrics.json\n",
      "[PROCESSING] Table: living_proof_the_farewell_tour, Source Columns: ['Date', 'City', 'Country', 'Venue']\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/19_living_proof_the_farewell_tour_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/19_living_proof_the_farewell_tour_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': '2002-2003'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': '2004-2005'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/19_living_proof_the_farewell_tour_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/19_living_proof_the_farewell_tour_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': '2002-2003'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': '2004-2005'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/19_living_proof_the_farewell_tour_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/19_living_proof_the_farewell_tour_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'year', 'value': '2002'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'year', 'value': '2003'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'year', 'value': '2004'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'year', 'value': '2005'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/19_living_proof_the_farewell_tour_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/19_living_proof_the_farewell_tour_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'year', 'value': '2002'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'year', 'value': '2003'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'year', 'value': '2004'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'year', 'value': '2005'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/19_living_proof_the_farewell_tour_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/19_living_proof_the_farewell_tour_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': '2002-2003'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': '2004-2005'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/19_living_proof_the_farewell_tour_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/19_living_proof_the_farewell_tour_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': '2002-2003'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': '2004-2005'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/19_living_proof_the_farewell_tour_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/19_living_proof_the_farewell_tour_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/19_living_proof_the_farewell_tour_metrics.json\n",
      "[PROCESSING] Table: portuguese_grape_varieties, Source Columns: ['Grape', 'Color']\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/19_living_proof_the_farewell_tour_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/19_living_proof_the_farewell_tour_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/19_living_proof_the_farewell_tour_metrics.json\n",
      "[PROCESSING] Table: portuguese_grape_varieties, Source Columns: ['Grape', 'Color']\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/33_portuguese_grape_varieties_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/33_portuguese_grape_varieties_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: {'field': 'Color', 'value': 'Red'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: {'field': 'Color', 'value': 'White'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/33_portuguese_grape_varieties_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/33_portuguese_grape_varieties_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: {'field': 'Color', 'value': 'Red'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: {'field': 'Color', 'value': 'White'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/33_portuguese_grape_varieties_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/33_portuguese_grape_varieties_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: {'field': 'Color', 'value': 'Red'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: {'field': 'Color', 'value': 'White'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/33_portuguese_grape_varieties_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/33_portuguese_grape_varieties_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: {'field': 'Color', 'value': 'Red'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: {'field': 'Color', 'value': 'White'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/33_portuguese_grape_varieties_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/33_portuguese_grape_varieties_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: {'field': 'Color', 'value': 'Red'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: {'field': 'Color', 'value': 'White'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/33_portuguese_grape_varieties_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/33_portuguese_grape_varieties_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: {'field': 'Color', 'value': 'Red'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: {'field': 'Color', 'value': 'White'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/33_portuguese_grape_varieties_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/33_portuguese_grape_varieties_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/33_portuguese_grape_varieties_metrics.json\n",
      "[PROCESSING] Table: republican_straw_polls_2012, Source Columns: ['Zip Code', 'Ron Paul', 'Mitt Romney', 'Gary Johnson', 'Rick Santorum', 'Virgil Goode', 'Buddy Roemer', 'Newt Gingrich', 'Barack Obama', 'Other', 'Total']\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/33_portuguese_grape_varieties_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/33_portuguese_grape_varieties_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/33_portuguese_grape_varieties_metrics.json\n",
      "[PROCESSING] Table: republican_straw_polls_2012, Source Columns: ['Zip Code', 'Ron Paul', 'Mitt Romney', 'Gary Johnson', 'Rick Santorum', 'Virgil Goode', 'Buddy Roemer', 'Newt Gingrich', 'Barack Obama', 'Other', 'Total']\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/0_republican_straw_polls_2012_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/0_republican_straw_polls_2012_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 0}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 1}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 2}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 3}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 4}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 5}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 6}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 7}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/0_republican_straw_polls_2012_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/0_republican_straw_polls_2012_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 0}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 1}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 2}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 3}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 4}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 5}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 6}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 7}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 8}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 8}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 9}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 9}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 10}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 10}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 11}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 11}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 12}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 12}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 13}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 13}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 14}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 14}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 15}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 15}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 16}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 17}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 16}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 17}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 18}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 18}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/0_republican_straw_polls_2012_statistical_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/0_republican_straw_polls_2012_statistical_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83336-83634'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/0_republican_straw_polls_2012_statistical_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/0_republican_straw_polls_2012_statistical_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83336-83634'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/0_republican_straw_polls_2012_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/0_republican_straw_polls_2012_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83000-83200'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83201-83400'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83401-83600'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83601-83800'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83801-84000'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/0_republican_straw_polls_2012_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/0_republican_straw_polls_2012_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83000-83200'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83201-83400'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83401-83600'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83601-83800'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83801-84000'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/0_republican_straw_polls_2012_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/0_republican_straw_polls_2012_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83000-83400'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83401-83800'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83801-84200'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '84201-84600'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '84601-85000'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/0_republican_straw_polls_2012_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/0_republican_straw_polls_2012_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83000-83400'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83401-83800'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83801-84200'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '84201-84600'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '84601-85000'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/0_republican_straw_polls_2012_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/0_republican_straw_polls_2012_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/0_republican_straw_polls_2012_metrics.json\n",
      "[PROCESSING] Table: miss_new_york_usa_delegates_2012, Source Columns: ['Represents', 'Candidate']\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/0_republican_straw_polls_2012_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/0_republican_straw_polls_2012_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/0_republican_straw_polls_2012_metrics.json\n",
      "[PROCESSING] Table: miss_new_york_usa_delegates_2012, Source Columns: ['Represents', 'Candidate']\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/59_miss_new_york_usa_delegates_2012_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/59_miss_new_york_usa_delegates_2012_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Central Islip'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Claremont Park'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Clifton Park'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Dutchess County'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Hollis'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Hamptons'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Kings County'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Lady Liberty'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/59_miss_new_york_usa_delegates_2012_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/59_miss_new_york_usa_delegates_2012_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Central Islip'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Claremont Park'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Clifton Park'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Dutchess County'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Hollis'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Hamptons'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Kings County'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Lady Liberty'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Lake George'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Long Island'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Lake George'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Long Island'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Manhasset'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Middle Village'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Manhasset'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Middle Village'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Miracle Miles'}, Model: google_gemini-2.5-flash-lite[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Nutrish'}, Model: google_gemini-2.5-flash-lite\n",
      "\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Miracle Miles'}, Model: google_gemini-2.5-flash-lite[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Nutrish'}, Model: google_gemini-2.5-flash-lite\n",
      "\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Project Girl'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Queens'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Project Girl'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Queens'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Statue of Liberty'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Tribeca'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Statue of Liberty'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Tribeca'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Uptown'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Uptown'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Washington Heights'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Washington Heights'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/59_miss_new_york_usa_delegates_2012_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/59_miss_new_york_usa_delegates_2012_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'All'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/59_miss_new_york_usa_delegates_2012_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/59_miss_new_york_usa_delegates_2012_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'All'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/59_miss_new_york_usa_delegates_2012_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/59_miss_new_york_usa_delegates_2012_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Washington Heights'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Clifton Park'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Miracle Miles'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Project Girl'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/59_miss_new_york_usa_delegates_2012_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/59_miss_new_york_usa_delegates_2012_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Washington Heights'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Clifton Park'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Miracle Miles'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Project Girl'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/59_miss_new_york_usa_delegates_2012_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/59_miss_new_york_usa_delegates_2012_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/59_miss_new_york_usa_delegates_2012_metrics.json\n",
      "[PROCESSING] Table: cross_country_junior_women_1996, Source Columns: ['Rank', 'Athlete', 'Country', 'Time']\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/59_miss_new_york_usa_delegates_2012_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/59_miss_new_york_usa_delegates_2012_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/59_miss_new_york_usa_delegates_2012_metrics.json\n",
      "[PROCESSING] Table: cross_country_junior_women_1996, Source Columns: ['Rank', 'Athlete', 'Country', 'Time']\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/52_cross_country_junior_women_1996_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/52_cross_country_junior_women_1996_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '1-20'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '21-40'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '41-60'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '61-80'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '81-100'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/52_cross_country_junior_women_1996_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/52_cross_country_junior_women_1996_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '1-20'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '21-40'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '41-60'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '61-80'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '81-100'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/52_cross_country_junior_women_1996_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/52_cross_country_junior_women_1996_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '1-20'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '21-40'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '41-60'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '61-80'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '81-100'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/52_cross_country_junior_women_1996_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/52_cross_country_junior_women_1996_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '1-20'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '21-40'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '41-60'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '61-80'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '81-100'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/52_cross_country_junior_women_1996_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/52_cross_country_junior_women_1996_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '1-20'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '21-40'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '41-60'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '61-80'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '81-100'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/52_cross_country_junior_women_1996_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/52_cross_country_junior_women_1996_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '1-20'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '21-40'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '41-60'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '61-80'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '81-100'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/52_cross_country_junior_women_1996_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/52_cross_country_junior_women_1996_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/52_cross_country_junior_women_1996_metrics.json\n",
      "[PROCESSING] Table: tour_de_france_2009, Source Columns: ['Rider', 'Team', 'Nationality', 'Age']\n",
      "[FETCH] Table: tour_de_france_2009, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/52_cross_country_junior_women_1996_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/52_cross_country_junior_women_1996_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/52_cross_country_junior_women_1996_metrics.json\n",
      "[PROCESSING] Table: tour_de_france_2009, Source Columns: ['Rider', 'Team', 'Nationality', 'Age']\n",
      "[FETCH] Table: tour_de_france_2009, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/9_tour_de_france_2009_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/9_tour_de_france_2009_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 23}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 24}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 25}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 26}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 27}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 28}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 29}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 30}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/9_tour_de_france_2009_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/9_tour_de_france_2009_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 23}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 24}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 25}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 26}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 27}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 28}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 29}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 30}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 31}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 31}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 32}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 33}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 32}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 33}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 34}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 37}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 34}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 37}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 40}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 40}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/9_tour_de_france_2009_statistical_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/9_tour_de_france_2009_statistical_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Lance Armstrong'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Grischa Niermann'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Christophe Moreau'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Rinaldo Nocentini'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Alexandre Botcharov'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Jurgen Van Den Broeck'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Yaroslav Popovych'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Tony Martin'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/9_tour_de_france_2009_statistical_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/9_tour_de_france_2009_statistical_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Lance Armstrong'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Grischa Niermann'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Christophe Moreau'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Rinaldo Nocentini'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Alexandre Botcharov'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Jurgen Van Den Broeck'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Yaroslav Popovych'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Tony Martin'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Christophe Kern'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Marco Bandiera'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Christophe Kern'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Marco Bandiera'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Yauheni Hutarovich'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'David Lelay'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Yauheni Hutarovich'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'David Lelay'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Maxime Monfort'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Matteo Tosatto'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Maxime Monfort'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Matteo Tosatto'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Christian Vande Velde'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Johan Van Summeren'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Danny Pate'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Christian Vande Velde'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Johan Van Summeren'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Danny Pate'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Simon Špilak'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Jérémy Roy'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Simon Špilak'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Jérémy Roy'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Koldo Fernández'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Rider', 'value': 'Koldo Fernández'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/9_tour_de_france_2009_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/9_tour_de_france_2009_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Astana'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Rabobank'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Agritubel'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Ag2r-La Mondiale'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Team Katusha'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Silence-Lotto'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Team Columbia-HTC'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Cofidis'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/9_tour_de_france_2009_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/9_tour_de_france_2009_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Astana'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Rabobank'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Agritubel'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Ag2r-La Mondiale'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Team Katusha'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Silence-Lotto'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Team Columbia-HTC'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Cofidis'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Lampre-NGC'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Lampre-NGC'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Française des Jeux'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Française des Jeux'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Quick Step'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Quick Step'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Garmin-Slipstream'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Garmin-Slipstream'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Euskaltel-Euskadi'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Euskaltel-Euskadi'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/9_tour_de_france_2009_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/9_tour_de_france_2009_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Nationality', 'value': 'United States'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Nationality', 'value': 'Germany'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Nationality', 'value': 'France'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Nationality', 'value': 'Italy'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Nationality', 'value': 'Others'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/9_tour_de_france_2009_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/9_tour_de_france_2009_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Nationality', 'value': 'United States'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Nationality', 'value': 'Germany'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Nationality', 'value': 'France'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Nationality', 'value': 'Italy'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Nationality', 'value': 'Others'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/9_tour_de_france_2009_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/9_tour_de_france_2009_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/9_tour_de_france_2009_metrics.json\n",
      "[PROCESSING] Table: anaheim_ducks_draft_picks_1998_2013, Source Columns: ['Draft', 'Round', 'Pick', 'Player', 'Nationality', 'Pos', 'RS', 'PO']\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/9_tour_de_france_2009_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/9_tour_de_france_2009_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/9_tour_de_france_2009_metrics.json\n",
      "[PROCESSING] Table: anaheim_ducks_draft_picks_1998_2013, Source Columns: ['Draft', 'Round', 'Pick', 'Player', 'Nationality', 'Pos', 'RS', 'PO']\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/7_anaheim_ducks_draft_picks_1998_2013_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/7_anaheim_ducks_draft_picks_1998_2013_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1993'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1994'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/7_anaheim_ducks_draft_picks_1998_2013_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/7_anaheim_ducks_draft_picks_1998_2013_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1993'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1994'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/7_anaheim_ducks_draft_picks_1998_2013_statistical_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/7_anaheim_ducks_draft_picks_1998_2013_statistical_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1994-1999'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '2000-2005'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '2006-2012'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/7_anaheim_ducks_draft_picks_1998_2013_statistical_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/7_anaheim_ducks_draft_picks_1998_2013_statistical_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1994-1999'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '2000-2005'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '2006-2012'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/7_anaheim_ducks_draft_picks_1998_2013_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/7_anaheim_ducks_draft_picks_1998_2013_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1994-1996'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1998-1999'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '2001-2004'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '2005-2007'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '2009-2012'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/7_anaheim_ducks_draft_picks_1998_2013_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/7_anaheim_ducks_draft_picks_1998_2013_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1994-1996'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1998-1999'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '2001-2004'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '2005-2007'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '2009-2012'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/7_anaheim_ducks_draft_picks_1998_2013_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/7_anaheim_ducks_draft_picks_1998_2013_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1994-1999'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '2000-2005'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '2006-2011'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '2012-2017'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '2018-2023'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/7_anaheim_ducks_draft_picks_1998_2013_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/7_anaheim_ducks_draft_picks_1998_2013_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1994-1999'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '2000-2005'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '2006-2011'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '2012-2017'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '2018-2023'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/7_anaheim_ducks_draft_picks_1998_2013_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/7_anaheim_ducks_draft_picks_1998_2013_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/7_anaheim_ducks_draft_picks_1998_2013_metrics.json\n",
      "[PROCESSING] Table: belgium_demographics_1900_2011, Source Columns: ['Year', 'Average population (x 1,000)', 'Live births', 'Deaths', 'Natural change', 'Crude birth rate (per 1,000)', 'Crude death rate (per 1,000)', 'Natural change (per 1,000)', 'Fertility rates']\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/7_anaheim_ducks_draft_picks_1998_2013_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/7_anaheim_ducks_draft_picks_1998_2013_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/7_anaheim_ducks_draft_picks_1998_2013_metrics.json\n",
      "[PROCESSING] Table: belgium_demographics_1900_2011, Source Columns: ['Year', 'Average population (x 1,000)', 'Live births', 'Deaths', 'Natural change', 'Crude birth rate (per 1,000)', 'Crude death rate (per 1,000)', 'Natural change (per 1,000)', 'Fertility rates']\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: None, Model: openai_gpt-4o-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_24893/3314864075.py:117: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/2_belgium_demographics_1900_2011_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/2_belgium_demographics_1900_2011_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': '11.2-12.9'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': '13.0-14.9'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': '15.0-16.9'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': '17.0-18.9'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': '19.0-20.9'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': '21.0-22.9'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': '23.0-24.9'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': '25.0-26.9'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': '27.0-28.9'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': '27.0-28.9'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': '29.0-30.9'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': '29.0-30.9'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/2_belgium_demographics_1900_2011_statistical_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/2_belgium_demographics_1900_2011_statistical_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '1900-1910'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '1911-1920'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '1921-1930'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '1940-1950'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '1951-1960'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '1961-1970'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '1971-1980'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '1981-2003'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/2_belgium_demographics_1900_2011_statistical_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/2_belgium_demographics_1900_2011_statistical_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '1900-1910'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '1911-1920'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '1921-1930'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '1940-1950'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '1951-1960'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '1961-1970'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '1971-1980'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '1981-2003'}, Model: google_gemini-2.5-flash-lite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_24893/3314864075.py:117: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/2_belgium_demographics_1900_2011_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/2_belgium_demographics_1900_2011_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '1900-1919'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '1920-1939'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '1940-1959'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '1960-1979'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '1980-2003'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/2_belgium_demographics_1900_2011_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/2_belgium_demographics_1900_2011_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '1900-1940'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '1941-1960'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '1961-1980'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '1981-2000'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '2001-2020'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/2_belgium_demographics_1900_2011_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/2_belgium_demographics_1900_2011_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '1900-1940'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '1941-1960'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '1961-1980'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '1981-2000'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Year', 'value': '2001-2020'}, Model: openai_gpt-4o-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_24893/3314864075.py:117: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n",
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_24893/3314864075.py:117: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n",
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_24893/3314864075.py:117: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/2_belgium_demographics_1900_2011_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/2_belgium_demographics_1900_2011_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/2_belgium_demographics_1900_2011_metrics.json\n",
      "[PROCESSING] Table: men_butterfly_100m_2009, Source Columns: ['Name', 'Nationality', 'Time', 'Heat', 'Lane']\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/10_men_butterfly_100m_2009_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/10_men_butterfly_100m_2009_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Lane', 'value': 1}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Lane', 'value': 2}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Lane', 'value': 3}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Lane', 'value': 4}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Lane', 'value': 5}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Lane', 'value': 6}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Lane', 'value': 7}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Lane', 'value': 8}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/10_men_butterfly_100m_2009_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/10_men_butterfly_100m_2009_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Lane', 'value': 1}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Lane', 'value': 2}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Lane', 'value': 3}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Lane', 'value': 4}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Lane', 'value': 5}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Lane', 'value': 6}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Lane', 'value': 7}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Lane', 'value': 8}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Lane', 'value': 9}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Lane', 'value': 9}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/10_men_butterfly_100m_2009_statistical_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/10_men_butterfly_100m_2009_statistical_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '1'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '3'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '5'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '6'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '7'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/10_men_butterfly_100m_2009_statistical_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/10_men_butterfly_100m_2009_statistical_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '1'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '3'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '5'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '6'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '7'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/10_men_butterfly_100m_2009_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/10_men_butterfly_100m_2009_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '1-4'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '5-8'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '9-12'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '13-16'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '17'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/10_men_butterfly_100m_2009_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/10_men_butterfly_100m_2009_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '1-4'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '5-8'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '9-12'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '13-16'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '17'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/10_men_butterfly_100m_2009_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/10_men_butterfly_100m_2009_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '1'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '2'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '3'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '4'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '5'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '6'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '7'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '8'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/10_men_butterfly_100m_2009_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/10_men_butterfly_100m_2009_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '1'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '2'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '3'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '4'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '5'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '6'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '7'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '8'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '9'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '9'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '10'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '10'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '11'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '11'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '12'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '12'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '13'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '14'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '13'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '14'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '15'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '16'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '15'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '16'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '17'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: men_butterfly_100m_2009, Page: {'field': 'Heat', 'value': '17'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/10_men_butterfly_100m_2009_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/10_men_butterfly_100m_2009_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/10_men_butterfly_100m_2009_metrics.json\n",
      "[PROCESSING] Table: tennessee_vanderbilt_rivalry_1900_2012, Source Columns: ['Year', 'Location', 'Winner', 'Tennessee', 'Vanderbilt']\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/10_men_butterfly_100m_2009_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/10_men_butterfly_100m_2009_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/10_men_butterfly_100m_2009_metrics.json\n",
      "[PROCESSING] Table: tennessee_vanderbilt_rivalry_1900_2012, Source Columns: ['Year', 'Location', 'Winner', 'Tennessee', 'Vanderbilt']\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/29_tennessee_vanderbilt_rivalry_1900_2012_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/29_tennessee_vanderbilt_rivalry_1900_2012_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 0}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 1}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 2}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 3}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 4}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 5}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 6}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 7}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/29_tennessee_vanderbilt_rivalry_1900_2012_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/29_tennessee_vanderbilt_rivalry_1900_2012_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 0}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 1}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 2}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 3}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 4}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 5}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 6}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 7}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 8}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 8}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 9}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 9}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 10}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 11}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 10}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 11}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 12}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 12}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 13}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 13}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 14}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 14}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 15}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 16}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 15}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 16}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 17}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 18}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 17}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 18}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 19}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 19}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 20}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 20}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 21}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 22}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 21}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 22}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 23}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 23}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 24}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 24}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 25}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 25}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 26}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 27}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 26}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 27}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 28}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 28}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 29}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 29}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 30}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 31}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 30}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 31}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 32}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 33}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 32}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 33}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 34}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 34}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 35}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 35}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 36}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 36}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 37}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 37}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 38}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 39}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 38}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 39}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 40}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 40}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 41}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 42}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 41}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 42}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 43}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 43}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 44}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 44}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 45}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 46}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 47}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 45}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 46}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 47}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 48}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 48}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 49}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 49}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 50}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 50}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 51}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 51}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 52}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 53}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 52}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 53}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 54}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 54}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 55}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 55}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 56}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 56}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 57}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 57}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 58}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 58}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 59}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 59}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 60}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 60}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 61}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 61}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 62}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 62}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 63}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 63}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 64}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 64}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 65}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 65}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 66}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 67}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 66}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 67}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 68}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 68}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 69}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 69}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 70}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 70}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 71}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 71}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 72}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 72}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 73}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 73}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 74}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 75}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 74}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 75}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 76}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Vanderbilt', 'value': 76}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/29_tennessee_vanderbilt_rivalry_1900_2012_statistical_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/29_tennessee_vanderbilt_rivalry_1900_2012_statistical_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1900-1919'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1920-1939'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1940-1959'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1960-1979'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1980-2012'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/29_tennessee_vanderbilt_rivalry_1900_2012_statistical_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/29_tennessee_vanderbilt_rivalry_1900_2012_statistical_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1900-1919'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1920-1939'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1940-1959'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1960-1979'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1980-2012'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/29_tennessee_vanderbilt_rivalry_1900_2012_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/29_tennessee_vanderbilt_rivalry_1900_2012_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1900-1919'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1920-1939'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1940-1959'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1960-1979'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1980-1999'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '2000-2019'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/29_tennessee_vanderbilt_rivalry_1900_2012_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/29_tennessee_vanderbilt_rivalry_1900_2012_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1900-1919'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1920-1939'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1940-1959'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1960-1979'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1980-1999'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '2000-2019'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/29_tennessee_vanderbilt_rivalry_1900_2012_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/29_tennessee_vanderbilt_rivalry_1900_2012_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1900-1910'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1911-1920'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1921-1930'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1931-1940'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1941-2012'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/29_tennessee_vanderbilt_rivalry_1900_2012_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/29_tennessee_vanderbilt_rivalry_1900_2012_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1900-1910'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1911-1920'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1921-1930'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1931-1940'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tennessee_vanderbilt_rivalry_1900_2012, Page: {'field': 'Year', 'value': '1941-2012'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/29_tennessee_vanderbilt_rivalry_1900_2012_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/29_tennessee_vanderbilt_rivalry_1900_2012_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/29_tennessee_vanderbilt_rivalry_1900_2012_metrics.json\n",
      "[PROCESSING] Table: ice_hockey_2006, Source Columns: ['Country', 'Player name', 'GP', 'G', 'A', 'Pts', 'PIM']\n",
      "[FETCH] Table: ice_hockey_2006, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/29_tennessee_vanderbilt_rivalry_1900_2012_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/29_tennessee_vanderbilt_rivalry_1900_2012_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/29_tennessee_vanderbilt_rivalry_1900_2012_metrics.json\n",
      "[PROCESSING] Table: ice_hockey_2006, Source Columns: ['Country', 'Player name', 'GP', 'G', 'A', 'Pts', 'PIM']\n",
      "[FETCH] Table: ice_hockey_2006, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/5_ice_hockey_2006_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/5_ice_hockey_2006_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'GP', 'value': 5}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/5_ice_hockey_2006_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/5_ice_hockey_2006_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'GP', 'value': 5}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/5_ice_hockey_2006_statistical_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/5_ice_hockey_2006_statistical_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Canada'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Czech Republic'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Finland'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Germany'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Italy'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Kazakhstan'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Latvia'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Russia'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/5_ice_hockey_2006_statistical_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/5_ice_hockey_2006_statistical_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Canada'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Czech Republic'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Finland'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Germany'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Italy'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Kazakhstan'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Latvia'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Russia'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Slovakia'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Slovakia'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Sweden'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Sweden'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Switzerland'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Switzerland'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'United States'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'United States'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/5_ice_hockey_2006_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/5_ice_hockey_2006_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Canada'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Czech Republic'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Finland'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Germany'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Italy'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Kazakhstan'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Latvia'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Russia'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/5_ice_hockey_2006_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/5_ice_hockey_2006_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Canada'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Czech Republic'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Finland'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Germany'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Italy'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Kazakhstan'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Latvia'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Russia'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Slovakia'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Sweden'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Slovakia'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Sweden'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Switzerland'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Switzerland'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'United States'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'United States'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/5_ice_hockey_2006_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/5_ice_hockey_2006_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Czech Republic'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Canada'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Russia'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Switzerland'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Sweden'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Slovakia'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Latvia'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Italy'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/5_ice_hockey_2006_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/5_ice_hockey_2006_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Czech Republic'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Canada'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Russia'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Switzerland'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Sweden'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Slovakia'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Latvia'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Italy'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Finland'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Finland'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'United States'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'United States'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Kazakhstan'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Kazakhstan'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Germany'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ice_hockey_2006, Page: {'field': 'Country', 'value': 'Germany'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/5_ice_hockey_2006_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/5_ice_hockey_2006_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/5_ice_hockey_2006_metrics.json\n",
      "[PROCESSING] Table: scottish_football_transfers_summer_2011, Source Columns: ['Name', 'Moving from', 'Moving to']\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/5_ice_hockey_2006_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/5_ice_hockey_2006_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/5_ice_hockey_2006_metrics.json\n",
      "[PROCESSING] Table: scottish_football_transfers_summer_2011, Source Columns: ['Name', 'Moving from', 'Moving to']\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/17_scottish_football_transfers_summer_2011_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/17_scottish_football_transfers_summer_2011_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Aberdeen'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Brora Rangers'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Cumnock Juniors'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Cowdenbeath'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Dunfermline Athletic'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Elgin City'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Greenock Morton'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Hibernian'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/17_scottish_football_transfers_summer_2011_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/17_scottish_football_transfers_summer_2011_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Aberdeen'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Brora Rangers'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Cumnock Juniors'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Cowdenbeath'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Dunfermline Athletic'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Elgin City'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Greenock Morton'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Hibernian'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Inverness Caledonian Thistle'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Inverness Caledonian Thistle'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Kilmarnock'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Kirkintilloch Rob Roy'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Kilmarnock'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Kirkintilloch Rob Roy'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Motherwell'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Motherwell'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Oxford United'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Oxford United'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Perth Glory'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Rangers'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Perth Glory'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Rangers'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'St. Johnstone'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'St. Johnstone'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Torquay United'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving to', 'value': 'Torquay United'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/17_scottish_football_transfers_summer_2011_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/17_scottish_football_transfers_summer_2011_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'first_letter_of_Name', 'value': 'A-D'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'first_letter_of_Name', 'value': 'E-H'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'first_letter_of_Name', 'value': 'I-L'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'first_letter_of_Name', 'value': 'M-P'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'first_letter_of_Name', 'value': 'Q-Z'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/17_scottish_football_transfers_summer_2011_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/17_scottish_football_transfers_summer_2011_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'first_letter_of_Name', 'value': 'A-D'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'first_letter_of_Name', 'value': 'E-H'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'first_letter_of_Name', 'value': 'I-L'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'first_letter_of_Name', 'value': 'M-P'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'first_letter_of_Name', 'value': 'Q-Z'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/17_scottish_football_transfers_summer_2011_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/17_scottish_football_transfers_summer_2011_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Ayr United'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'St. Johnstone'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Dundee'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Crawley Town'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Milton Keynes Dons'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Manchester City'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Ross County'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Dumbarton'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/17_scottish_football_transfers_summer_2011_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/17_scottish_football_transfers_summer_2011_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Ayr United'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'St. Johnstone'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Dundee'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Crawley Town'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Milton Keynes Dons'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Manchester City'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Ross County'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Dumbarton'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Doncaster Rovers'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Doncaster Rovers'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Hibernian'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Hibernian'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Raith Rovers'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Falkirk'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Raith Rovers'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Falkirk'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Heart of Midlothian'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Blackburn Rovers'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Heart of Midlothian'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Blackburn Rovers'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Kilmarnock'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Unattached'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Kilmarnock'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: scottish_football_transfers_summer_2011, Page: {'field': 'Moving from', 'value': 'Unattached'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/17_scottish_football_transfers_summer_2011_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/17_scottish_football_transfers_summer_2011_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/17_scottish_football_transfers_summer_2011_metrics.json\n",
      "[PROCESSING] Table: udaykumar_films, Source Columns: ['Year', 'Film', 'Director']\n",
      "[FETCH] Table: udaykumar_films, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/17_scottish_football_transfers_summer_2011_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/17_scottish_football_transfers_summer_2011_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/17_scottish_football_transfers_summer_2011_metrics.json\n",
      "[PROCESSING] Table: udaykumar_films, Source Columns: ['Year', 'Film', 'Director']\n",
      "[FETCH] Table: udaykumar_films, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/31_udaykumar_films_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/31_udaykumar_films_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': 1956}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': 1957}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': 1958}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': 1959}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': 1960}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/31_udaykumar_films_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/31_udaykumar_films_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': 1956}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': 1957}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': 1958}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': 1959}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': 1960}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/31_udaykumar_films_statistical_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/31_udaykumar_films_statistical_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': '1960-1963'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': '1965-1967'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': '1969-1971'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': '1977'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': '1980-1982'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/31_udaykumar_films_statistical_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/31_udaykumar_films_statistical_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': '1960-1963'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': '1965-1967'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': '1969-1971'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': '1977'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': '1980-1982'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/31_udaykumar_films_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/31_udaykumar_films_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': '1960-1967'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': '1968-1975'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': '1976-1982'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/31_udaykumar_films_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/31_udaykumar_films_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': '1960-1967'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': '1968-1975'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': '1976-1982'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/31_udaykumar_films_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/31_udaykumar_films_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': '1960-1965'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': '1966-1970'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': '1971-1975'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': '1976-1980'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/31_udaykumar_films_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/31_udaykumar_films_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': '1960-1965'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': '1966-1970'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': '1971-1975'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: udaykumar_films, Page: {'field': 'Year', 'value': '1976-1980'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/31_udaykumar_films_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/31_udaykumar_films_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/31_udaykumar_films_metrics.json\n",
      "[PROCESSING] Table: ramsar_convention_parties, Source Columns: ['Country', 'Entry date', 'Ramsar sites']\n",
      "[FETCH] Table: ramsar_convention_parties, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/31_udaykumar_films_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/31_udaykumar_films_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/31_udaykumar_films_metrics.json\n",
      "[PROCESSING] Table: ramsar_convention_parties, Source Columns: ['Country', 'Entry date', 'Ramsar sites']\n",
      "[FETCH] Table: ramsar_convention_parties, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/34_ramsar_convention_parties_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/34_ramsar_convention_parties_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Ramsar sites', 'value': 1.0}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Ramsar sites', 'value': 2.0}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Ramsar sites', 'value': 3.0}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Ramsar sites', 'value': 4.0}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Ramsar sites', 'value': 9.0}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Ramsar sites', 'value': 11.0}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Ramsar sites', 'value': 20.0}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Ramsar sites', 'value': 21.0}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/34_ramsar_convention_parties_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/34_ramsar_convention_parties_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Ramsar sites', 'value': 1.0}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Ramsar sites', 'value': 2.0}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Ramsar sites', 'value': 3.0}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Ramsar sites', 'value': 4.0}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Ramsar sites', 'value': 9.0}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Ramsar sites', 'value': 11.0}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Ramsar sites', 'value': 20.0}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Ramsar sites', 'value': 21.0}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Ramsar sites', 'value': 50.0}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Ramsar sites', 'value': 64.0}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Ramsar sites', 'value': 50.0}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Ramsar sites', 'value': 64.0}, Model: openai_gpt-4o-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_24893/3314864075.py:117: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/34_ramsar_convention_parties_statistical_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/34_ramsar_convention_parties_statistical_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Entry date', 'value': '1975-1985'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Entry date', 'value': '1986-2013'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/34_ramsar_convention_parties_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/34_ramsar_convention_parties_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Entry date', 'value': '1970-1979'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Entry date', 'value': '1980-1989'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Entry date', 'value': '1990-1999'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Entry date', 'value': '2000-2009'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Entry date', 'value': '2010-2020'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/34_ramsar_convention_parties_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/34_ramsar_convention_parties_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Entry date', 'value': '1970-1979'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Entry date', 'value': '1980-1989'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Entry date', 'value': '1990-1999'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Entry date', 'value': '2000-2009'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Entry date', 'value': '2010-2020'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/34_ramsar_convention_parties_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/34_ramsar_convention_parties_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Entry date', 'value': '1970-1980'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Entry date', 'value': '1981-1990'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Entry date', 'value': '1991-2000'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Entry date', 'value': '2001-2010'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Entry date', 'value': '2011-2020'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/34_ramsar_convention_parties_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/34_ramsar_convention_parties_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Entry date', 'value': '1970-1980'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Entry date', 'value': '1981-1990'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Entry date', 'value': '1991-2000'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Entry date', 'value': '2001-2010'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: ramsar_convention_parties, Page: {'field': 'Entry date', 'value': '2011-2020'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/34_ramsar_convention_parties_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/34_ramsar_convention_parties_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/34_ramsar_convention_parties_metrics.json\n",
      "[PROCESSING] Table: figure_skating_ladies_2009_2010, Source Columns: ['Rank', 'Name', 'Country', 'Points', 'Event', 'Date']\n",
      "[FETCH] Table: figure_skating_ladies_2009_2010, Page: None, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/34_ramsar_convention_parties_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/34_ramsar_convention_parties_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250904_215438/34_ramsar_convention_parties_metrics.json\n",
      "[PROCESSING] Table: figure_skating_ladies_2009_2010, Source Columns: ['Rank', 'Name', 'Country', 'Points', 'Event', 'Date']\n",
      "[FETCH] Table: figure_skating_ladies_2009_2010, Page: None, Model: openai_gpt-4o-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_24893/3314864075.py:117: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged CSV: processing/2_fetched_pages/20250904_215438/13_figure_skating_ladies_2009_2010_naive_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250904_215438/13_figure_skating_ladies_2009_2010_naive_openai_gpt-4o-mini_llm_logs.json\n",
      "[FETCH] Table: figure_skating_ladies_2009_2010, Page: {'field': 'Points', 'value': {'range': '160-170'}}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: figure_skating_ladies_2009_2010, Page: {'field': 'Points', 'value': {'range': '170-180'}}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: figure_skating_ladies_2009_2010, Page: {'field': 'Points', 'value': {'range': '180-190'}}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: figure_skating_ladies_2009_2010, Page: {'field': 'Points', 'value': {'range': '190-200'}}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: figure_skating_ladies_2009_2010, Page: {'field': 'Points', 'value': {'range': '200-210'}}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: figure_skating_ladies_2009_2010, Page: {'field': 'Points', 'value': {'range': '210-230'}}, Model: openai_gpt-4o-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_24893/3314864075.py:117: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 123\u001b[39m\n\u001b[32m    119\u001b[39m                     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[WARNING] Skipping non-CSV response for table \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeta.get(\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# Save LLM query, raw response, and parsed response for this page\u001b[39;00m\n\u001b[32m    121\u001b[39m             llm_logs.append({\n\u001b[32m    122\u001b[39m                 \u001b[33m'\u001b[39m\u001b[33mpage_key\u001b[39m\u001b[33m'\u001b[39m: page_key,\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m                 \u001b[33m'\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m'\u001b[39m: page_prompts.get(page_key, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m    124\u001b[39m                 \u001b[33m'\u001b[39m\u001b[33mraw_response\u001b[39m\u001b[33m'\u001b[39m: res.get(\u001b[33m'\u001b[39m\u001b[33mraw_response\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    125\u001b[39m                 \u001b[33m'\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m'\u001b[39m: res.get(\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    126\u001b[39m                 \u001b[33m'\u001b[39m\u001b[33mlatency\u001b[39m\u001b[33m'\u001b[39m: res[\u001b[33m'\u001b[39m\u001b[33mlatency\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    127\u001b[39m                 \u001b[33m'\u001b[39m\u001b[33musage\u001b[39m\u001b[33m'\u001b[39m: res[\u001b[33m'\u001b[39m\u001b[33musage\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    128\u001b[39m                 \u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m: res[\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    129\u001b[39m             })\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    131\u001b[39m     \u001b[38;5;66;03m# Sequential execution\u001b[39;00m\n\u001b[32m    132\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m idx, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tasks):\n",
      "\u001b[31mTypeError\u001b[39m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "# Fetch Pages Using LLM and Record Metrics (Parallelized)\n",
    "from io import StringIO\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "PROVIDE_SOURCE_TABLE = False  # If True, include source table as CSV in the prompt\n",
    "NUM_WORKERS = 8\n",
    "LLM_TIMEOUT = 30  # seconds\n",
    "LLM_MODEL = 'openai/gpt-4o-mini'  # Use this model for all criteria\n",
    "OPENROUTER_API_KEY='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'\n",
    "TOGGLE_USE_EXECUTOR = True  # Toggle whether to use ThreadPoolExecutor for parallel fetching\n",
    "# OPENROUTER_API_KEY = os.environ.get('OPENROUTER_API_KEY', '')\n",
    "# print('OPENROUTER_API_KEY:', OPENROUTER_API_KEY)\n",
    "\n",
    "output_root = 'processing/2_fetched_pages/'\n",
    "\n",
    "table_generator = TableGenerator_JSON()\n",
    "\n",
    "def get_latest_timestamped_dir(root):\n",
    "    folders = [f for f in os.listdir(root) if os.path.isdir(os.path.join(root, f))]\n",
    "    if not folders:\n",
    "        return None\n",
    "    # Sort by timestamp in folder name (assuming YYYYMMDD_HHMMSS)\n",
    "    return sorted(folders)[-1]\n",
    "\n",
    "if INCREMENT_MODE:\n",
    "    output_root = 'processing/2_fetched_pages/'\n",
    "    latest_dir = get_latest_timestamped_dir(output_root)\n",
    "    if latest_dir:\n",
    "        output_folder = os.path.join(output_root, latest_dir)\n",
    "        print(f\"[INCREMENT] Using latest output folder: {output_folder}\")\n",
    "    else:\n",
    "        output_folder = os.path.join(output_root, timestamp)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        print(f\"[INCREMENT] No previous folder found, using new: {output_folder}\")\n",
    "    # Build set of already processed table names\n",
    "    existing_metrics = set()\n",
    "    for fname in os.listdir(output_folder):\n",
    "        if fname.endswith('_metrics.json'):\n",
    "            parts = fname.split('_metrics.json')[0].split('_', 1)\n",
    "            if len(parts) == 2:\n",
    "                existing_metrics.add(parts[1])  # table name\n",
    "            else:\n",
    "                existing_metrics.add(parts[0])  # fallback\n",
    "    print(f\"[INCREMENT] Existing metrics found for tables: {existing_metrics}\")\n",
    "else:\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    output_folder = os.path.join(output_root, timestamp)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    print(f\"[FULL RUN] Using new output folder: {output_folder}\")\n",
    "\n",
    "for table in tables:\n",
    "    meta = table['meta']\n",
    "    criteria = table['criteria']\n",
    "    if INCREMENT_MODE and meta.get('name') in existing_metrics:\n",
    "        print(f\"[INCREMENT] Skipping table {meta.get('name')} (metrics.json exists)\")\n",
    "        continue\n",
    "    source_csv_path = meta.get('source_file')\n",
    "    source_csv_str = ''\n",
    "    source_columns = None\n",
    "    source_df = None\n",
    "    if source_csv_path and os.path.exists(source_csv_path):\n",
    "        try:\n",
    "            source_df = pd.read_csv(source_csv_path)\n",
    "            source_csv_str = source_df.to_csv(index=False)\n",
    "            source_columns = list(source_df.columns)\n",
    "            csv_path = os.path.join(output_folder, f\"{meta.get('id','')}_{meta['file']}\")\n",
    "            source_df.to_csv(csv_path, index=False)\n",
    "        except Exception as e:\n",
    "            print(f'[WARNING] Could not load source CSV for {meta.get(\"name\")}: {e}')\n",
    "            source_csv_str = ''\n",
    "            source_columns = None\n",
    "    print(f\"[PROCESSING] Table: {meta.get('name')}, Source Columns: {source_columns}\")\n",
    "    table_results = {}\n",
    "    for method, crit in criteria.items():\n",
    "        # For llm, collect top recommendation from all listed models\n",
    "        if method == 'llm':\n",
    "            criteria_list = []\n",
    "            for model_name, model_criteria in crit.items():\n",
    "                if not model_criteria:\n",
    "                    continue\n",
    "                top_crit = model_criteria[0] if isinstance(model_criteria, list) else model_criteria\n",
    "                criteria_list.append((model_name, top_crit))\n",
    "        # For oracle_single_row and single_row_llm, treat as single-criteria methods\n",
    "        elif method in {'oracle_single_row', 'single_row_llm'}:\n",
    "            criteria_list = [(LLM_MODEL, crit)]\n",
    "        else:\n",
    "            criteria_list = [(LLM_MODEL, crit)]\n",
    "        for model_name, crit_obj in criteria_list:\n",
    "            model_name = model_name.replace('/', '_')\n",
    "            pages = crit_obj.get('pages', [])\n",
    "            if source_columns:\n",
    "                merged_df = pd.DataFrame(columns=source_columns)\n",
    "            else:\n",
    "                merged_df = pd.DataFrame()\n",
    "            metrics = []\n",
    "            llm_logs = []  # Collect LLM queries and responses for each page\n",
    "            # Prepare tasks for all pages\n",
    "            tasks = []\n",
    "            page_prompts = {}  # page_key -> prompt string\n",
    "            raw_responses = {}  # page_key -> raw response string\n",
    "            for page_key in pages:\n",
    "                # Build the prompt string for each page\n",
    "                page_content = {'field': crit_obj.get('criteria',''), 'value': page_key} if page_key != 'ALL' else None\n",
    "                system_msg, user_msg = table_generator.generate_prompts(meta.get('query_without_cutoff'), source_columns, page_content)\n",
    "                if PROVIDE_SOURCE_TABLE and source_csv_str:\n",
    "                    user_msg += f\"\\n\\nSource table as CSV:\\n{source_csv_str}\"\n",
    "                tasks.append((meta, crit_obj, page_key, model_name, source_columns, source_csv_str if PROVIDE_SOURCE_TABLE else None))\n",
    "                page_prompts[str(page_key)] = user_msg\n",
    "            results = []\n",
    "            if TOGGLE_USE_EXECUTOR:\n",
    "                with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
    "                    future_to_page = {executor.submit(fetch_page_task, t): t[2] for t in tasks}\n",
    "                    for future in as_completed(future_to_page):\n",
    "                        page_key = future_to_page[future]\n",
    "                        res = future.result()\n",
    "                        metrics.append({'latency': res['latency'], 'usage': res['usage'], 'error': res['error']})\n",
    "                        if res['content'] is not None:\n",
    "                            try:\n",
    "                                df_page = res['content']\n",
    "                                merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n",
    "                            except Exception:\n",
    "                                print(f\"[WARNING] Skipping non-CSV response for table {meta.get('name')}, page {page_key}, model {model_name}\")\n",
    "                        # Save LLM query, raw response, and parsed response for this page\n",
    "                        llm_logs.append({\n",
    "                            'page_key': page_key,\n",
    "                            'query': page_prompts.get(page_key, ''),\n",
    "                            'raw_response': res.get('raw_response', None),\n",
    "                            'response': res.get('content', None),\n",
    "                            'latency': res['latency'],\n",
    "                            'usage': res['usage'],\n",
    "                            'error': res['error']\n",
    "                        })\n",
    "            else:\n",
    "                # Sequential execution\n",
    "                for idx, t in enumerate(tasks):\n",
    "                    page_key = t[2]\n",
    "                    res = fetch_page_task(t)\n",
    "                    metrics.append({'latency': res['latency'], 'usage': res['usage'], 'error': res['error']})\n",
    "                    if res['content'] is not None:\n",
    "                        try:\n",
    "                            df_page = res['content']\n",
    "                            merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n",
    "                        except Exception:\n",
    "                            print(f\"[WARNING] Skipping non-CSV response for table {meta.get('name')}, page {page_key}, model {model_name}\")\n",
    "                    # Save LLM query, raw response, and parsed response for this page\n",
    "                    llm_logs.append({\n",
    "                        'page_key': page_key,\n",
    "                        'query': page_prompts.get(page_key, ''),\n",
    "                        'raw_response': res.get('raw_response', None),\n",
    "                        'response': res.get('content', None),\n",
    "                        'latency': res['latency'],\n",
    "                        'usage': res['usage'],\n",
    "                        'error': res['error']\n",
    "                    })\n",
    "            if merged_df is not None and not merged_df.empty:\n",
    "                csv_name = f\"{meta.get('id','')}_{meta.get('name','')}_{method}_{model_name}.csv\"\n",
    "                csv_path = os.path.join(output_folder, csv_name)\n",
    "                merged_df.to_csv(csv_path, index=False)\n",
    "                print(f'Saved merged CSV: {csv_path}')\n",
    "                # Save LLM logs for this table/method/model\n",
    "                llm_log_name = f\"{meta.get('id','')}_{meta.get('name','')}_{method}_{model_name}_llm_logs.json\"\n",
    "                llm_log_path = os.path.join(output_folder, llm_log_name)\n",
    "                # Convert DataFrames in 'response' to dicts for serialization\n",
    "                for log in llm_logs:\n",
    "                    if hasattr(log['response'], 'to_dict'):\n",
    "                        log['response'] = log['response'].to_dict()\n",
    "                with open(llm_log_path, 'w') as f:\n",
    "                    json.dump(llm_logs, f, indent=2)\n",
    "                print(f'Saved LLM logs: {llm_log_path}')\n",
    "            else:\n",
    "                metrics.append({'latency': None, 'usage': None, 'error': 'Merged DataFrame is empty'})\n",
    "            # After building merged_df and metrics:\n",
    "            metric_result = compute_metrics(merged_df, source_columns, metrics, source_df)\n",
    "            table_results[f'{method}_{model_name}'] = {\n",
    "                'merged_df': merged_df,\n",
    "                'metrics': metrics,\n",
    "                'criteria': crit_obj,\n",
    "                **metric_result\n",
    "            }\n",
    "    out_json = {\n",
    "        'meta': meta,\n",
    "        'results': {}\n",
    "    }\n",
    "    for key, res in table_results.items():\n",
    "        out_json['results'][key] = {\n",
    "            'criteria': res.get('criteria'),\n",
    "            'metrics': res.get('metrics'),\n",
    "            'row_count': res.get('row_count'),\n",
    "            'column_consistency': res.get('column_consistency'),\n",
    "            'error_rate': res.get('error_rate'),\n",
    "            'avg_latency': res.get('avg_latency'),\n",
    "            'sum_tokens': res.get('sum_tokens'),\n",
    "            'accuracy': res.get('accuracy')\n",
    "        }\n",
    "    json_name = f\"{meta.get('id','')}_{meta.get('name','')}_metrics.json\"\n",
    "    json_path = os.path.join(output_folder, json_name)\n",
    "    os.makedirs(os.path.dirname(json_path), exist_ok=True)\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(out_json, f, indent=2)\n",
    "    print(f'Saved JSON metadata: {json_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
