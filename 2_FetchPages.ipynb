{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a07c4455",
   "metadata": {},
   "source": [
    "# Stage 3: Fetch Pages\n",
    "\n",
    "\n",
    "This notebook implements the third stage of the pipeline: fetching pages using LLMs, recording metrics, and saving results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74912bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f70d826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pagination folder: processing/1_pagination/20250831_110417\n"
     ]
    }
   ],
   "source": [
    "# Identify Latest Folder Under Pagination\n",
    "pagination_root = 'processing/1_pagination/'\n",
    "folders = [f for f in os.listdir(pagination_root) if os.path.isdir(os.path.join(pagination_root, f))]\n",
    "latest_folder = sorted(folders)[-1] if folders else None\n",
    "pagination_path = os.path.join(pagination_root, latest_folder) if latest_folder else None\n",
    "assert pagination_path and os.path.exists(pagination_path), 'No pagination folder found.'\n",
    "print('Using pagination folder:', pagination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ed3ce2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 26 tables.\n"
     ]
    }
   ],
   "source": [
    "# Load Pagination Criteria\n",
    "json_files = glob.glob(os.path.join(pagination_path, '*.json'))\n",
    "tables = []\n",
    "for jf in json_files:\n",
    "    with open(jf, 'r') as f:\n",
    "        obj = json.load(f)\n",
    "    tables.append({'path': jf, 'meta': obj['meta'], 'criteria': obj['pagination_criteria']})\n",
    "print(f'Loaded {len(tables)} tables.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fcb997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class TableGenerator_JSON():\n",
    "    TEMPLATE = \"\"\"\n",
    "    List %s - as many as possible to fit into response.\n",
    "    The response will be formatted as JSON shown below.\n",
    "    Each element of the response will contain %d fields: %s.\n",
    "    Do not output any additional text that is not in JSON format.\n",
    "    %s\n",
    "    \n",
    "    \"\"\"   \n",
    "\n",
    "    def _norm_field(self, s):\n",
    "        s = s.lower().replace(\" \",\"_\").replace(\"-\",\"_\").replace(\".\", \"\").replace(\",\",\"_\")\\\n",
    "                .replace(\"(\", \"\").replace(\")\", \"\").replace(\":\", \"\").replace('\"','').replace(\"'\",\"\")\\\n",
    "                .replace(\"/\", \"\")\n",
    "        return re.sub('_+', '_', s)\n",
    "        \n",
    "    def generate_prompts(self, query, fields, paging: dict | None):\n",
    "        system_msg = \"You are a retriever of facts.\"\n",
    "\n",
    "        num_fields = len(fields)\n",
    "        fields_json = []\n",
    "        fields = [f for f in fields]\n",
    "        for field in fields:\n",
    "            fields_json.append('\"%s\": \"%s\"' % ('_'.join(field.replace(\"-\", \" \").split()), field))\n",
    "        response_format = ', '.join(fields)\n",
    "        if paging:\n",
    "            paging_criteria = ('Only fetch the results where values for %s match: %s.' % (paging['field'], paging['value']))\n",
    "        else:\n",
    "            paging_criteria = ''\n",
    "        user_msg = self.TEMPLATE % (query, num_fields, response_format, paging_criteria)\n",
    "        return system_msg, user_msg\n",
    "\n",
    "    def parse_llm_response(self, response): \n",
    "        res = []\n",
    "        try:\n",
    "            if not response.startswith(\"[\") and \"[\" in response:\n",
    "                response = response[response.find(\"[\"):]\n",
    "\n",
    "            if not response.endswith(\"]\") and \"]\" in response:\n",
    "                response = response[:response.rfind(\"]\")+1]\n",
    "\n",
    "            if '[' not in response and ']' not in response and '{' in response and '}' in response:\n",
    "                response = '[' + response + ']'    \n",
    "\n",
    "            response_json = json.loads(response)\n",
    "\n",
    "            if isinstance(response_json, dict) and len(response_json.keys()) == 1:\n",
    "                response_json = list(response_json.values())[0]    \n",
    "        except:  \n",
    "            split_response = response.split(\"{\")\n",
    "            response_json = []\n",
    "            for s in split_response[1:]:\n",
    "                split_s = s.split(\"}\")\n",
    "                if len(split_s) > 1:\n",
    "                    content = split_s[0]\n",
    "                    attributes = content.split(\",\")\n",
    "                    elements = {}\n",
    "                    for attr in attributes:\n",
    "                        knv = attr.split(\":\")   \n",
    "                        if len(knv) > 1:\n",
    "                            parsed_k = \"%s\" % knv[0].replace('\"','').strip()\n",
    "                            parsed_v = \"%s\" % knv[1].replace('\"','').strip()\n",
    "                            elements[parsed_k] = parsed_v\n",
    "\n",
    "                    response_json.append(elements)  \n",
    "\n",
    "        df = pd.DataFrame.from_records(response_json) \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bad1417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: None, Model: x-ai_grok-3-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250831_111058/25_english_latin_rivalry_1887_2012_naive_x-ai_grok-3-mini.csv\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 0}, Model: x-ai_grok-3-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 4}, Model: x-ai_grok-3-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 5}, Model: x-ai_grok-3-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 6}, Model: x-ai_grok-3-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 10}, Model: x-ai_grok-3-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 12}, Model: x-ai_grok-3-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 22}, Model: x-ai_grok-3-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 23}, Model: x-ai_grok-3-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 44}, Model: x-ai_grok-3-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250831_111058/25_english_latin_rivalry_1887_2012_statistical_x-ai_grok-3-mini.csv\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1887-1894'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1895-1902'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1903-1910'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1911-1918'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1919-1926'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250831_111058/25_english_latin_rivalry_1887_2012_llm_google_gemini-2.5-flash-lite.csv\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1880s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1890s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1900s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1910s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1920s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250831_111058/25_english_latin_rivalry_1887_2012_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1887-1890'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1891-1894'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1895-1898'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1899-1902'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1903-1906'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250831_111058/25_english_latin_rivalry_1887_2012_llm_openai_gpt-4o-mini.csv\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250831_111058/25_english_latin_rivalry_1887_2012_metrics.json\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: None, Model: x-ai_grok-3-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_75671/3540648575.py:159: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged CSV: processing/2_fetched_pages/20250831_111058/3_australia_demographics_1900_2010_naive_x-ai_grok-3-mini.csv\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': 'NaN'}, Model: x-ai_grok-3-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': '0-1'}, Model: x-ai_grok-3-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': '1-2'}, Model: x-ai_grok-3-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': '2-3'}, Model: x-ai_grok-3-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': '3-4'}, Model: x-ai_grok-3-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': '4-5'}, Model: x-ai_grok-3-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': '5-6'}, Model: x-ai_grok-3-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': '6-7'}, Model: x-ai_grok-3-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': '7-8'}, Model: x-ai_grok-3-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': '8-9'}, Model: x-ai_grok-3-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': '9-10'}, Model: x-ai_grok-3-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250831_111058/3_australia_demographics_1900_2010_statistical_x-ai_grok-3-mini.csv\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1900-1910'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1911-1920'}, Model: google_gemini-2.5-flash-lite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_75671/3540648575.py:159: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged CSV: processing/2_fetched_pages/20250831_111058/3_australia_demographics_1900_2010_llm_google_gemini-2.5-flash-lite.csv\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1900-1919'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1920-1939'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1940-1959'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1960-1979'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1980-1999'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250831_111058/3_australia_demographics_1900_2010_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1900-1910'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1911-1920'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1921-1930'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1931-1940'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1941-1950'}, Model: openai_gpt-4o-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_75671/3540648575.py:159: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged CSV: processing/2_fetched_pages/20250831_111058/3_australia_demographics_1900_2010_llm_openai_gpt-4o-mini.csv\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250831_111058/3_australia_demographics_1900_2010_metrics.json\n",
      "[FETCH] Table: elements, Page: None, Model: x-ai_grok-3-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_75671/3540648575.py:159: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged CSV: processing/2_fetched_pages/20250831_111058/15_elements_naive_x-ai_grok-3-mini.csv\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': 1}, Model: x-ai_grok-3-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': 2}, Model: x-ai_grok-3-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': 3}, Model: x-ai_grok-3-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': 4}, Model: x-ai_grok-3-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_75671/3540648575.py:159: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged CSV: processing/2_fetched_pages/20250831_111058/15_elements_statistical_x-ai_grok-3-mini.csv\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': '1'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': '2'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': '3'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': '4'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': '5'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': '6'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': '7'}, Model: google_gemini-2.5-flash-lite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_75671/3540648575.py:159: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged CSV: processing/2_fetched_pages/20250831_111058/15_elements_llm_google_gemini-2.5-flash-lite.csv\n",
      "[FETCH] Table: elements, Page: {'field': 'Period,Group', 'value': '1,1-18'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: elements, Page: {'field': 'Period,Group', 'value': '2,1-18'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: elements, Page: {'field': 'Period,Group', 'value': '3,1-18'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: elements, Page: {'field': 'Period,Group', 'value': '4,1-18'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: elements, Page: {'field': 'Period,Group', 'value': '5-7,1-18'}, Model: deepseek_deepseek-chat-v3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_75671/3540648575.py:159: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged CSV: processing/2_fetched_pages/20250831_111058/15_elements_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '1'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '2'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '13'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '14'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '18'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250831_111058/15_elements_llm_openai_gpt-4o-mini.csv\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250831_111058/15_elements_metrics.json\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: None, Model: x-ai_grok-3-mini\n",
      "[ERROR] Failed to fetch page: Expecting value: line 777 column 1 (char 4268)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Merged DataFrame is empty for table rock_band_downloadable_2011, method naive, model x-ai_grok-3-mini",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 170\u001b[39m\n\u001b[32m    168\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mSaved merged CSV: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mMerged DataFrame is empty for table \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeta.get(\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, method \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m    171\u001b[39m \u001b[38;5;66;03m# After building merged_df and metrics:\u001b[39;00m\n\u001b[32m    172\u001b[39m metric_result = compute_metrics(merged_df, source_columns, metrics, source_df)\n",
      "\u001b[31mValueError\u001b[39m: Merged DataFrame is empty for table rock_band_downloadable_2011, method naive, model x-ai_grok-3-mini"
     ]
    }
   ],
   "source": [
    "# Fetch Pages Using LLM and Record Metrics (Parallelized)\n",
    "from io import StringIO\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "PROVIDE_SOURCE_TABLE = True  # If True, include source table as CSV in the prompt\n",
    "LLM_TIMEOUT = 30  # seconds\n",
    "LLM_MODEL = 'x-ai/grok-3-mini'  # Use this model for all criteria\n",
    "\n",
    "OPENROUTER_API_KEY = os.environ.get('OPENROUTER_API_KEY', '')\n",
    "\n",
    "output_root = 'processing/2_fetched_pages/'\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "output_folder = os.path.join(output_root, timestamp)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "def compute_metrics(merged_df, source_columns, metrics, source_df):\n",
    "    row_count = len(merged_df) if merged_df is not None else 0\n",
    "    col_consistency = (set(merged_df.columns) == set(source_columns)) if source_columns and not merged_df.empty else None\n",
    "    error_count = sum(1 for m in metrics if m['error'])\n",
    "    total_pages = len(metrics)\n",
    "    error_rate = error_count / total_pages if total_pages > 0 else None\n",
    "    latencies = [m['latency'] for m in metrics if m['latency'] is not None]\n",
    "    avg_latency = sum(latencies) / len(latencies) if latencies else None\n",
    "    token_counts = [m['usage'].get('total_tokens', 0) for m in metrics if m['usage'] and 'total_tokens' in m['usage']]\n",
    "    sum_tokens = sum(token_counts) if token_counts else None\n",
    "    acc_metrics = None\n",
    "    if source_df is not None and not merged_df.empty:\n",
    "        acc_metrics = accuracy_metrics(merged_df, source_df)\n",
    "    return {\n",
    "        'row_count': row_count,\n",
    "        'column_consistency': col_consistency,\n",
    "        'error_rate': error_rate,\n",
    "        'avg_latency': avg_latency,\n",
    "        'sum_tokens': sum_tokens,\n",
    "        'accuracy': acc_metrics\n",
    "    }\n",
    "\n",
    "table_generator = TableGenerator_JSON()\n",
    "\n",
    "def fetch_page_llm(prompt, model, api_key, system_msg: str = ''):\n",
    "    url = 'https://openrouter.ai/api/v1/chat/completions'\n",
    "    headers = {'Authorization': f'Bearer {api_key}', 'Content-Type': 'application/json'}\n",
    "    payload = {\n",
    "        'model': model,\n",
    "        'messages': [\n",
    "            {'role': 'system', 'content': system_msg},\n",
    "            {'role': 'user', 'content': prompt}\n",
    "        ],\n",
    "        'max_tokens': 100000\n",
    "    }\n",
    "    start = time.time()\n",
    "    try:\n",
    "        resp = requests.post(url, headers=headers, json=payload, timeout=LLM_TIMEOUT)\n",
    "        latency = time.time() - start\n",
    "        resp.raise_for_status()\n",
    "        result = resp.json()\n",
    "        content = result['choices'][0]['message']['content'] if 'choices' in result else ''\n",
    "        content = table_generator.parse_llm_response(content)\n",
    "        usage = result.get('usage', {})\n",
    "        return content, latency, usage, None\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to fetch page: {e}\")\n",
    "        return None, None, None, str(e)\n",
    "\n",
    "# Accuracy metric functions (from old/2_Metrics_calculation.ipynb)\n",
    "def accuracy_metrics(merged_df, source_df):\n",
    "    # Only compare columns present in both\n",
    "    common_cols = [col for col in source_df.columns if col in merged_df.columns]\n",
    "    # Cast all columns to string for comparison\n",
    "    src = source_df[common_cols].drop_duplicates().reset_index(drop=True).astype(str)\n",
    "    pred = merged_df[common_cols].drop_duplicates().reset_index(drop=True).astype(str)\n",
    "    # Row-level accuracy: fraction of source rows present in merged\n",
    "    correct_rows = src.merge(pred, how='inner').shape[0]\n",
    "    total_rows = src.shape[0]\n",
    "    row_recall = correct_rows / total_rows if total_rows > 0 else None\n",
    "    # Precision: fraction of merged rows that are correct\n",
    "    correct_pred_rows = pred.merge(src, how='inner').shape[0]\n",
    "    total_pred_rows = pred.shape[0]\n",
    "    row_precision = correct_pred_rows / total_pred_rows if total_pred_rows > 0 else None\n",
    "    # F1 score\n",
    "    if row_precision is not None and row_recall is not None and (row_precision + row_recall) > 0:\n",
    "        row_f1 = 2 * row_precision * row_recall / (row_precision + row_recall)\n",
    "    else:\n",
    "        row_f1 = None\n",
    "    return {\n",
    "        'row_recall': row_recall,\n",
    "        'row_precision': row_precision,\n",
    "        'row_f1': row_f1\n",
    "    }\n",
    "\n",
    "def fetch_page_task(args):\n",
    "    # args: (meta, crit_obj, page_key, model_name, source_columns, source_csv_str)\n",
    "    meta, crit_obj, page_key, model_name, source_columns, source_csv_str = args\n",
    "    page_content = {'field': crit_obj.get('criteria',''), 'value': page_key} if page_key != 'ALL' else None\n",
    "    system_msg, user_msg = table_generator.generate_prompts(meta.get('query_without_cutoff'), source_columns, page_content)\n",
    "    if PROVIDE_SOURCE_TABLE and source_csv_str:\n",
    "        user_msg += f\"\\n\\nSource table as CSV:\\n{source_csv_str}\"\n",
    "    print(f\"[FETCH] Table: {meta.get('name')}, Page: {page_content}, Model: {model_name}\")\n",
    "    content, latency, usage, error = fetch_page_llm(user_msg, LLM_MODEL, OPENROUTER_API_KEY, system_msg)\n",
    "    return {\n",
    "        'content': content,\n",
    "        'latency': latency,\n",
    "        'usage': usage,\n",
    "        'error': error,\n",
    "        'page_key': page_key\n",
    "    }\n",
    "\n",
    "for table in tables:\n",
    "    meta = table['meta']\n",
    "    criteria = table['criteria']\n",
    "    source_csv_path = meta.get('source_file')\n",
    "    source_csv_str = ''\n",
    "    source_columns = None\n",
    "    source_df = None\n",
    "    if PROVIDE_SOURCE_TABLE and source_csv_path and os.path.exists(source_csv_path):\n",
    "        try:\n",
    "            source_df = pd.read_csv(source_csv_path)\n",
    "            source_csv_str = source_df.to_csv(index=False)\n",
    "            source_columns = list(source_df.columns)\n",
    "            csv_path = os.path.join(output_folder, meta['file'])\n",
    "            source_df.to_csv(csv_path, index=False)\n",
    "        except Exception as e:\n",
    "            print(f'[WARNING] Could not load source CSV for {meta.get(\"name\")}: {e}')\n",
    "            source_csv_str = ''\n",
    "            source_columns = None\n",
    "    table_results = {}\n",
    "    for method, crit in criteria.items():\n",
    "        # For llm, collect top recommendation from all listed models\n",
    "        if method == 'llm':\n",
    "            criteria_list = []\n",
    "            for model_name, model_criteria in crit.items():\n",
    "                if not model_criteria:\n",
    "                    continue\n",
    "                top_crit = model_criteria[0] if isinstance(model_criteria, list) else model_criteria\n",
    "                criteria_list.append((model_name, top_crit))\n",
    "        else:\n",
    "            criteria_list = [(LLM_MODEL, crit)]\n",
    "        for model_name, crit_obj in criteria_list:\n",
    "            model_name = model_name.replace('/', '_')\n",
    "            pages = crit_obj.get('pages', [])\n",
    "            if source_columns:\n",
    "                merged_df = pd.DataFrame(columns=source_columns)\n",
    "            else:\n",
    "                merged_df = pd.DataFrame()\n",
    "            metrics = []\n",
    "            # Prepare tasks for all pages\n",
    "            tasks = [(meta, crit_obj, page_key, model_name, source_columns, source_csv_str) for page_key in pages]\n",
    "            results = []\n",
    "            with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "                future_to_page = {executor.submit(fetch_page_task, t): t[2] for t in tasks}\n",
    "                for future in as_completed(future_to_page):\n",
    "                    page_key = future_to_page[future]\n",
    "                    try:\n",
    "                        res = future.result()\n",
    "                        metrics.append({'latency': res['latency'], 'usage': res['usage'], 'error': res['error']})\n",
    "                        if res['content'] is not None:\n",
    "                            try:\n",
    "                                df_page = res['content']\n",
    "                                merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n",
    "                            except Exception:\n",
    "                                print(f\"[WARNING] Skipping non-CSV response for table {meta.get('name')}, page {page_key}, model {model_name}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"[ERROR] Exception in future for page {page_key}: {e}\")\n",
    "            if merged_df is not None and not merged_df.empty:\n",
    "                csv_name = f\"{meta.get('id','')}_{meta.get('name','')}_{method}_{model_name}.csv\"\n",
    "                csv_path = os.path.join(output_folder, csv_name)\n",
    "                merged_df.to_csv(csv_path, index=False)\n",
    "                print(f'Saved merged CSV: {csv_path}')\n",
    "            # else:\n",
    "            #     raise ValueError(f'Merged DataFrame is empty for table {meta.get(\"name\")}, method {method}, model {model_name}')\n",
    "            # After building merged_df and metrics:\n",
    "            metric_result = compute_metrics(merged_df, source_columns, metrics, source_df)\n",
    "            table_results[f'{method}_{model_name}'] = {\n",
    "                'merged_df': merged_df,\n",
    "                'metrics': metrics,\n",
    "                'criteria': crit_obj,\n",
    "                **metric_result\n",
    "            }\n",
    "    out_json = {\n",
    "        'meta': meta,\n",
    "        'results': {}\n",
    "    }\n",
    "    for key, res in table_results.items():\n",
    "        out_json['results'][key] = {\n",
    "            'criteria': res.get('criteria'),\n",
    "            'metrics': res.get('metrics'),\n",
    "            'row_count': res.get('row_count'),\n",
    "            'column_consistency': res.get('column_consistency'),\n",
    "            'error_rate': res.get('error_rate'),\n",
    "            'avg_latency': res.get('avg_latency'),\n",
    "            'sum_tokens': res.get('sum_tokens'),\n",
    "            'accuracy': res.get('accuracy')\n",
    "        }\n",
    "    json_name = f\"{meta.get('id','')}_{meta.get('name','')}_metrics.json\"\n",
    "    json_path = os.path.join(output_folder, json_name)\n",
    "    os.makedirs(os.path.dirname(json_path), exist_ok=True)\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(out_json, f, indent=2)\n",
    "    print(f'Saved JSON metadata: {json_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
