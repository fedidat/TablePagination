{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a07c4455",
   "metadata": {},
   "source": [
    "# Stage 3: Fetch Pages\n",
    "\n",
    "\n",
    "This notebook implements the third stage of the pipeline: fetching pages using LLMs, recording metrics, and saving results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74912bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f70d826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pagination folder: processing/1_pagination/20250831_110417\n"
     ]
    }
   ],
   "source": [
    "# Identify Latest Folder Under Pagination\n",
    "pagination_root = 'processing/1_pagination/'\n",
    "folders = [f for f in os.listdir(pagination_root) if os.path.isdir(os.path.join(pagination_root, f))]\n",
    "latest_folder = sorted(folders)[-1] if folders else None\n",
    "pagination_path = os.path.join(pagination_root, latest_folder) if latest_folder else None\n",
    "assert pagination_path and os.path.exists(pagination_path), 'No pagination folder found.'\n",
    "print('Using pagination folder:', pagination_path)\n",
    "\n",
    "# INCREMENT MODE: Build a set of already processed table IDs/names\n",
    "INCREMENT_MODE = False  # Set to False for normal full run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ed3ce2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 26 tables.\n"
     ]
    }
   ],
   "source": [
    "# Load Pagination Criteria\n",
    "json_files = glob.glob(os.path.join(pagination_path, '*.json'))\n",
    "tables = []\n",
    "for jf in json_files:\n",
    "    with open(jf, 'r') as f:\n",
    "        obj = json.load(f)\n",
    "    tables.append({'path': jf, 'meta': obj['meta'], 'criteria': obj['pagination_criteria']})\n",
    "print(f'Loaded {len(tables)} tables.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fcb997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class TableGenerator_JSON():\n",
    "    TEMPLATE = \"\"\"\n",
    "    List %s - as many as possible to fit into response.\n",
    "    The response will be formatted as JSON.\n",
    "    Each element of the response will contain %d fields: %s.\n",
    "    Do not output any additional text that is not in JSON format.\n",
    "    %s\n",
    "    \n",
    "    \"\"\"   \n",
    "\n",
    "    def _norm_field(self, s):\n",
    "        s = s.lower().replace(\" \",\"_\").replace(\"-\",\"_\").replace(\".\", \"\").replace(\",\",\"_\")\\\n",
    "                .replace(\"(\", \"\").replace(\")\", \"\").replace(\":\", \"\").replace('\"','').replace(\"'\",\"\")\\\n",
    "                .replace(\"/\", \"\")\n",
    "        return re.sub('_+', '_', s)\n",
    "        \n",
    "    def generate_prompts(self, query, fields, paging: dict | None):\n",
    "        system_msg = \"You are a retriever of facts.\"\n",
    "\n",
    "        num_fields = len(fields)\n",
    "        fields_json = []\n",
    "        fields = [f for f in fields]\n",
    "        for field in fields:\n",
    "            fields_json.append('\"%s\": \"%s\"' % ('_'.join(field.replace(\"-\", \" \").split()), field))\n",
    "        response_format = ', '.join(fields)\n",
    "        if paging:\n",
    "            paging_criteria = ('Only fetch the results where values for %s match: %s.' % (paging['field'], paging['value']))\n",
    "        else:\n",
    "            paging_criteria = ''\n",
    "        user_msg = self.TEMPLATE % (query, num_fields, response_format, paging_criteria)\n",
    "        return system_msg, user_msg\n",
    "\n",
    "    def parse_llm_response(self, response): \n",
    "        res = []\n",
    "        try:\n",
    "            if not response.startswith(\"[\") and \"[\" in response:\n",
    "                response = response[response.find(\"[\"):]\n",
    "\n",
    "            if not response.endswith(\"]\") and \"]\" in response:\n",
    "                response = response[:response.rfind(\"]\")+1]\n",
    "\n",
    "            if '[' not in response and ']' not in response and '{' in response and '}' in response:\n",
    "                response = '[' + response + ']'    \n",
    "\n",
    "            response_json = json.loads(response)\n",
    "\n",
    "            if isinstance(response_json, dict) and len(response_json.keys()) == 1:\n",
    "                response_json = list(response_json.values())[0]    \n",
    "        except:  \n",
    "            split_response = response.split(\"{\")\n",
    "            response_json = []\n",
    "            for s in split_response[1:]:\n",
    "                split_s = s.split(\"}\")\n",
    "                if len(split_s) > 1:\n",
    "                    content = split_s[0]\n",
    "                    attributes = content.split(\",\")\n",
    "                    elements = {}\n",
    "                    for attr in attributes:\n",
    "                        knv = attr.split(\":\")   \n",
    "                        if len(knv) > 1:\n",
    "                            parsed_k = \"%s\" % knv[0].replace('\"','').strip()\n",
    "                            parsed_v = \"%s\" % knv[1].replace('\"','').strip()\n",
    "                            elements[parsed_k] = parsed_v\n",
    "\n",
    "                    response_json.append(elements)  \n",
    "\n",
    "        df = pd.DataFrame.from_records(response_json) \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "604a0e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(merged_df, source_columns, metrics, source_df):\n",
    "    row_count = len(merged_df) if merged_df is not None else 0\n",
    "    col_consistency = (set(merged_df.columns) == set(source_columns)) if source_columns and not merged_df.empty else None\n",
    "    error_count = sum(1 for m in metrics if m['error'])\n",
    "    total_pages = len(metrics)\n",
    "    error_rate = error_count / total_pages if total_pages > 0 else None\n",
    "    latencies = [m['latency'] for m in metrics if m['latency'] is not None]\n",
    "    avg_latency = sum(latencies) / len(latencies) if latencies else None\n",
    "    token_counts = [m['usage'].get('total_tokens', 0) for m in metrics if m['usage'] and 'total_tokens' in m['usage']]\n",
    "    sum_tokens = sum(token_counts) if token_counts else None\n",
    "    acc_metrics = None\n",
    "    if source_df is not None and not merged_df.empty:\n",
    "        acc_metrics = accuracy_metrics(merged_df, source_df)\n",
    "    return {\n",
    "        'row_count': row_count,\n",
    "        'column_consistency': col_consistency,\n",
    "        'error_rate': error_rate,\n",
    "        'avg_latency': avg_latency,\n",
    "        'sum_tokens': sum_tokens,\n",
    "        'accuracy': acc_metrics\n",
    "    }\n",
    "\n",
    "# Accuracy metric functions (from old/2_Metrics_calculation.ipynb)\n",
    "def accuracy_metrics(merged_df, source_df):\n",
    "    # Only compare columns present in both\n",
    "    common_cols = [col for col in source_df.columns if col in merged_df.columns]\n",
    "    # Cast all columns to string for comparison\n",
    "    src = source_df[common_cols].drop_duplicates().reset_index(drop=True).astype(str)\n",
    "    pred = merged_df[common_cols].drop_duplicates().reset_index(drop=True).astype(str)\n",
    "    # Row-level accuracy: fraction of source rows present in merged\n",
    "    correct_rows = src.merge(pred, how='inner').shape[0]\n",
    "    total_rows = src.shape[0]\n",
    "    row_recall = correct_rows / total_rows if total_rows > 0 else None\n",
    "    # Precision: fraction of merged rows that are correct\n",
    "    correct_pred_rows = pred.merge(src, how='inner').shape[0]\n",
    "    total_pred_rows = pred.shape[0]\n",
    "    row_precision = correct_pred_rows / total_pred_rows if total_pred_rows > 0 else None\n",
    "    # F1 score\n",
    "    if row_precision is not None and row_recall is not None and (row_precision + row_recall) > 0:\n",
    "        row_f1 = 2 * row_precision * row_recall / (row_precision + row_recall)\n",
    "    else:\n",
    "        row_f1 = None\n",
    "    return {\n",
    "        'row_recall': row_recall,\n",
    "        'row_precision': row_precision,\n",
    "        'row_f1': row_f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ec1f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_page_llm(prompt, model, api_key, system_msg: str = ''):\n",
    "    url = 'https://openrouter.ai/api/v1/chat/completions'\n",
    "    headers = {'Authorization': f'Bearer {api_key}', 'Content-Type': 'application/json'}\n",
    "    payload = {\n",
    "        'model': model,\n",
    "        'messages': [\n",
    "            {'role': 'system', 'content': system_msg},\n",
    "            {'role': 'user', 'content': prompt}\n",
    "        ],\n",
    "        'max_tokens': 20000\n",
    "    }\n",
    "    start = time.time()\n",
    "    try:\n",
    "        resp = requests.post(url, headers=headers, json=payload, timeout=LLM_TIMEOUT)\n",
    "        latency = time.time() - start\n",
    "        resp.raise_for_status()\n",
    "        result = resp.json()\n",
    "        raw_response = result['choices'][0]['message']['content'] if 'choices' in result else ''\n",
    "        content = table_generator.parse_llm_response(raw_response)\n",
    "        usage = result.get('usage', {})\n",
    "        return content, latency, usage, None, raw_response\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to fetch page: {e}\")\n",
    "        return None, None, None, str(e), None\n",
    "\n",
    "def fetch_page_task(args):\n",
    "    # args: (meta, crit_obj, page_key, model_name, source_columns, source_csv_str)\n",
    "    meta, crit_obj, page_key, model_name, source_columns, source_csv_str = args\n",
    "    page_content = {'field': crit_obj.get('criteria',''), 'value': page_key} if page_key != 'ALL' else None\n",
    "    system_msg, user_msg = table_generator.generate_prompts(meta.get('query_without_cutoff'), source_columns, page_content)\n",
    "    if PROVIDE_SOURCE_TABLE and source_csv_str:\n",
    "        user_msg += f\"\\n\\nSource table as CSV:\\n{source_csv_str}\"\n",
    "    print(f\"[FETCH] Table: {meta.get('name')}, Page: {page_content}, Model: {model_name}\")\n",
    "    content, latency, usage, error, raw_response = fetch_page_llm(user_msg, LLM_MODEL, OPENROUTER_API_KEY, system_msg)\n",
    "    return {\n",
    "        'content': content,\n",
    "        'latency': latency,\n",
    "        'usage': usage,\n",
    "        'error': error,\n",
    "        'page_key': page_key,\n",
    "        'raw_response': raw_response\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bad1417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FULL RUN] Using new output folder: processing/2_fetched_pages/20250902_003227\n",
      "[PROCESSING] Table: english_latin_rivalry_1887_2012, Source Columns: ['Year', 'Latin', 'English', 'Winner']\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: None, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/25_english_latin_rivalry_1887_2012_naive_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/25_english_latin_rivalry_1887_2012_naive_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 0}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 4}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 5}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 6}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 10}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 12}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 22}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 23}, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/25_english_latin_rivalry_1887_2012_naive_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/25_english_latin_rivalry_1887_2012_naive_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 0}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 4}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 5}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 6}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 10}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 12}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 22}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 23}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 44}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'English', 'value': 44}, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/25_english_latin_rivalry_1887_2012_statistical_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/25_english_latin_rivalry_1887_2012_statistical_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1887-1894'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1895-1902'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1903-1910'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1911-1918'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1919-1926'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/25_english_latin_rivalry_1887_2012_statistical_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/25_english_latin_rivalry_1887_2012_statistical_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1887-1894'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1895-1902'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1903-1910'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1911-1918'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1919-1926'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/25_english_latin_rivalry_1887_2012_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/25_english_latin_rivalry_1887_2012_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1880s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1890s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1900s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1910s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1920s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/25_english_latin_rivalry_1887_2012_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/25_english_latin_rivalry_1887_2012_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1880s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1890s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1900s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1910s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'decade', 'value': '1920s'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/25_english_latin_rivalry_1887_2012_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/25_english_latin_rivalry_1887_2012_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1887-1890'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1891-1894'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1895-1898'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1899-1902'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1903-1906'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/25_english_latin_rivalry_1887_2012_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/25_english_latin_rivalry_1887_2012_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1887-1890'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1891-1894'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1895-1898'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1899-1902'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: english_latin_rivalry_1887_2012, Page: {'field': 'Year', 'value': '1903-1906'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/25_english_latin_rivalry_1887_2012_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/25_english_latin_rivalry_1887_2012_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250902_003227/25_english_latin_rivalry_1887_2012_metrics.json\n",
      "[PROCESSING] Table: australia_demographics_1900_2010, Source Columns: ['Year', 'Average population (x 1,000)', 'Live births', 'Deaths', 'Natural change', 'Crude birth rate (per 1,000)', 'Crude death rate (per 1,000)', 'Natural change (per 1,000)', 'Fertility rates']\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: None, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/25_english_latin_rivalry_1887_2012_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/25_english_latin_rivalry_1887_2012_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250902_003227/25_english_latin_rivalry_1887_2012_metrics.json\n",
      "[PROCESSING] Table: australia_demographics_1900_2010, Source Columns: ['Year', 'Average population (x 1,000)', 'Live births', 'Deaths', 'Natural change', 'Crude birth rate (per 1,000)', 'Crude death rate (per 1,000)', 'Natural change (per 1,000)', 'Fertility rates']\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: None, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/3_australia_demographics_1900_2010_naive_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/3_australia_demographics_1900_2010_naive_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': 'NaN'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': '0-1'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': '1-2'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': '2-3'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': '3-4'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': '4-5'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': '5-6'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': '6-7'}, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/3_australia_demographics_1900_2010_naive_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/3_australia_demographics_1900_2010_naive_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': 'NaN'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': '0-1'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': '1-2'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': '2-3'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': '3-4'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': '4-5'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': '5-6'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': '6-7'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': '7-8'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': '7-8'}, Model: google_gemini-2.0-flash-001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_23615/3993774273.py:117: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': '8-9'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Fertility rates', 'value': '9-10'}, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/3_australia_demographics_1900_2010_statistical_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/3_australia_demographics_1900_2010_statistical_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1900-1910'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1911-1920'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/3_australia_demographics_1900_2010_statistical_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/3_australia_demographics_1900_2010_statistical_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1900-1910'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1911-1920'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/3_australia_demographics_1900_2010_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/3_australia_demographics_1900_2010_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1900-1919'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1920-1939'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1940-1959'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1960-1979'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1980-1999'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/3_australia_demographics_1900_2010_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/3_australia_demographics_1900_2010_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1900-1919'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1920-1939'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1940-1959'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1960-1979'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1980-1999'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/3_australia_demographics_1900_2010_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/3_australia_demographics_1900_2010_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1900-1910'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1911-1920'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1921-1930'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1931-1940'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1941-1950'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/3_australia_demographics_1900_2010_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/3_australia_demographics_1900_2010_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1900-1910'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1911-1920'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1921-1930'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1931-1940'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: australia_demographics_1900_2010, Page: {'field': 'Year', 'value': '1941-1950'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/3_australia_demographics_1900_2010_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/3_australia_demographics_1900_2010_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250902_003227/3_australia_demographics_1900_2010_metrics.json\n",
      "[PROCESSING] Table: elements, Source Columns: ['Z', 'Sym', 'Element', 'Group', 'Period', 'Atomic weight u', 'Density g / cm 3', 'Melt K', 'Boil K', 'Heat J / g * K', 'Neg']\n",
      "[FETCH] Table: elements, Page: None, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/3_australia_demographics_1900_2010_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/3_australia_demographics_1900_2010_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250902_003227/3_australia_demographics_1900_2010_metrics.json\n",
      "[PROCESSING] Table: elements, Source Columns: ['Z', 'Sym', 'Element', 'Group', 'Period', 'Atomic weight u', 'Density g / cm 3', 'Melt K', 'Boil K', 'Heat J / g * K', 'Neg']\n",
      "[FETCH] Table: elements, Page: None, Model: google_gemini-2.0-flash-001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_23615/3993774273.py:117: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/15_elements_naive_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/15_elements_naive_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': 1}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': 2}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': 3}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': 4}, Model: google_gemini-2.0-flash-001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_23615/3993774273.py:117: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/15_elements_statistical_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/15_elements_statistical_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': '1'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': '2'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': '3'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': '4'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': '5'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': '6'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: elements, Page: {'field': 'Period', 'value': '7'}, Model: google_gemini-2.5-flash-lite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_23615/3993774273.py:117: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/15_elements_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/15_elements_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: elements, Page: {'field': 'Period,Group', 'value': '1,1-18'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: elements, Page: {'field': 'Period,Group', 'value': '2,1-18'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: elements, Page: {'field': 'Period,Group', 'value': '3,1-18'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: elements, Page: {'field': 'Period,Group', 'value': '4,1-18'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: elements, Page: {'field': 'Period,Group', 'value': '5-7,1-18'}, Model: deepseek_deepseek-chat-v3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_23615/3993774273.py:117: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/15_elements_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/15_elements_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '1'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '2'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '13'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '14'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: elements, Page: {'field': 'Group', 'value': '18'}, Model: openai_gpt-4o-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_23615/3993774273.py:117: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/15_elements_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/15_elements_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250902_003227/15_elements_metrics.json\n",
      "[PROCESSING] Table: rock_band_downloadable_2011, Source Columns: ['Song title', 'Artist', 'Year', 'Genre', 'Single / Pack name', 'Release date', 'Family Friendly']\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: None, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/12_rock_band_downloadable_2011_naive_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/12_rock_band_downloadable_2011_naive_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '1955'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '1956'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '1958'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '1959'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '1961'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '1964'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '2006'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '2007'}, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/12_rock_band_downloadable_2011_naive_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/12_rock_band_downloadable_2011_naive_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '1955'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '1956'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '1958'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '1959'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '1961'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '1964'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '2006'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '2007'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '2008'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '2009'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '2000'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '2008'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '2009'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '2000'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '2003'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '2003'}, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/12_rock_band_downloadable_2011_statistical_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/12_rock_band_downloadable_2011_statistical_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '2011'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/12_rock_band_downloadable_2011_statistical_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/12_rock_band_downloadable_2011_statistical_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '2011'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/12_rock_band_downloadable_2011_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/12_rock_band_downloadable_2011_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Release date', 'value': 'Jan.4,2011'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Release date', 'value': 'Jan.11,2011'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Release date', 'value': 'Jan.18,2011'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Release date', 'value': 'Jan.25,2011'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Release date', 'value': 'Feb.1,2011'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/12_rock_band_downloadable_2011_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/12_rock_band_downloadable_2011_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Release date', 'value': 'Jan.4,2011'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Release date', 'value': 'Jan.11,2011'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Release date', 'value': 'Jan.18,2011'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Release date', 'value': 'Jan.25,2011'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Release date', 'value': 'Feb.1,2011'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/12_rock_band_downloadable_2011_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/12_rock_band_downloadable_2011_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '2007-2008'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '2009-2010'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '2011'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/12_rock_band_downloadable_2011_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/12_rock_band_downloadable_2011_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '2007-2008'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '2009-2010'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: rock_band_downloadable_2011, Page: {'field': 'Year', 'value': '2011'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/12_rock_band_downloadable_2011_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/12_rock_band_downloadable_2011_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250902_003227/12_rock_band_downloadable_2011_metrics.json\n",
      "[PROCESSING] Table: living_proof_the_farewell_tour, Source Columns: ['Date', 'City', 'Country', 'Venue']\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: None, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/12_rock_band_downloadable_2011_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/12_rock_band_downloadable_2011_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250902_003227/12_rock_band_downloadable_2011_metrics.json\n",
      "[PROCESSING] Table: living_proof_the_farewell_tour, Source Columns: ['Date', 'City', 'Country', 'Venue']\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: None, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/19_living_proof_the_farewell_tour_naive_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/19_living_proof_the_farewell_tour_naive_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': 'June 14, 2002'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': 'June 15, 2002'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': 'June 18, 2002'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': 'June 19, 2002'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/19_living_proof_the_farewell_tour_naive_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/19_living_proof_the_farewell_tour_naive_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': 'June 14, 2002'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': 'June 15, 2002'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': 'June 18, 2002'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': 'June 19, 2002'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/19_living_proof_the_farewell_tour_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/19_living_proof_the_farewell_tour_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': 'June 14-22, 2002'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': 'June 24-30, 2002'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': 'July 2-6, 2002'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': 'July 8-13, 2002'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': 'July 15, 2002'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/19_living_proof_the_farewell_tour_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/19_living_proof_the_farewell_tour_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': 'June 14-22, 2002'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': 'June 24-30, 2002'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': 'July 2-6, 2002'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': 'July 8-13, 2002'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': 'July 15, 2002'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/19_living_proof_the_farewell_tour_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/19_living_proof_the_farewell_tour_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': 'June 14, 2002 - June 19, 2002'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': 'June 20, 2002 - June 25, 2002'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': 'June 26, 2002 - July 1, 2002'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': 'July 2, 2002 - July 7, 2002'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': 'July 8, 2002 - July 15, 2002'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/19_living_proof_the_farewell_tour_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/19_living_proof_the_farewell_tour_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': 'June 14, 2002 - June 19, 2002'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': 'June 20, 2002 - June 25, 2002'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': 'June 26, 2002 - July 1, 2002'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': 'July 2, 2002 - July 7, 2002'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: living_proof_the_farewell_tour, Page: {'field': 'Date', 'value': 'July 8, 2002 - July 15, 2002'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/19_living_proof_the_farewell_tour_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/19_living_proof_the_farewell_tour_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250902_003227/19_living_proof_the_farewell_tour_metrics.json\n",
      "[PROCESSING] Table: portuguese_grape_varieties, Source Columns: ['Grape', 'Color']\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: None, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/19_living_proof_the_farewell_tour_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/19_living_proof_the_farewell_tour_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250902_003227/19_living_proof_the_farewell_tour_metrics.json\n",
      "[PROCESSING] Table: portuguese_grape_varieties, Source Columns: ['Grape', 'Color']\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: None, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/33_portuguese_grape_varieties_naive_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/33_portuguese_grape_varieties_naive_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: {'field': 'Grape', 'value': 'Alfrocheiro'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: {'field': 'Grape', 'value': 'Alicante Bouschet'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: {'field': 'Grape', 'value': 'Alvaraca'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: {'field': 'Grape', 'value': 'Alvarelhão'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/33_portuguese_grape_varieties_naive_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/33_portuguese_grape_varieties_naive_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: {'field': 'Grape', 'value': 'Alfrocheiro'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: {'field': 'Grape', 'value': 'Alicante Bouschet'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: {'field': 'Grape', 'value': 'Alvaraca'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: {'field': 'Grape', 'value': 'Alvarelhão'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/33_portuguese_grape_varieties_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/33_portuguese_grape_varieties_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: {'field': 'Color', 'value': 'Red'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: {'field': 'Color', 'value': 'White'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/33_portuguese_grape_varieties_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/33_portuguese_grape_varieties_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: {'field': 'Color', 'value': 'Red'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: {'field': 'Color', 'value': 'White'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/33_portuguese_grape_varieties_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/33_portuguese_grape_varieties_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: {'field': 'Color', 'value': 'Red'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: {'field': 'Color', 'value': 'White'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/33_portuguese_grape_varieties_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/33_portuguese_grape_varieties_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: {'field': 'Color', 'value': 'Red'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: portuguese_grape_varieties, Page: {'field': 'Color', 'value': 'White'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/33_portuguese_grape_varieties_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/33_portuguese_grape_varieties_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250902_003227/33_portuguese_grape_varieties_metrics.json\n",
      "[PROCESSING] Table: republican_straw_polls_2012, Source Columns: ['Zip Code', 'Ron Paul', 'Mitt Romney', 'Gary Johnson', 'Rick Santorum', 'Virgil Goode', 'Buddy Roemer', 'Newt Gingrich', 'Barack Obama', 'Other', 'Total']\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: None, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/33_portuguese_grape_varieties_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/33_portuguese_grape_varieties_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250902_003227/33_portuguese_grape_varieties_metrics.json\n",
      "[PROCESSING] Table: republican_straw_polls_2012, Source Columns: ['Zip Code', 'Ron Paul', 'Mitt Romney', 'Gary Johnson', 'Rick Santorum', 'Virgil Goode', 'Buddy Roemer', 'Newt Gingrich', 'Barack Obama', 'Other', 'Total']\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: None, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/0_republican_straw_polls_2012_naive_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/0_republican_straw_polls_2012_naive_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 0}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 1}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 2}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 3}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 4}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 5}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 6}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 7}, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/0_republican_straw_polls_2012_naive_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/0_republican_straw_polls_2012_naive_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 0}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 1}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 2}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 3}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 4}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 5}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 6}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 7}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 8}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 9}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 8}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 9}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 10}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 11}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 10}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 11}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 12}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 13}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 12}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 13}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 14}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 14}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 15}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 16}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 15}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 16}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 17}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 18}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 17}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Other', 'value': 18}, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/0_republican_straw_polls_2012_statistical_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/0_republican_straw_polls_2012_statistical_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83201-83401'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83402-83642'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83646-83705'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83706-83713'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83714-83814'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/0_republican_straw_polls_2012_statistical_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/0_republican_straw_polls_2012_statistical_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83201-83401'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83402-83642'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83646-83705'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83706-83713'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83714-83814'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/0_republican_straw_polls_2012_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/0_republican_straw_polls_2012_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83000-83200'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83201-83400'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83401-83600'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83601-83800'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83801-84000'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/0_republican_straw_polls_2012_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/0_republican_straw_polls_2012_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83000-83200'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83201-83400'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83401-83600'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83601-83800'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83801-84000'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/0_republican_straw_polls_2012_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/0_republican_straw_polls_2012_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83200-83209'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83210-83219'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83220-83229'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83230-83239'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83240-83249'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/0_republican_straw_polls_2012_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/0_republican_straw_polls_2012_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83200-83209'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83210-83219'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83220-83229'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83230-83239'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: republican_straw_polls_2012, Page: {'field': 'Zip Code', 'value': '83240-83249'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/0_republican_straw_polls_2012_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/0_republican_straw_polls_2012_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250902_003227/0_republican_straw_polls_2012_metrics.json\n",
      "[PROCESSING] Table: miss_new_york_usa_delegates_2012, Source Columns: ['Represents', 'Candidate']\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: None, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/0_republican_straw_polls_2012_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/0_republican_straw_polls_2012_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250902_003227/0_republican_straw_polls_2012_metrics.json\n",
      "[PROCESSING] Table: miss_new_york_usa_delegates_2012, Source Columns: ['Represents', 'Candidate']\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: None, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/59_miss_new_york_usa_delegates_2012_naive_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/59_miss_new_york_usa_delegates_2012_naive_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Albany'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Amsterdam'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Au Sable Valley'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Avenue of the Americas'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Big Apple'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/59_miss_new_york_usa_delegates_2012_naive_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/59_miss_new_york_usa_delegates_2012_naive_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Albany'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Amsterdam'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Au Sable Valley'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Avenue of the Americas'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Big Apple'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/59_miss_new_york_usa_delegates_2012_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/59_miss_new_york_usa_delegates_2012_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'first_letter_of_Candidate', 'value': 'A-C'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'first_letter_of_Candidate', 'value': 'D-F'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'first_letter_of_Candidate', 'value': 'G-I'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'first_letter_of_Candidate', 'value': 'J-L'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'first_letter_of_Candidate', 'value': 'M-O'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'first_letter_of_Candidate', 'value': 'P-R'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'first_letter_of_Candidate', 'value': 'S-U'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'first_letter_of_Candidate', 'value': 'V-Z'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/59_miss_new_york_usa_delegates_2012_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/59_miss_new_york_usa_delegates_2012_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'first_letter_of_Candidate', 'value': 'A-C'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'first_letter_of_Candidate', 'value': 'D-F'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'first_letter_of_Candidate', 'value': 'G-I'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'first_letter_of_Candidate', 'value': 'J-L'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'first_letter_of_Candidate', 'value': 'M-O'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'first_letter_of_Candidate', 'value': 'P-R'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'first_letter_of_Candidate', 'value': 'S-U'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'first_letter_of_Candidate', 'value': 'V-Z'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/59_miss_new_york_usa_delegates_2012_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/59_miss_new_york_usa_delegates_2012_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Albany'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Amsterdam'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Au Sable Valley'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Avenue of the Americas'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Big Apple'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/59_miss_new_york_usa_delegates_2012_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/59_miss_new_york_usa_delegates_2012_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Albany'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Amsterdam'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Au Sable Valley'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Avenue of the Americas'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: miss_new_york_usa_delegates_2012, Page: {'field': 'Represents', 'value': 'Big Apple'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/59_miss_new_york_usa_delegates_2012_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/59_miss_new_york_usa_delegates_2012_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250902_003227/59_miss_new_york_usa_delegates_2012_metrics.json\n",
      "[PROCESSING] Table: cross_country_junior_women_1996, Source Columns: ['Rank', 'Athlete', 'Country', 'Time']\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: None, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/59_miss_new_york_usa_delegates_2012_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/59_miss_new_york_usa_delegates_2012_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250902_003227/59_miss_new_york_usa_delegates_2012_metrics.json\n",
      "[PROCESSING] Table: cross_country_junior_women_1996, Source Columns: ['Rank', 'Athlete', 'Country', 'Time']\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: None, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/52_cross_country_junior_women_1996_naive_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/52_cross_country_junior_women_1996_naive_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Country', 'value': 'Ethiopia'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Country', 'value': 'Finland'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Country', 'value': 'Kenya'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Country', 'value': 'Romania'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Country', 'value': 'Japan'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Country', 'value': 'China'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Country', 'value': 'France'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Country', 'value': 'United States'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/52_cross_country_junior_women_1996_naive_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/52_cross_country_junior_women_1996_naive_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Country', 'value': 'Ethiopia'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Country', 'value': 'Finland'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Country', 'value': 'Kenya'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Country', 'value': 'Romania'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Country', 'value': 'Japan'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Country', 'value': 'China'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Country', 'value': 'France'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Country', 'value': 'United States'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/52_cross_country_junior_women_1996_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/52_cross_country_junior_women_1996_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '1-20'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '21-40'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '41-60'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '61-80'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '81-100'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/52_cross_country_junior_women_1996_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/52_cross_country_junior_women_1996_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '1-20'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '21-40'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '41-60'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '61-80'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '81-100'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/52_cross_country_junior_women_1996_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/52_cross_country_junior_women_1996_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '1-5'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '6-10'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '11-15'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '16-20'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/52_cross_country_junior_women_1996_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/52_cross_country_junior_women_1996_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '1-5'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '6-10'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '11-15'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: cross_country_junior_women_1996, Page: {'field': 'Rank', 'value': '16-20'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/52_cross_country_junior_women_1996_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/52_cross_country_junior_women_1996_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250902_003227/52_cross_country_junior_women_1996_metrics.json\n",
      "[PROCESSING] Table: tour_de_france_2009, Source Columns: ['Rider', 'Team', 'Nationality', 'Age']\n",
      "[FETCH] Table: tour_de_france_2009, Page: None, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/52_cross_country_junior_women_1996_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/52_cross_country_junior_women_1996_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250902_003227/52_cross_country_junior_women_1996_metrics.json\n",
      "[PROCESSING] Table: tour_de_france_2009, Source Columns: ['Rider', 'Team', 'Nationality', 'Age']\n",
      "[FETCH] Table: tour_de_france_2009, Page: None, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/9_tour_de_france_2009_naive_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/9_tour_de_france_2009_naive_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 23}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 24}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 25}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 26}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 27}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 28}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 29}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 30}, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/9_tour_de_france_2009_naive_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/9_tour_de_france_2009_naive_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 23}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 24}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 25}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 26}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 27}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 28}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 29}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 30}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 31}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 31}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 32}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 33}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 34}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 35}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 32}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 33}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 34}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 35}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 36}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 36}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 37}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 37}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 38}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 39}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 40}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 38}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 39}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': 40}, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/9_tour_de_france_2009_statistical_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/9_tour_de_france_2009_statistical_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': '20-29'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': '30-40'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/9_tour_de_france_2009_statistical_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/9_tour_de_france_2009_statistical_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': '20-29'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Age', 'value': '30-40'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/9_tour_de_france_2009_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/9_tour_de_france_2009_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Cervélo TestTeam'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Silence-Lotto'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Astana'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/9_tour_de_france_2009_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/9_tour_de_france_2009_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Cervélo TestTeam'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Silence-Lotto'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Astana'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/9_tour_de_france_2009_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/9_tour_de_france_2009_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Cervélo TestTeam'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Silence-Lotto'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Astana'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/9_tour_de_france_2009_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/9_tour_de_france_2009_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Cervélo TestTeam'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Silence-Lotto'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: tour_de_france_2009, Page: {'field': 'Team', 'value': 'Astana'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/9_tour_de_france_2009_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/9_tour_de_france_2009_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250902_003227/9_tour_de_france_2009_metrics.json\n",
      "[PROCESSING] Table: anaheim_ducks_draft_picks_1998_2013, Source Columns: ['Draft', 'Round', 'Pick', 'Player', 'Nationality', 'Pos', 'RS', 'PO']\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: None, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/9_tour_de_france_2009_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/9_tour_de_france_2009_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250902_003227/9_tour_de_france_2009_metrics.json\n",
      "[PROCESSING] Table: anaheim_ducks_draft_picks_1998_2013, Source Columns: ['Draft', 'Round', 'Pick', 'Player', 'Nationality', 'Pos', 'RS', 'PO']\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: None, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/7_anaheim_ducks_draft_picks_1998_2013_naive_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/7_anaheim_ducks_draft_picks_1998_2013_naive_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1993'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1994'}, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/7_anaheim_ducks_draft_picks_1998_2013_naive_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/7_anaheim_ducks_draft_picks_1998_2013_naive_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1993'}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1994'}, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/7_anaheim_ducks_draft_picks_1998_2013_statistical_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/7_anaheim_ducks_draft_picks_1998_2013_statistical_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1993'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1994'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1995-2000'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/7_anaheim_ducks_draft_picks_1998_2013_statistical_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/7_anaheim_ducks_draft_picks_1998_2013_statistical_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1993'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1994'}, Model: google_gemini-2.5-flash-lite\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1995-2000'}, Model: google_gemini-2.5-flash-lite\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/7_anaheim_ducks_draft_picks_1998_2013_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/7_anaheim_ducks_draft_picks_1998_2013_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1993-1997'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1998-2002'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '2003-2007'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '2008-2012'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '2013-2017'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/7_anaheim_ducks_draft_picks_1998_2013_llm_google_gemini-2.5-flash-lite.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/7_anaheim_ducks_draft_picks_1998_2013_llm_google_gemini-2.5-flash-lite_llm_logs.json\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1993-1997'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1998-2002'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '2003-2007'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '2008-2012'}, Model: deepseek_deepseek-chat-v3.1\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '2013-2017'}, Model: deepseek_deepseek-chat-v3.1\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/7_anaheim_ducks_draft_picks_1998_2013_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/7_anaheim_ducks_draft_picks_1998_2013_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1993'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1994'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1995'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1996'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1997'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/7_anaheim_ducks_draft_picks_1998_2013_llm_deepseek_deepseek-chat-v3.1.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/7_anaheim_ducks_draft_picks_1998_2013_llm_deepseek_deepseek-chat-v3.1_llm_logs.json\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1993'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1994'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1995'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1996'}, Model: openai_gpt-4o-mini\n",
      "[FETCH] Table: anaheim_ducks_draft_picks_1998_2013, Page: {'field': 'Draft', 'value': '1997'}, Model: openai_gpt-4o-mini\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/7_anaheim_ducks_draft_picks_1998_2013_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/7_anaheim_ducks_draft_picks_1998_2013_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250902_003227/7_anaheim_ducks_draft_picks_1998_2013_metrics.json\n",
      "[PROCESSING] Table: belgium_demographics_1900_2011, Source Columns: ['Year', 'Average population (x 1,000)', 'Live births', 'Deaths', 'Natural change', 'Crude birth rate (per 1,000)', 'Crude death rate (per 1,000)', 'Natural change (per 1,000)', 'Fertility rates']\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: None, Model: google_gemini-2.0-flash-001\n",
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/7_anaheim_ducks_draft_picks_1998_2013_llm_openai_gpt-4o-mini.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/7_anaheim_ducks_draft_picks_1998_2013_llm_openai_gpt-4o-mini_llm_logs.json\n",
      "Saved JSON metadata: processing/2_fetched_pages/20250902_003227/7_anaheim_ducks_draft_picks_1998_2013_metrics.json\n",
      "[PROCESSING] Table: belgium_demographics_1900_2011, Source Columns: ['Year', 'Average population (x 1,000)', 'Live births', 'Deaths', 'Natural change', 'Crude birth rate (per 1,000)', 'Crude death rate (per 1,000)', 'Natural change (per 1,000)', 'Fertility rates']\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: None, Model: google_gemini-2.0-flash-001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/dzjx_6bx24960zc7sd87xsq400xh_z/T/ipykernel_23615/3993774273.py:117: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged CSV: processing/2_fetched_pages/20250902_003227/2_belgium_demographics_1900_2011_naive_google_gemini-2.0-flash-001.csv\n",
      "Saved LLM logs: processing/2_fetched_pages/20250902_003227/2_belgium_demographics_1900_2011_naive_google_gemini-2.0-flash-001_llm_logs.json\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': {'range': '11-15'}}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': {'range': '16-20'}}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': {'range': '21-25'}}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': {'range': '26-30'}}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': {'range': '31-35'}}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': {'range': '36-40'}}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': {'range': '41-45'}}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': {'range': '46-50'}}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': {'range': '51-55'}}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': {'range': '56-60'}}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': {'range': '51-55'}}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': {'range': '56-60'}}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': {'range': '61-65'}}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': {'range': '61-65'}}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': {'range': '66-70'}}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': {'range': '66-70'}}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': {'range': '71-75'}}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': {'range': '71-75'}}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': {'range': '76-80'}}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': {'range': '76-80'}}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': {'range': '81-85'}}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': {'range': '81-85'}}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': {'range': '86-90'}}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': {'range': '86-90'}}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': {'range': '91-95'}}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': {'range': '96-100'}}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': {'range': '91-95'}}, Model: google_gemini-2.0-flash-001\n",
      "[FETCH] Table: belgium_demographics_1900_2011, Page: {'field': 'Crude death rate (per 1,000)', 'value': {'range': '96-100'}}, Model: google_gemini-2.0-flash-001\n"
     ]
    }
   ],
   "source": [
    "# Fetch Pages Using LLM and Record Metrics (Parallelized)\n",
    "from io import StringIO\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "PROVIDE_SOURCE_TABLE = False  # If True, include source table as CSV in the prompt\n",
    "NUM_WORKERS = 8\n",
    "LLM_TIMEOUT = 30  # seconds\n",
    "LLM_MODEL = 'openai/gpt-4o-mini'  # Use this model for all criteria\n",
    "OPENROUTER_API_KEY='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'\n",
    "TOGGLE_USE_EXECUTOR = True  # Toggle whether to use ThreadPoolExecutor for parallel fetching\n",
    "# OPENROUTER_API_KEY = os.environ.get('OPENROUTER_API_KEY', '')\n",
    "# print('OPENROUTER_API_KEY:', OPENROUTER_API_KEY)\n",
    "\n",
    "output_root = 'processing/2_fetched_pages/'\n",
    "\n",
    "table_generator = TableGenerator_JSON()\n",
    "\n",
    "def get_latest_timestamped_dir(root):\n",
    "    folders = [f for f in os.listdir(root) if os.path.isdir(os.path.join(root, f))]\n",
    "    if not folders:\n",
    "        return None\n",
    "    # Sort by timestamp in folder name (assuming YYYYMMDD_HHMMSS)\n",
    "    return sorted(folders)[-1]\n",
    "\n",
    "if INCREMENT_MODE:\n",
    "    output_root = 'processing/2_fetched_pages/'\n",
    "    latest_dir = get_latest_timestamped_dir(output_root)\n",
    "    if latest_dir:\n",
    "        output_folder = os.path.join(output_root, latest_dir)\n",
    "        print(f\"[INCREMENT] Using latest output folder: {output_folder}\")\n",
    "    else:\n",
    "        output_folder = os.path.join(output_root, timestamp)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        print(f\"[INCREMENT] No previous folder found, using new: {output_folder}\")\n",
    "    # Build set of already processed table names\n",
    "    existing_metrics = set()\n",
    "    for fname in os.listdir(output_folder):\n",
    "        if fname.endswith('_metrics.json'):\n",
    "            parts = fname.split('_metrics.json')[0].split('_', 1)\n",
    "            if len(parts) == 2:\n",
    "                existing_metrics.add(parts[1])  # table name\n",
    "            else:\n",
    "                existing_metrics.add(parts[0])  # fallback\n",
    "    print(f\"[INCREMENT] Existing metrics found for tables: {existing_metrics}\")\n",
    "else:\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    output_folder = os.path.join(output_root, timestamp)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    print(f\"[FULL RUN] Using new output folder: {output_folder}\")\n",
    "\n",
    "for table in tables:\n",
    "    meta = table['meta']\n",
    "    criteria = table['criteria']\n",
    "    if INCREMENT_MODE and meta.get('name') in existing_metrics:\n",
    "        print(f\"[INCREMENT] Skipping table {meta.get('name')} (metrics.json exists)\")\n",
    "        continue\n",
    "    source_csv_path = meta.get('source_file')\n",
    "    source_csv_str = ''\n",
    "    source_columns = None\n",
    "    source_df = None\n",
    "    if source_csv_path and os.path.exists(source_csv_path):\n",
    "        try:\n",
    "            source_df = pd.read_csv(source_csv_path)\n",
    "            source_csv_str = source_df.to_csv(index=False)\n",
    "            source_columns = list(source_df.columns)\n",
    "            csv_path = os.path.join(output_folder, f\"{meta.get('id','')}_{meta['file']}\")\n",
    "            source_df.to_csv(csv_path, index=False)\n",
    "        except Exception as e:\n",
    "            print(f'[WARNING] Could not load source CSV for {meta.get(\"name\")}: {e}')\n",
    "            source_csv_str = ''\n",
    "            source_columns = None\n",
    "    print(f\"[PROCESSING] Table: {meta.get('name')}, Source Columns: {source_columns}\")\n",
    "    table_results = {}\n",
    "    for method, crit in criteria.items():\n",
    "        # For llm, collect top recommendation from all listed models\n",
    "        if method == 'llm':\n",
    "            criteria_list = []\n",
    "            for model_name, model_criteria in crit.items():\n",
    "                if not model_criteria:\n",
    "                    continue\n",
    "                top_crit = model_criteria[0] if isinstance(model_criteria, list) else model_criteria\n",
    "                criteria_list.append((model_name, top_crit))\n",
    "        else:\n",
    "            criteria_list = [(LLM_MODEL, crit)]\n",
    "        for model_name, crit_obj in criteria_list:\n",
    "            model_name = model_name.replace('/', '_')\n",
    "            pages = crit_obj.get('pages', [])\n",
    "            if source_columns:\n",
    "                merged_df = pd.DataFrame(columns=source_columns)\n",
    "            else:\n",
    "                merged_df = pd.DataFrame()\n",
    "            metrics = []\n",
    "            llm_logs = []  # Collect LLM queries and responses for each page\n",
    "            # Prepare tasks for all pages\n",
    "            tasks = []\n",
    "            page_prompts = {}  # page_key -> prompt string\n",
    "            raw_responses = {}  # page_key -> raw response string\n",
    "            for page_key in pages:\n",
    "                # Build the prompt string for each page\n",
    "                page_content = {'field': crit_obj.get('criteria',''), 'value': page_key} if page_key != 'ALL' else None\n",
    "                system_msg, user_msg = table_generator.generate_prompts(meta.get('query_without_cutoff'), source_columns, page_content)\n",
    "                if PROVIDE_SOURCE_TABLE and source_csv_str:\n",
    "                    user_msg += f\"\\n\\nSource table as CSV:\\n{source_csv_str}\"\n",
    "                tasks.append((meta, crit_obj, page_key, model_name, source_columns, source_csv_str if PROVIDE_SOURCE_TABLE else None))\n",
    "                page_prompts[str(page_key)] = user_msg\n",
    "            results = []\n",
    "            if TOGGLE_USE_EXECUTOR:\n",
    "                with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
    "                    future_to_page = {executor.submit(fetch_page_task, t): t[2] for t in tasks}\n",
    "                    for future in as_completed(future_to_page):\n",
    "                        page_key = future_to_page[future]\n",
    "                        res = future.result()\n",
    "                        metrics.append({'latency': res['latency'], 'usage': res['usage'], 'error': res['error']})\n",
    "                        if res['content'] is not None:\n",
    "                            try:\n",
    "                                df_page = res['content']\n",
    "                                merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n",
    "                            except Exception:\n",
    "                                print(f\"[WARNING] Skipping non-CSV response for table {meta.get('name')}, page {page_key}, model {model_name}\")\n",
    "                        # Save LLM query, raw response, and parsed response for this page\n",
    "                        llm_logs.append({\n",
    "                            'page_key': page_key,\n",
    "                            'query': page_prompts.get(page_key, ''),\n",
    "                            'raw_response': res.get('raw_response', None),\n",
    "                            'response': res.get('content', None),\n",
    "                            'latency': res['latency'],\n",
    "                            'usage': res['usage'],\n",
    "                            'error': res['error']\n",
    "                        })\n",
    "            else:\n",
    "                # Sequential execution\n",
    "                for idx, t in enumerate(tasks):\n",
    "                    page_key = t[2]\n",
    "                    res = fetch_page_task(t)\n",
    "                    metrics.append({'latency': res['latency'], 'usage': res['usage'], 'error': res['error']})\n",
    "                    if res['content'] is not None:\n",
    "                        try:\n",
    "                            df_page = res['content']\n",
    "                            merged_df = pd.concat([merged_df, df_page], ignore_index=True)\n",
    "                        except Exception:\n",
    "                            print(f\"[WARNING] Skipping non-CSV response for table {meta.get('name')}, page {page_key}, model {model_name}\")\n",
    "                    # Save LLM query, raw response, and parsed response for this page\n",
    "                    llm_logs.append({\n",
    "                        'page_key': page_key,\n",
    "                        'query': page_prompts.get(page_key, ''),\n",
    "                        'raw_response': res.get('raw_response', None),\n",
    "                        'response': res.get('content', None),\n",
    "                        'latency': res['latency'],\n",
    "                        'usage': res['usage'],\n",
    "                        'error': res['error']\n",
    "                    })\n",
    "            if merged_df is not None and not merged_df.empty:\n",
    "                csv_name = f\"{meta.get('id','')}_{meta.get('name','')}_{method}_{model_name}.csv\"\n",
    "                csv_path = os.path.join(output_folder, csv_name)\n",
    "                merged_df.to_csv(csv_path, index=False)\n",
    "                print(f'Saved merged CSV: {csv_path}')\n",
    "                # Save LLM logs for this table/method/model\n",
    "                llm_log_name = f\"{meta.get('id','')}_{meta.get('name','')}_{method}_{model_name}_llm_logs.json\"\n",
    "                llm_log_path = os.path.join(output_folder, llm_log_name)\n",
    "                # Convert DataFrames in 'response' to dicts for serialization\n",
    "                for log in llm_logs:\n",
    "                    if hasattr(log['response'], 'to_dict'):\n",
    "                        log['response'] = log['response'].to_dict()\n",
    "                with open(llm_log_path, 'w') as f:\n",
    "                    json.dump(llm_logs, f, indent=2)\n",
    "                print(f'Saved LLM logs: {llm_log_path}')\n",
    "            else:\n",
    "                metrics.append({'latency': None, 'usage': None, 'error': 'Merged DataFrame is empty'})\n",
    "            # After building merged_df and metrics:\n",
    "            metric_result = compute_metrics(merged_df, source_columns, metrics, source_df)\n",
    "            table_results[f'{method}_{model_name}'] = {\n",
    "                'merged_df': merged_df,\n",
    "                'metrics': metrics,\n",
    "                'criteria': crit_obj,\n",
    "                **metric_result\n",
    "            }\n",
    "    out_json = {\n",
    "        'meta': meta,\n",
    "        'results': {}\n",
    "    }\n",
    "    for key, res in table_results.items():\n",
    "        out_json['results'][key] = {\n",
    "            'criteria': res.get('criteria'),\n",
    "            'metrics': res.get('metrics'),\n",
    "            'row_count': res.get('row_count'),\n",
    "            'column_consistency': res.get('column_consistency'),\n",
    "            'error_rate': res.get('error_rate'),\n",
    "            'avg_latency': res.get('avg_latency'),\n",
    "            'sum_tokens': res.get('sum_tokens'),\n",
    "            'accuracy': res.get('accuracy')\n",
    "        }\n",
    "    json_name = f\"{meta.get('id','')}_{meta.get('name','')}_metrics.json\"\n",
    "    json_path = os.path.join(output_folder, json_name)\n",
    "    os.makedirs(os.path.dirname(json_path), exist_ok=True)\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(out_json, f, indent=2)\n",
    "    print(f'Saved JSON metadata: {json_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
