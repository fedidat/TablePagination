{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6167645",
   "metadata": {},
   "source": [
    "# Page Fetching for Pagination Strategies\n",
    "\n",
    "This notebook loads pagination plans from Stage 1 and executes the actual data fetching for each strategy.\n",
    "\n",
    "## Strategies:\n",
    "1. **Full Table** - Single query for entire table\n",
    "2. **Row by Row** - Fetch each row individually using key values\n",
    "3. **Attribute-based** - Fetch pages by partition values\n",
    "4. **Classic Pagination** - Offset-based iterative fetching\n",
    "5. **Range-based** - Fetch by defined ranges\n",
    "\n",
    "## Output:\n",
    "- CSV files: Aggregated table data (for metrics calculation)\n",
    "- JSON files: Detailed execution logs with per-page metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a37742",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dea23e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy directory: /Users/bef/Desktop/TablePagination/processing/1_strategy/20251005_004530\n",
      "Ground truth directory: /Users/bef/Desktop/TablePagination/processing/0_data/20251004_213355\n",
      "Output base: /Users/bef/Desktop/TablePagination/processing/2_fetching\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import openai\n",
    "\n",
    "# ===== CONFIGURATION =====\n",
    "# MAX_TABLES: Limit number of tables to process (None for all)\n",
    "MAX_TABLES = 30\n",
    "\n",
    "# MAX_PAGES: Limit pages per table per strategy (None for all, useful for testing)\n",
    "MAX_PAGES = None\n",
    "\n",
    "# PARALLEL_STRATEGIES: Run strategies in parallel per table\n",
    "PARALLEL_STRATEGIES = True\n",
    "\n",
    "# MAX_WORKERS: Number of parallel strategy executions per table\n",
    "MAX_WORKERS = 5\n",
    "\n",
    "# MAX_RETRIES: Number of retries for failed LLM calls\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "# MAX_PAGINATION_PAGES: Failsafe for classic_pagination\n",
    "MAX_PAGINATION_PAGES = 10\n",
    "\n",
    "# Paths\n",
    "ROOT = Path('.')\n",
    "PROCESSING_ROOT = ROOT / 'processing'\n",
    "STRATEGY_DIR = PROCESSING_ROOT / '1_strategy'\n",
    "OUTPUT_ROOT = PROCESSING_ROOT / '2_fetching'\n",
    "\n",
    "# Find the most recent strategy directory\n",
    "strategy_subdirs = sorted([d for d in STRATEGY_DIR.iterdir() if d.is_dir()], reverse=True)\n",
    "if not strategy_subdirs:\n",
    "    raise FileNotFoundError(f\"No strategy data found in {STRATEGY_DIR}\")\n",
    "\n",
    "LATEST_STRATEGY_DIR = strategy_subdirs[0]\n",
    "\n",
    "# Find ground truth data directory\n",
    "DATA_DIR = PROCESSING_ROOT / '0_data'\n",
    "data_subdirs = sorted([d for d in DATA_DIR.iterdir() if d.is_dir()], reverse=True)\n",
    "if not data_subdirs:\n",
    "    raise FileNotFoundError(f\"No ground truth data found in {DATA_DIR}\")\n",
    "\n",
    "LATEST_DATA_DIR = data_subdirs[0]\n",
    "\n",
    "print('Strategy directory:', LATEST_STRATEGY_DIR.resolve())\n",
    "print('Ground truth directory:', LATEST_DATA_DIR.resolve())\n",
    "print('Output base:', OUTPUT_ROOT.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27259394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ API key loaded from api_key.txt\n",
      "Using model: openai/gpt-5-mini\n"
     ]
    }
   ],
   "source": [
    "# Configure OpenRouter\n",
    "# Read API key from file\n",
    "api_key_file = ROOT / 'api_key.txt'\n",
    "if not api_key_file.exists():\n",
    "    raise ValueError('No API key found. Please create api_key.txt or set OPENROUTER_API_KEY environment variable')\n",
    "with open(api_key_file, 'r') as f:\n",
    "    OPENROUTER_API_KEY = f.read().strip()\n",
    "print('✓ API key loaded from api_key.txt')\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    api_key=OPENROUTER_API_KEY,\n",
    "    base_url=\"https://openrouter.ai/api/v1\"\n",
    ")\n",
    "\n",
    "MODEL = 'openai/gpt-5-mini'\n",
    "print(f'Using model: {MODEL}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a429e4b2",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63accf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_field(s: str) -> str:\n",
    "    \"\"\"Normalize field names (matching original experiment logic).\"\"\"\n",
    "    s = s.lower().replace(\" \",\"_\").replace(\"-\",\"_\").replace(\".\", \"\").replace(\",\",\"_\")\\\n",
    "            .replace(\"(\", \"\").replace(\")\", \"\").replace(\":\", \"\").replace('\"','').replace(\"'\",\"\")\\\n",
    "            .replace(\"/\", \"\")\n",
    "    return re.sub('_+', '_', s)\n",
    "\n",
    "\n",
    "def call_llm_with_metrics_split(system_msg: str, user_msg: str, retry_count: int = 0) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Call LLM with separate system and user messages (matching original experiment).\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    prompt_length = len(system_msg) + len(user_msg)\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[{\"role\": \"system\", \"content\": system_msg},\n",
    "                     {\"role\": \"user\", \"content\": user_msg}],\n",
    "            temperature=0\n",
    "        )\n",
    "        \n",
    "        latency = time.time() - start_time\n",
    "        content = response.choices[0].message.content\n",
    "        \n",
    "        # Check if content is None\n",
    "        if content is None:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': 'Response content is None',\n",
    "                'metrics': {\n",
    "                    'latency': round(latency, 3),\n",
    "                    'prompt_length': prompt_length,\n",
    "                    'retry_count': retry_count,\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        content = content.strip()\n",
    "        response_length = len(content)\n",
    "        \n",
    "        # Extract token usage\n",
    "        usage = response.usage\n",
    "        prompt_tokens = usage.prompt_tokens if usage else 0\n",
    "        completion_tokens = usage.completion_tokens if usage else 0\n",
    "        total_tokens = usage.total_tokens if usage else 0\n",
    "        \n",
    "        return {\n",
    "            'success': True,\n",
    "            'response': content,\n",
    "            'metrics': {\n",
    "                'latency': round(latency, 3),\n",
    "                'prompt_tokens': prompt_tokens,\n",
    "                'completion_tokens': completion_tokens,\n",
    "                'total_tokens': total_tokens,\n",
    "                'prompt_length': prompt_length,\n",
    "                'response_length': response_length,\n",
    "                'retry_count': retry_count,\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "        }\n",
    "    except Exception as e:\n",
    "        latency = time.time() - start_time\n",
    "        return {\n",
    "            'success': False,\n",
    "            'error': str(e),\n",
    "            'metrics': {\n",
    "                'latency': round(latency, 3),\n",
    "                'prompt_length': prompt_length,\n",
    "                'retry_count': retry_count,\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "def call_llm_with_retries(prompt: str = None, system_msg: str = None, user_msg: str = None, max_retries: int = MAX_RETRIES) -> Dict[str, Any]:\n",
    "    \"\"\"Call LLM with retry logic. Supports either single prompt or system+user messages.\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        if system_msg and user_msg:\n",
    "            result = call_llm_with_metrics_split(system_msg, user_msg, retry_count=attempt)\n",
    "        else:\n",
    "            result = call_llm_with_metrics_split(\"You are a retriever of facts.\", prompt, retry_count=attempt)\n",
    "        if result['success']:\n",
    "            return result\n",
    "        print(f\"  Retry {attempt + 1}/{max_retries} after error: {result['error']}\")\n",
    "        time.sleep(1)  # Brief delay between retries\n",
    "    \n",
    "    return result  # Return last failed attempt\n",
    "\n",
    "\n",
    "def parse_json_response(response: str, expect_list: bool = True) -> Tuple[Optional[Any], Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Extract and parse JSON from LLM response (matching original parsing logic).\n",
    "    \n",
    "    Args:\n",
    "        response: The raw LLM response text\n",
    "        expect_list: True for list responses, False for dict responses\n",
    "    \n",
    "    Returns:\n",
    "        - parsed_data: List/Dict or None\n",
    "        - parse_metrics: dict with parse_success, json_start_pos, json_end_pos\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        'parse_success': False,\n",
    "        'json_start_pos': -1,\n",
    "        'json_end_pos': -1\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Matching original logic: find JSON boundaries\n",
    "        if expect_list:\n",
    "            start_char, end_char = '[', ']'\n",
    "        else:\n",
    "            start_char, end_char = '{', '}'\n",
    "        \n",
    "        # Extract JSON portion\n",
    "        start_pos = response.find(start_char)\n",
    "        end_pos = response.rfind(end_char)\n",
    "        \n",
    "        if start_pos != -1 and end_pos != -1:\n",
    "            json_str = response[start_pos:end_pos + 1]\n",
    "            metrics['json_start_pos'] = start_pos\n",
    "            metrics['json_end_pos'] = end_pos + 1\n",
    "            \n",
    "            parsed = json.loads(json_str)\n",
    "            \n",
    "            # Handle wrapped responses\n",
    "            if isinstance(parsed, dict) and len(parsed.keys()) == 1:\n",
    "                parsed = list(parsed.values())[0]\n",
    "            \n",
    "            metrics['parse_success'] = True\n",
    "            return parsed, metrics\n",
    "        \n",
    "        # Fallback: manual parsing (matching original fallback logic)\n",
    "        if not expect_list and start_char not in response and end_char not in response:\n",
    "            return None, metrics\n",
    "            \n",
    "        split_response = response.split(\"{\")\n",
    "        response_json = []\n",
    "        for s in split_response[1:]:\n",
    "            split_s = s.split(\"}\")\n",
    "            if len(split_s) > 1:\n",
    "                content = split_s[0]\n",
    "                attributes = content.split(\",\")\n",
    "                elements = {}\n",
    "                for attr in attributes:\n",
    "                    knv = attr.split(\":\")\n",
    "                    if len(knv) > 1:\n",
    "                        parsed_k = \"%s\" % knv[0].replace('\"','').strip()\n",
    "                        parsed_v = \"%s\" % knv[1].replace('\"','').strip()\n",
    "                        elements[parsed_k] = parsed_v\n",
    "                \n",
    "                if elements:\n",
    "                    response_json.append(elements)\n",
    "        \n",
    "        if response_json:\n",
    "            metrics['parse_success'] = True\n",
    "            if expect_list:\n",
    "                return response_json, metrics\n",
    "            else:\n",
    "                return response_json[0] if response_json else {}, metrics\n",
    "        \n",
    "        return None, metrics\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        metrics['parse_error'] = str(e)\n",
    "        return None, metrics\n",
    "    except Exception as e:\n",
    "        metrics['parse_error'] = str(e)\n",
    "        return None, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2aaafa",
   "metadata": {},
   "source": [
    "## Strategy 1: Full Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e49a77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_full_table(plan: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fetch entire table in one query (matching original B004 approach).\n",
    "    \"\"\"\n",
    "    meta = plan['metadata']\n",
    "    table_title = meta['table_title']\n",
    "    columns = meta['columns']\n",
    "    table_id = plan['table_id']\n",
    "    \n",
    "    # Normalize field names and build response format (matching B004)\n",
    "    num_fields = len(columns)\n",
    "    norm_fields = [normalize_field(f) for f in columns]\n",
    "    fields_json = []\n",
    "    for field in norm_fields:\n",
    "        fields_json.append(f'\"{field}\": \"{field}\"')\n",
    "    response_format = ', '.join(fields_json)\n",
    "    \n",
    "    # Build prompt matching original B004 template exactly\n",
    "    system_msg = \"You are a retriever of facts.\"\n",
    "    user_msg = f\"\"\"List {table_title} - as many as possible to fit into response.\n",
    "The response will be formatted as JSON shown below.\n",
    "Each element of the response will contain {num_fields} fields: {', '.join(columns)}.\n",
    "Do not output any additional text that is not in JSON format.\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "[{{\n",
    "    {response_format}\n",
    "}}]\"\"\"\n",
    "    \n",
    "    print(f\"  Fetching full table...\")\n",
    "    \n",
    "    # Call LLM with separate system and user messages\n",
    "    result = call_llm_with_retries(system_msg=system_msg, user_msg=user_msg)\n",
    "    \n",
    "    page_data = {\n",
    "        'page_number': 1,\n",
    "        'system_msg': system_msg,\n",
    "        'user_msg': user_msg,\n",
    "        'prompt': user_msg,  # For backwards compatibility\n",
    "        'raw_response': result.get('response', ''),\n",
    "        'error': result.get('error'),\n",
    "        **result['metrics']\n",
    "    }\n",
    "    \n",
    "    if result['success']:\n",
    "        parsed_data, parse_metrics = parse_json_response(result['response'], expect_list=True)\n",
    "        page_data.update(parse_metrics)\n",
    "        page_data['rows_returned'] = len(parsed_data) if parsed_data else 0\n",
    "        page_data['parsed_data'] = parsed_data if parsed_data else []\n",
    "    else:\n",
    "        page_data['parse_success'] = False\n",
    "        page_data['rows_returned'] = 0\n",
    "        page_data['parsed_data'] = []\n",
    "    \n",
    "    return {\n",
    "        'pages': [page_data],\n",
    "        'all_rows': page_data['parsed_data']\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b578b05",
   "metadata": {},
   "source": [
    "## Strategy 2: Row by Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a971c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_row_by_row(plan: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fetch each row individually using key values from plan (matching original B008 approach).\n",
    "    \"\"\"\n",
    "    meta = plan['metadata']\n",
    "    config = plan['pagination_config']\n",
    "    \n",
    "    table_title = meta['table_title']\n",
    "    columns = meta['columns']\n",
    "    key_columns = config['key_columns']\n",
    "    key_values = config['key_values']\n",
    "    table_id = plan['table_id']\n",
    "    \n",
    "    # Normalize field names\n",
    "    norm_fields = [normalize_field(f) for f in columns]\n",
    "    norm_keys = [normalize_field(k) for k in key_columns]\n",
    "    \n",
    "    pages = []\n",
    "    all_rows = []\n",
    "    \n",
    "    # Apply MAX_PAGES limit if set\n",
    "    keys_to_fetch = key_values[:MAX_PAGES] if MAX_PAGES else key_values\n",
    "    total_keys = len(key_values)\n",
    "    \n",
    "    if MAX_PAGES and len(key_values) > MAX_PAGES:\n",
    "        print(f\"  Limited to first {MAX_PAGES} rows out of {total_keys}\")\n",
    "    \n",
    "    for page_num, key_combo in enumerate(keys_to_fetch, 1):\n",
    "        # Build WHERE clause for this row\n",
    "        key_conditions = []\n",
    "        for key in key_columns:\n",
    "            norm_key = normalize_field(key)\n",
    "            key_value = key_combo.get(norm_key, 'UNKNOWN')\n",
    "            key_conditions.append(f\"{key} = {key_value}\")\n",
    "        row_key = '(' + ', '.join(key_conditions) + ')'\n",
    "        \n",
    "        # Build response format with key values filled in (matching B008)\n",
    "        fields_json = []\n",
    "        for field in norm_fields:\n",
    "            # Use key values where available, field names otherwise\n",
    "            if field in key_combo:\n",
    "                fields_json.append(f'\"{field}\": \"{key_combo[field]}\"')\n",
    "            else:\n",
    "                fields_json.append(f'\"{field}\": \"{field}\"')\n",
    "        response_format = ', '.join(fields_json)\n",
    "        \n",
    "        # Build prompt matching original B008 template exactly\n",
    "        system_msg = \"You are a retriever of facts.\"\n",
    "        key_column_desc = f\"The key column{'s' if len(key_columns) > 1 else ''} in the table {'are' if len(key_columns) > 1 else 'is'} {', '.join(key_columns)}\"\n",
    "        user_msg = f\"\"\"We want to create a table with the detailed information about {table_title}.\n",
    "Columns in the table are {', '.join(columns)}.\n",
    "{key_column_desc}.\n",
    "Retrieve a single row whose key is {row_key}.\n",
    "The response will be formatted as JSON dictionary shown below.\n",
    "Pay special attention to wrap all property names and values in double quotes!\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "{{\n",
    "    {response_format}\n",
    "}}\"\"\"\n",
    "        \n",
    "        print(f\"  Fetching row {page_num}/{len(keys_to_fetch)}...\")\n",
    "        \n",
    "        result = call_llm_with_retries(system_msg=system_msg, user_msg=user_msg)\n",
    "        \n",
    "        page_data = {\n",
    "            'page_number': page_num,\n",
    "            'key_values': key_combo,\n",
    "            'system_msg': system_msg,\n",
    "            'user_msg': user_msg,\n",
    "            'prompt': user_msg,\n",
    "            'raw_response': result.get('response', ''),\n",
    "            'error': result.get('error'),\n",
    "            **result['metrics']\n",
    "        }\n",
    "        \n",
    "        if result['success']:\n",
    "            # Parse as dict (single row), then wrap in list\n",
    "            parsed_dict, parse_metrics = parse_json_response(result['response'], expect_list=False)\n",
    "            page_data.update(parse_metrics)\n",
    "            \n",
    "            if parsed_dict:\n",
    "                parsed_data = [parsed_dict]  # Wrap dict in list\n",
    "                page_data['rows_returned'] = 1\n",
    "                page_data['parsed_data'] = parsed_data\n",
    "                all_rows.extend(parsed_data)\n",
    "            else:\n",
    "                page_data['rows_returned'] = 0\n",
    "                page_data['parsed_data'] = []\n",
    "        else:\n",
    "            page_data['parse_success'] = False\n",
    "            page_data['rows_returned'] = 0\n",
    "            page_data['parsed_data'] = []\n",
    "        \n",
    "        pages.append(page_data)\n",
    "    \n",
    "    return {\n",
    "        'pages': pages,\n",
    "        'all_rows': all_rows\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6174b1d",
   "metadata": {},
   "source": [
    "## Strategy 3: Attribute-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6eebb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_attribute_based(plan: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fetch pages by partition values (matching original approach).\n",
    "    \"\"\"\n",
    "    meta = plan['metadata']\n",
    "    config = plan['pagination_config']\n",
    "    \n",
    "    table_title = meta['table_title']\n",
    "    columns = meta['columns']\n",
    "    partition_column = config['partition_column']\n",
    "    partition_values = config['partition_values']\n",
    "    table_id = plan['table_id']\n",
    "    \n",
    "    # Normalize field names\n",
    "    num_fields = len(columns)\n",
    "    norm_fields = [normalize_field(f) for f in columns]\n",
    "    \n",
    "    pages = []\n",
    "    all_rows = []\n",
    "    \n",
    "    # Apply MAX_PAGES limit\n",
    "    values_to_fetch = partition_values[:MAX_PAGES] if MAX_PAGES else partition_values\n",
    "    total_values = len(partition_values)\n",
    "    \n",
    "    if MAX_PAGES and len(partition_values) > MAX_PAGES:\n",
    "        print(f\"  Limited to first {MAX_PAGES} partitions out of {total_values}\")\n",
    "    \n",
    "    for page_num, value in enumerate(values_to_fetch, 1):\n",
    "        # Build response format\n",
    "        fields_json = [f'\"{field}\": \"{field}\"' for field in norm_fields]\n",
    "        response_format = ', '.join(fields_json)\n",
    "        \n",
    "        # Build prompt matching original approach\n",
    "        system_msg = \"You are a retriever of facts.\"\n",
    "        user_msg = f\"\"\"List rows from {table_title} where {partition_column} = {value}.\n",
    "The response will be formatted as JSON shown below.\n",
    "Each element of the response will contain {num_fields} fields: {', '.join(columns)}.\n",
    "Do not output any additional text that is not in JSON format.\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "[{{\n",
    "    {response_format}\n",
    "}}]\"\"\"\n",
    "        \n",
    "        print(f\"  Fetching partition {page_num}/{len(values_to_fetch)}: {partition_column}={value}...\")\n",
    "        \n",
    "        result = call_llm_with_retries(system_msg=system_msg, user_msg=user_msg)\n",
    "        \n",
    "        page_data = {\n",
    "            'page_number': page_num,\n",
    "            'partition_value': value,\n",
    "            'system_msg': system_msg,\n",
    "            'user_msg': user_msg,\n",
    "            'prompt': user_msg,\n",
    "            'raw_response': result.get('response', ''),\n",
    "            'error': result.get('error'),\n",
    "            **result['metrics']\n",
    "        }\n",
    "        \n",
    "        if result['success']:\n",
    "            parsed_data, parse_metrics = parse_json_response(result['response'], expect_list=True)\n",
    "            page_data.update(parse_metrics)\n",
    "            page_data['rows_returned'] = len(parsed_data) if parsed_data else 0\n",
    "            page_data['parsed_data'] = parsed_data if parsed_data else []\n",
    "            \n",
    "            if parsed_data:\n",
    "                all_rows.extend(parsed_data)\n",
    "        else:\n",
    "            page_data['parse_success'] = False\n",
    "            page_data['rows_returned'] = 0\n",
    "            page_data['parsed_data'] = []\n",
    "        \n",
    "        pages.append(page_data)\n",
    "    \n",
    "    return {\n",
    "        'pages': pages,\n",
    "        'all_rows': all_rows\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc9e075",
   "metadata": {},
   "source": [
    "## Strategy 4: Classic Pagination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "921ace95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_classic_pagination(plan: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Iterative offset-based pagination (matching original approach).\n",
    "    Stops when LLM returns empty result or hits MAX_PAGINATION_PAGES failsafe.\n",
    "    \"\"\"\n",
    "    meta = plan['metadata']\n",
    "    config = plan['pagination_config']\n",
    "    \n",
    "    table_title = meta['table_title']\n",
    "    columns = meta['columns']\n",
    "    page_size = config['page_size']\n",
    "    sort_order = config['sort_order']\n",
    "    table_id = plan['table_id']\n",
    "    \n",
    "    # Normalize field names\n",
    "    num_fields = len(columns)\n",
    "    norm_fields = [normalize_field(f) for f in columns]\n",
    "    \n",
    "    pages = []\n",
    "    all_rows = []\n",
    "    offset = 0\n",
    "    page_num = 0\n",
    "    \n",
    "    max_pages = min(MAX_PAGES, MAX_PAGINATION_PAGES) if MAX_PAGES else MAX_PAGINATION_PAGES\n",
    "    \n",
    "    while page_num < max_pages:\n",
    "        page_num += 1\n",
    "        \n",
    "        # Build response format\n",
    "        fields_json = [f'\"{field}\": \"{field}\"' for field in norm_fields]\n",
    "        response_format = ', '.join(fields_json)\n",
    "        \n",
    "        # Build prompt matching original approach\n",
    "        system_msg = \"You are a retriever of facts.\"\n",
    "        sort_desc = ', '.join(sort_order)\n",
    "        user_msg = f\"\"\"List rows {offset + 1} to {offset + page_size} from {table_title}, sorted by {sort_desc}.\n",
    "The response will be formatted as JSON shown below.\n",
    "Each element of the response will contain {num_fields} fields: {', '.join(columns)}.\n",
    "Do not output any additional text that is not in JSON format.\n",
    "\n",
    "If there are no more rows at this offset, respond with an empty list: []\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "[{{\n",
    "    {response_format}\n",
    "}}]\"\"\"\n",
    "        \n",
    "        print(f\"  Fetching page {page_num} (offset {offset}, size {page_size})...\")\n",
    "        \n",
    "        result = call_llm_with_retries(system_msg=system_msg, user_msg=user_msg)\n",
    "        \n",
    "        page_data = {\n",
    "            'page_number': page_num,\n",
    "            'offset': offset,\n",
    "            'page_size': page_size,\n",
    "            'system_msg': system_msg,\n",
    "            'user_msg': user_msg,\n",
    "            'prompt': user_msg,\n",
    "            'raw_response': result.get('response', ''),\n",
    "            'error': result.get('error'),\n",
    "            **result['metrics']\n",
    "        }\n",
    "        \n",
    "        if result['success']:\n",
    "            parsed_data, parse_metrics = parse_json_response(result['response'], expect_list=True)\n",
    "            page_data.update(parse_metrics)\n",
    "            page_data['rows_returned'] = len(parsed_data) if parsed_data else 0\n",
    "            page_data['parsed_data'] = parsed_data if parsed_data else []\n",
    "            \n",
    "            if parsed_data and len(parsed_data) > 0:\n",
    "                all_rows.extend(parsed_data)\n",
    "                offset += page_size\n",
    "            else:\n",
    "                # Empty result, stop pagination\n",
    "                print(f\"  Stopping: Empty result at offset {offset}\")\n",
    "                page_data['stop_reason'] = 'empty_result'\n",
    "                pages.append(page_data)\n",
    "                break\n",
    "        else:\n",
    "            page_data['parse_success'] = False\n",
    "            page_data['rows_returned'] = 0\n",
    "            page_data['parsed_data'] = []\n",
    "        \n",
    "        pages.append(page_data)\n",
    "    \n",
    "    if page_num >= max_pages:\n",
    "        print(f\"  Stopping: Hit max pages limit ({max_pages})\")\n",
    "    \n",
    "    return {\n",
    "        'pages': pages,\n",
    "        'all_rows': all_rows\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cfb96f",
   "metadata": {},
   "source": [
    "## Strategy 5: Range-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17c11e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_range_based(plan: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fetch pages by defined ranges (matching original approach).\n",
    "    \"\"\"\n",
    "    meta = plan['metadata']\n",
    "    config = plan['pagination_config']\n",
    "    \n",
    "    table_title = meta['table_title']\n",
    "    columns = meta['columns']\n",
    "    partition_column = config['partition_column']\n",
    "    ranges = config['ranges']\n",
    "    table_id = plan['table_id']\n",
    "    \n",
    "    # Normalize field names\n",
    "    num_fields = len(columns)\n",
    "    norm_fields = [normalize_field(f) for f in columns]\n",
    "    \n",
    "    pages = []\n",
    "    all_rows = []\n",
    "    \n",
    "    # Apply MAX_PAGES limit\n",
    "    ranges_to_fetch = ranges[:MAX_PAGES] if MAX_PAGES else ranges\n",
    "    total_ranges = len(ranges)\n",
    "    \n",
    "    if MAX_PAGES and len(ranges) > MAX_PAGES:\n",
    "        print(f\"  Limited to first {MAX_PAGES} ranges out of {total_ranges}\")\n",
    "    \n",
    "    for page_num, range_spec in enumerate(ranges_to_fetch, 1):\n",
    "        gte = range_spec.get('gte', '')\n",
    "        lt = range_spec.get('lt', '')\n",
    "        \n",
    "        # Build response format\n",
    "        fields_json = [f'\"{field}\": \"{field}\"' for field in norm_fields]\n",
    "        response_format = ', '.join(fields_json)\n",
    "        \n",
    "        # Build prompt matching original approach\n",
    "        system_msg = \"You are a retriever of facts.\"\n",
    "        user_msg = f\"\"\"List rows from {table_title} where {partition_column} >= {gte} and {partition_column} < {lt}.\n",
    "The response will be formatted as JSON shown below.\n",
    "Each element of the response will contain {num_fields} fields: {', '.join(columns)}.\n",
    "Do not output any additional text that is not in JSON format.\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "[{{\n",
    "    {response_format}\n",
    "}}]\"\"\"\n",
    "        \n",
    "        print(f\"  Fetching range {page_num}/{len(ranges_to_fetch)}: {partition_column} [{gte}, {lt})...\")\n",
    "        \n",
    "        result = call_llm_with_retries(system_msg=system_msg, user_msg=user_msg)\n",
    "        \n",
    "        page_data = {\n",
    "            'page_number': page_num,\n",
    "            'range': range_spec,\n",
    "            'system_msg': system_msg,\n",
    "            'user_msg': user_msg,\n",
    "            'prompt': user_msg,\n",
    "            'raw_response': result.get('response', ''),\n",
    "            'error': result.get('error'),\n",
    "            **result['metrics']\n",
    "        }\n",
    "        \n",
    "        if result['success']:\n",
    "            parsed_data, parse_metrics = parse_json_response(result['response'], expect_list=True)\n",
    "            page_data.update(parse_metrics)\n",
    "            page_data['rows_returned'] = len(parsed_data) if parsed_data else 0\n",
    "            page_data['parsed_data'] = parsed_data if parsed_data else []\n",
    "            \n",
    "            if parsed_data:\n",
    "                all_rows.extend(parsed_data)\n",
    "        else:\n",
    "            page_data['parse_success'] = False\n",
    "            page_data['rows_returned'] = 0\n",
    "            page_data['parsed_data'] = []\n",
    "        \n",
    "        pages.append(page_data)\n",
    "    \n",
    "    return {\n",
    "        'pages': pages,\n",
    "        'all_rows': all_rows\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd17e489",
   "metadata": {},
   "source": [
    "## Main Execution: Process All Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07b59480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 239 strategy-table combinations\n",
      "\n",
      "Filtering to tables with plans for all 5 strategies:\n",
      "  Total unique tables: 48\n",
      "  Tables with all strategies: 47\n",
      "  Filtered to 235 strategy-table combinations\n",
      "Limited to 150 combinations for 30 tables\n",
      "Processing 150 strategy-table combinations...\n"
     ]
    }
   ],
   "source": [
    "# Strategy function mapping\n",
    "STRATEGY_FUNCTIONS = {\n",
    "    'full_table': fetch_full_table,\n",
    "    'row_by_row': fetch_row_by_row,\n",
    "    'attribute_based': fetch_attribute_based,\n",
    "    'classic_pagination': fetch_classic_pagination,\n",
    "    'range_based': fetch_range_based\n",
    "}\n",
    "\n",
    "# Load all strategies\n",
    "strategies_to_process = []\n",
    "for strategy_name in STRATEGY_FUNCTIONS.keys():\n",
    "    strategy_dir = LATEST_STRATEGY_DIR / strategy_name\n",
    "    if not strategy_dir.exists():\n",
    "        print(f\"Skipping {strategy_name}: directory not found\")\n",
    "        continue\n",
    "    \n",
    "    json_files = sorted(strategy_dir.glob('*.json'))\n",
    "    # Filter out error files\n",
    "    json_files = [f for f in json_files if not f.name.startswith('_')]\n",
    "    \n",
    "    for json_file in json_files:\n",
    "        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "            plan = json.load(f)\n",
    "        strategies_to_process.append((strategy_name, plan))\n",
    "\n",
    "print(f\"Found {len(strategies_to_process)} strategy-table combinations\")\n",
    "\n",
    "# Filter to only tables that have plans for ALL strategies (apples-to-apples comparison)\n",
    "from collections import Counter\n",
    "all_strategies = list(STRATEGY_FUNCTIONS.keys())\n",
    "table_strategy_counts = Counter(plan['table_id'] for _, plan in strategies_to_process)\n",
    "tables_with_all_strategies = [table_id for table_id, count in table_strategy_counts.items() \n",
    "                               if count == len(all_strategies)]\n",
    "\n",
    "print(f\"\\nFiltering to tables with plans for all {len(all_strategies)} strategies:\")\n",
    "print(f\"  Total unique tables: {len(table_strategy_counts)}\")\n",
    "print(f\"  Tables with all strategies: {len(tables_with_all_strategies)}\")\n",
    "\n",
    "strategies_to_process = [(s, p) for s, p in strategies_to_process \n",
    "                         if p['table_id'] in tables_with_all_strategies]\n",
    "print(f\"  Filtered to {len(strategies_to_process)} strategy-table combinations\")\n",
    "\n",
    "# Apply MAX_TABLES limit across all strategies\n",
    "if MAX_TABLES:\n",
    "    # Group by table_id to ensure we process complete sets\n",
    "    table_ids = list(set(p['table_id'] for _, p in strategies_to_process))[:MAX_TABLES]\n",
    "    strategies_to_process = [(s, p) for s, p in strategies_to_process if p['table_id'] in table_ids]\n",
    "    print(f\"Limited to {len(strategies_to_process)} combinations for {len(table_ids)} tables\")\n",
    "\n",
    "print(f\"Processing {len(strategies_to_process)} strategy-table combinations...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e75e9d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: processing/2_fetching/20251005_124736\n",
      "\n",
      "Grouped into 30 tables with strategies\n",
      "\n",
      "======================================================================\n",
      "[1/30] Processing table: 12_rock_band_downloadable_2011\n",
      "======================================================================\n",
      "Strategies: full_table, row_by_row, attribute_based, classic_pagination, range_based\n",
      "  Fetching full table...\n",
      "  Fetching row 1/10...\n",
      "  Fetching partition 1/52: Release date=2011-01-04...\n",
      "  Fetching page 1 (offset 0, size 10)...\n",
      "  Fetching range 1/12: Release date [2011-01, 2011-02)...\n",
      "  Stopping: Empty result at offset 0\n",
      "  ⚠ classic_pagination/12_rock_band_downloadable_2011: No rows to save\n",
      "  Stopping: Empty result at offset 0\n",
      "  ⚠ classic_pagination/12_rock_band_downloadable_2011: No rows to save\n",
      "  Fetching row 2/10...\n",
      "  Fetching row 2/10...\n",
      "  Fetching partition 2/52: Release date=2011-01-11...\n",
      "  Fetching partition 2/52: Release date=2011-01-11...\n",
      "  Fetching range 2/12: Release date [2011-02, 2011-03)...\n",
      "  Fetching range 2/12: Release date [2011-02, 2011-03)...\n",
      "  ⚠ full_table/12_rock_band_downloadable_2011: No rows to save\n",
      "  ⚠ full_table/12_rock_band_downloadable_2011: No rows to save\n",
      "  Fetching range 3/12: Release date [2011-03, 2011-04)...\n",
      "  Fetching range 3/12: Release date [2011-03, 2011-04)...\n",
      "  Fetching partition 3/52: Release date=2011-01-18...\n",
      "  Fetching partition 3/52: Release date=2011-01-18...\n",
      "  Fetching row 3/10...\n",
      "  Fetching row 3/10...\n",
      "  Fetching range 4/12: Release date [2011-04, 2011-05)...\n",
      "  Fetching range 4/12: Release date [2011-04, 2011-05)...\n",
      "  Fetching partition 4/52: Release date=2011-01-25...\n",
      "  Fetching partition 4/52: Release date=2011-01-25...\n",
      "  Fetching row 4/10...\n",
      "  Fetching row 4/10...\n",
      "  Fetching range 5/12: Release date [2011-05, 2011-06)...\n",
      "  Fetching range 5/12: Release date [2011-05, 2011-06)...\n",
      "  Fetching partition 5/52: Release date=2011-02-01...\n",
      "  Fetching partition 5/52: Release date=2011-02-01...\n",
      "  Fetching row 5/10...\n",
      "  Fetching row 5/10...\n",
      "  Fetching range 6/12: Release date [2011-06, 2011-07)...\n",
      "  Fetching range 6/12: Release date [2011-06, 2011-07)...\n",
      "  Fetching partition 6/52: Release date=2011-02-08...\n",
      "  Fetching partition 6/52: Release date=2011-02-08...\n",
      "  Fetching row 6/10...\n",
      "  Fetching row 6/10...\n",
      "  Fetching range 7/12: Release date [2011-07, 2011-08)...\n",
      "  Fetching range 7/12: Release date [2011-07, 2011-08)...\n",
      "  Fetching partition 7/52: Release date=2011-02-15...\n",
      "  Fetching partition 7/52: Release date=2011-02-15...\n",
      "  Fetching range 8/12: Release date [2011-08, 2011-09)...\n",
      "  Fetching range 8/12: Release date [2011-08, 2011-09)...\n",
      "  Fetching row 7/10...\n",
      "  Fetching row 7/10...\n",
      "  Fetching range 9/12: Release date [2011-09, 2011-10)...\n",
      "  Fetching range 9/12: Release date [2011-09, 2011-10)...\n",
      "  Fetching partition 8/52: Release date=2011-02-22...\n",
      "  Fetching partition 8/52: Release date=2011-02-22...\n",
      "  Fetching partition 9/52: Release date=2011-03-01...\n",
      "  Fetching partition 9/52: Release date=2011-03-01...\n",
      "  Fetching range 10/12: Release date [2011-10, 2011-11)...\n",
      "  Fetching range 10/12: Release date [2011-10, 2011-11)...\n",
      "  Fetching row 8/10...\n",
      "  Fetching row 8/10...\n",
      "  Fetching partition 10/52: Release date=2011-03-08...\n",
      "  Fetching partition 10/52: Release date=2011-03-08...\n",
      "  Fetching range 11/12: Release date [2011-11, 2011-12)...\n",
      "  Fetching range 11/12: Release date [2011-11, 2011-12)...\n",
      "  Fetching partition 11/52: Release date=2011-03-15...\n",
      "  Fetching partition 11/52: Release date=2011-03-15...\n",
      "  Fetching row 9/10...\n",
      "  Fetching row 9/10...\n",
      "  Fetching range 12/12: Release date [2011-12, 2012-01)...\n",
      "  Fetching range 12/12: Release date [2011-12, 2012-01)...\n",
      "  Fetching partition 12/52: Release date=2011-03-22...\n",
      "  Fetching partition 12/52: Release date=2011-03-22...\n",
      "  Fetching row 10/10...\n",
      "  Fetching row 10/10...\n",
      "  Fetching partition 31/52: Release date=2011-08-02...\n",
      "  Fetching partition 32/52: Release date=2011-08-09...\n",
      "  Fetching partition 33/52: Release date=2011-08-16...\n",
      "  Fetching partition 46/52: Release date=2011-11-15...\n",
      "  Fetching partition 47/52: Release date=2011-11-22...\n",
      "  Fetching row 13/20...\n",
      "  Fetching partition 17/21: Discovery Date=1986-08-22...\n",
      "  Fetching partition 18/21: Discovery Date=1987-08-20...\n",
      "  Fetching row 14/20...\n",
      "  Fetching partition 19/21: Discovery Date=1988-08-18...\n",
      "  Fetching partition 20/21: Discovery Date=1989-08-16...\n",
      "  Fetching row 15/20...\n",
      "  Fetching partition 21/21: Discovery Date=1990-08-14...\n",
      "  Fetching row 16/20...\n",
      "  ✓ attribute_based/14_minor_planets_discovered_by_nikolai_chernykh: 1 rows, 15501 tokens, 255.15s\n",
      "  Fetching row 17/20...\n",
      "  Fetching partition 3/10: Locale=Manitoba...\n",
      "  Fetching range 2/26: Skip [B, C)...\n",
      "  Fetching row 3/15...\n",
      "  ⚠ full_table/16_curling_teams_women_2013_2014: No rows to save\n",
      "  Fetching partition 4/10: Locale=New Brunswick...\n",
      "  Fetching range 3/26: Skip [C, D)...\n",
      "  Fetching partition 5/10: Locale=Newfoundland and Labrador...\n",
      "  Fetching row 4/15...\n",
      "  Fetching partition 6/10: Locale=Nova Scotia...\n",
      "  Fetching range 4/26: Skip [D, E)...\n",
      "  Fetching row 5/15...\n",
      "  Fetching partition 7/10: Locale=Ontario...\n",
      "  Fetching range 5/26: Skip [E, F)...\n",
      "  Fetching partition 8/10: Locale=Quebec...\n",
      "  Fetching row 6/15...\n",
      "  Fetching range 6/26: Skip [F, G)...\n",
      "  Fetching partition 9/10: Locale=Saskatchewan...\n",
      "  Fetching partition 10/10: Locale=United States...\n",
      "  Fetching range 7/26: Skip [G, H)...\n",
      "  Fetching row 7/15...\n",
      "  ⚠ attribute_based/16_curling_teams_women_2013_2014: No rows to save\n",
      "  Fetching range 8/26: Skip [H, I)...\n",
      "  Fetching row 8/15...\n",
      "  Fetching row 9/15...\n",
      "  Fetching range 9/26: Skip [I, J)...\n",
      "  Fetching row 10/15...\n",
      "  Fetching range 10/26: Skip [J, K)...\n",
      "  Fetching row 11/15...\n",
      "  Fetching row 12/15...\n",
      "  Fetching range 11/26: Skip [K, L)...\n",
      "  Fetching row 13/15...\n",
      "  Fetching range 12/26: Skip [L, M)...\n",
      "  Fetching row 14/15...\n",
      "  Fetching range 13/26: Skip [M, N)...\n",
      "  Fetching row 15/15...\n",
      "  ✓ row_by_row/16_curling_teams_women_2013_2014: 8 rows, 16691 tokens, 218.99s\n",
      "  Fetching range 14/26: Skip [N, O)...\n",
      "  Fetching range 15/26: Skip [O, P)...\n",
      "  Fetching range 16/26: Skip [P, Q)...\n",
      "  Fetching range 17/26: Skip [Q, R)...\n",
      "  Fetching range 18/26: Skip [R, S)...\n",
      "  Fetching range 19/26: Skip [S, T)...\n",
      "  Fetching range 20/26: Skip [T, U)...\n",
      "  Fetching range 21/26: Skip [U, V)...\n",
      "  Fetching range 22/26: Skip [V, W)...\n",
      "  Fetching range 23/26: Skip [W, X)...\n",
      "  Fetching range 24/26: Skip [X, Y)...\n",
      "  Fetching range 25/26: Skip [Y, Z)...\n",
      "  Fetching range 26/26: Skip [Z, [)...\n",
      "  ✓ range_based/16_curling_teams_women_2013_2014: 5 rows, 23850 tokens, 378.16s\n",
      "\n",
      "======================================================================\n",
      "[4/30] Processing table: 19_living_proof_the_farewell_tour\n",
      "======================================================================\n",
      "Strategies: full_table, row_by_row, attribute_based, classic_pagination, range_based\n",
      "  Fetching full table...\n",
      "  Fetching row 1/20...\n",
      "  Fetching partition 1/10: Date=2023-09-15...\n",
      "  Fetching page 1 (offset 0, size 10)...\n",
      "  Fetching range 1/12: Date [2023-01, 2023-02)...\n",
      "  Stopping: Empty result at offset 0\n",
      "  ⚠ classic_pagination/19_living_proof_the_farewell_tour: No rows to save\n",
      "  Fetching row 2/20...\n",
      "  Fetching partition 2/10: Date=2023-09-16...\n",
      "  Fetching range 2/12: Date [2023-02, 2023-03)...\n",
      "  Fetching range 3/12: Date [2023-03, 2023-04)...\n",
      "  Fetching partition 3/10: Date=2023-09-18...\n",
      "  ⚠ full_table/19_living_proof_the_farewell_tour: No rows to save\n",
      "  Fetching row 3/20...\n",
      "  Fetching range 4/12: Date [2023-04, 2023-05)...\n",
      "  Fetching partition 4/10: Date=2023-09-20...\n",
      "  Fetching range 5/12: Date [2023-05, 2023-06)...\n",
      "  Fetching row 4/20...\n",
      "  Fetching partition 5/10: Date=2023-09-22...\n",
      "  Fetching row 5/20...\n",
      "  Fetching range 6/12: Date [2023-06, 2023-07)...\n",
      "  Fetching partition 6/10: Date=2023-09-24...\n",
      "  Fetching row 6/20...\n",
      "  Fetching range 7/12: Date [2023-07, 2023-08)...\n",
      "  Fetching partition 7/10: Date=2023-09-26...\n",
      "  Fetching range 8/12: Date [2023-08, 2023-09)...\n",
      "  Fetching row 7/20...\n",
      "  Fetching partition 8/10: Date=2023-09-28...\n",
      "  Fetching row 8/20...\n",
      "  Fetching range 9/12: Date [2023-09, 2023-10)...\n",
      "  Fetching partition 9/10: Date=2023-09-30...\n",
      "  Fetching row 9/20...\n",
      "  Fetching partition 10/10: Date=2023-10-02...\n",
      "  Fetching row 10/20...\n",
      "  ⚠ attribute_based/19_living_proof_the_farewell_tour: No rows to save\n",
      "  Fetching range 10/12: Date [2023-10, 2023-11)...\n",
      "  Fetching row 11/20...\n",
      "  Fetching range 11/12: Date [2023-11, 2023-12)...\n",
      "  Fetching row 12/20...\n",
      "  Fetching range 12/12: Date [2023-12, 2024-01)...\n",
      "  Fetching row 13/20...\n",
      "  ✓ range_based/19_living_proof_the_farewell_tour: 1 rows, 10807 tokens, 167.59s\n",
      "  Fetching row 14/20...\n",
      "  Fetching row 15/20...\n",
      "  Fetching row 16/20...\n",
      "  Fetching row 17/20...\n",
      "  Fetching row 18/20...\n",
      "  Fetching row 19/20...\n",
      "  Fetching row 20/20...\n",
      "  ✓ row_by_row/19_living_proof_the_farewell_tour: 6 rows, 17108 tokens, 281.29s\n",
      "\n",
      "======================================================================\n",
      "[5/30] Processing table: 20_new_zealand_demographics_1921_2011\n",
      "======================================================================\n",
      "Strategies: full_table, row_by_row, attribute_based, classic_pagination, range_based\n",
      "  Fetching full table...\n",
      "  Fetching row 1/16...\n",
      "  Fetching partition 1/17: Year=1921...\n",
      "  Fetching page 1 (offset 0, size 10)...\n",
      "  Fetching range 1/10: Year [1920, 1930)...\n",
      "  Stopping: Empty result at offset 0\n",
      "  ⚠ classic_pagination/20_new_zealand_demographics_1921_2011: No rows to save\n",
      "  Fetching row 2/16...\n",
      "  Fetching partition 2/17: Year=1926...\n",
      "  Fetching range 2/10: Year [1930, 1940)...\n",
      "  Fetching row 3/16...\n",
      "  Fetching range 3/10: Year [1940, 1950)...\n",
      "  Fetching partition 3/17: Year=1936...\n",
      "  Fetching row 4/16...\n",
      "  Fetching range 4/10: Year [1950, 1960)...\n",
      "  Fetching partition 4/17: Year=1945...\n",
      "  Fetching row 5/16...\n",
      "  Fetching partition 5/17: Year=1951...\n",
      "  Fetching range 5/10: Year [1960, 1970)...\n",
      "  Fetching row 6/16...\n",
      "  Fetching range 6/10: Year [1970, 1980)...\n",
      "  Fetching row 7/16...\n",
      "  ✓ full_table/20_new_zealand_demographics_1921_2011: 91 rows, 7492 tokens, 87.07s\n",
      "  Fetching row 8/16...\n",
      "  Fetching partition 6/17: Year=1956...\n",
      "  Fetching row 9/16...\n",
      "  Fetching range 7/10: Year [1980, 1990)...\n",
      "  Fetching partition 7/17: Year=1961...\n",
      "  Fetching row 10/16...\n",
      "  Fetching range 8/10: Year [1990, 2000)...\n",
      "  Fetching partition 8/17: Year=1966...\n",
      "  Fetching range 9/10: Year [2000, 2010)...\n",
      "  Fetching row 11/16...\n",
      "  Fetching range 10/10: Year [2010, 2020)...\n",
      "  Fetching partition 9/17: Year=1971...\n",
      "  Fetching partition 10/17: Year=1976...\n",
      "  Fetching row 12/16...\n",
      "  ✓ range_based/20_new_zealand_demographics_1921_2011: 21 rows, 10994 tokens, 171.92s\n",
      "  Fetching partition 11/17: Year=1981...\n",
      "  Fetching row 13/16...\n",
      "  Fetching row 14/16...\n",
      "  Fetching partition 12/17: Year=1986...\n",
      "  Fetching row 15/16...\n",
      "  Fetching partition 13/17: Year=1991...\n",
      "  Fetching row 16/16...\n",
      "  ✓ row_by_row/20_new_zealand_demographics_1921_2011: 11 rows, 16930 tokens, 235.20s\n",
      "  Fetching partition 14/17: Year=1996...\n",
      "  Fetching partition 15/17: Year=2001...\n",
      "  Fetching partition 16/17: Year=2006...\n",
      "  Fetching partition 17/17: Year=2011...\n",
      "  ✓ attribute_based/20_new_zealand_demographics_1921_2011: 11 rows, 21086 tokens, 330.81s\n",
      "\n",
      "======================================================================\n",
      "[6/30] Processing table: 23_andorra_demographics_1948_2012\n",
      "======================================================================\n",
      "Strategies: full_table, row_by_row, attribute_based, classic_pagination, range_based\n",
      "  Fetching full table...\n",
      "  Fetching row 1/9...\n",
      "  Fetching partition 1/9: Year=1948...\n",
      "  Fetching page 1 (offset 0, size 10)...\n",
      "  Fetching range 1/8: year [1940, 1950)...\n",
      "  Fetching row 2/9...\n",
      "  Stopping: Empty result at offset 0\n",
      "  ⚠ classic_pagination/23_andorra_demographics_1948_2012: No rows to save\n",
      "  Fetching range 2/8: year [1950, 1960)...\n",
      "  Fetching partition 2/9: Year=1950...\n",
      "  ✓ full_table/23_andorra_demographics_1948_2012: 1 rows, 1412 tokens, 25.76s\n",
      "  Fetching row 3/9...\n",
      "  Fetching range 3/8: year [1960, 1970)...\n",
      "  Fetching partition 3/9: Year=1960...\n",
      "  Fetching row 4/9...\n",
      "  Fetching partition 4/9: Year=1970...\n",
      "  Fetching row 5/9...\n",
      "  Fetching row 6/9...\n",
      "  Fetching partition 5/9: Year=1981...\n",
      "  Fetching partition 6/9: Year=1990...\n",
      "  Fetching row 7/9...\n",
      "  Fetching range 4/8: year [1970, 1980)...\n",
      "  Fetching partition 7/9: Year=2000...\n",
      "  Fetching row 8/9...\n",
      "  Fetching range 5/8: year [1980, 1990)...\n",
      "  Fetching partition 8/9: Year=2010...\n",
      "  Fetching row 9/9...\n",
      "  Fetching range 6/8: year [1990, 2000)...\n",
      "  ✓ row_by_row/23_andorra_demographics_1948_2012: 6 rows, 7547 tokens, 109.49s\n",
      "  Fetching partition 9/9: Year=2012...\n",
      "  Fetching range 7/8: year [2000, 2010)...\n",
      "  ✓ attribute_based/23_andorra_demographics_1948_2012: 3 rows, 7069 tokens, 129.60s\n",
      "  Fetching range 8/8: year [2010, 2020)...\n",
      "  ✓ range_based/23_andorra_demographics_1948_2012: 6 rows, 9647 tokens, 154.55s\n",
      "\n",
      "======================================================================\n",
      "[7/30] Processing table: 29_tennessee_vanderbilt_rivalry_1900_2012\n",
      "======================================================================\n",
      "Strategies: full_table, row_by_row, attribute_based, classic_pagination, range_based\n",
      "  Fetching full table...\n",
      "  Fetching row 1/113...\n",
      "  Fetching partition 1/113: Year=1900...\n",
      "  Fetching page 1 (offset 0, size 10)...\n",
      "  Fetching range 1/12: year [1900, 1910)...\n",
      "  ⚠ full_table/29_tennessee_vanderbilt_rivalry_1900_2012: No rows to save\n",
      "  Fetching row 2/113...\n",
      "  Stopping: Empty result at offset 0\n",
      "  ⚠ classic_pagination/29_tennessee_vanderbilt_rivalry_1900_2012: No rows to save\n",
      "  Fetching range 2/12: year [1910, 1920)...\n",
      "  Fetching partition 2/113: Year=1901...\n",
      "  Fetching row 3/113...\n",
      "  Fetching range 3/12: year [1920, 1930)...\n",
      "  Fetching partition 3/113: Year=1902...\n",
      "  Fetching row 4/113...\n",
      "  Fetching partition 4/113: Year=1903...\n",
      "  Fetching range 4/12: year [1930, 1940)...\n",
      "  Fetching row 5/113...\n",
      "  Fetching partition 5/113: Year=1904...\n",
      "  Fetching range 5/12: year [1940, 1950)...\n",
      "  Fetching row 6/113...\n",
      "  Fetching range 6/12: year [1950, 1960)...\n",
      "  Fetching partition 6/113: Year=1905...\n",
      "  Fetching row 7/113...\n",
      "  Fetching range 7/12: year [1960, 1970)...\n",
      "  Fetching partition 7/113: Year=1906...\n",
      "  Fetching row 8/113...\n",
      "  Fetching range 8/12: year [1970, 1980)...\n",
      "  Fetching partition 8/113: Year=1907...\n",
      "  Fetching range 9/12: year [1980, 1990)...\n",
      "  Fetching row 9/113...\n",
      "  Fetching partition 9/113: Year=1908...\n",
      "  Fetching range 10/12: year [1990, 2000)...\n",
      "  Fetching partition 10/113: Year=1909...\n",
      "  Fetching row 10/113...\n",
      "  Fetching partition 11/113: Year=1910...\n",
      "  Fetching row 11/113...\n",
      "  Fetching row 12/113...\n",
      "  Fetching range 11/12: year [2000, 2010)...\n",
      "  Fetching partition 12/113: Year=1911...\n",
      "  Fetching row 13/113...\n",
      "  Fetching partition 13/113: Year=1912...\n",
      "  Fetching row 14/113...\n",
      "  Fetching range 12/12: year [2010, 2020)...\n",
      "  Fetching partition 14/113: Year=1913...\n",
      "  Fetching row 15/113...\n",
      "  Fetching partition 15/113: Year=1914...\n",
      "  ✓ range_based/29_tennessee_vanderbilt_rivalry_1900_2012: 31 rows, 16112 tokens, 261.29s\n",
      "  Fetching row 16/113...\n",
      "  Fetching partition 16/113: Year=1915...\n",
      "  Fetching row 17/113...\n",
      "  Fetching partition 17/113: Year=1916...\n",
      "  Fetching row 18/113...\n",
      "  Fetching partition 18/113: Year=1917...\n",
      "  Fetching row 19/113...\n",
      "  Fetching row 20/113...\n",
      "  Fetching partition 19/113: Year=1918...\n",
      "  Fetching row 21/113...\n",
      "  Fetching row 22/113...\n",
      "  Fetching partition 20/113: Year=1919...\n",
      "  Fetching row 23/113...\n",
      "  Fetching partition 21/113: Year=1920...\n",
      "  Fetching row 24/113...\n",
      "  Fetching partition 22/113: Year=1921...\n",
      "  Fetching row 25/113...\n",
      "  Fetching row 26/113...\n",
      "  Fetching partition 23/113: Year=1922...\n",
      "  Fetching row 27/113...\n",
      "  Fetching partition 24/113: Year=1923...\n",
      "  Fetching row 28/113...\n",
      "  Fetching partition 25/113: Year=1924...\n",
      "  Fetching row 29/113...\n",
      "  Fetching partition 26/113: Year=1925...\n",
      "  Fetching row 30/113...\n",
      "  Fetching row 31/113...\n",
      "  Fetching row 32/113...\n",
      "  Fetching partition 27/113: Year=1926...\n",
      "  Fetching row 33/113...\n",
      "  Fetching partition 28/113: Year=1927...\n",
      "  Fetching row 34/113...\n",
      "  Fetching row 35/113...\n",
      "  Fetching partition 29/113: Year=1928...\n",
      "  Fetching row 36/113...\n",
      "  Fetching row 37/113...\n",
      "  Fetching partition 30/113: Year=1929...\n",
      "  Fetching row 38/113...\n",
      "  Fetching partition 31/113: Year=1930...\n",
      "  Fetching row 39/113...\n",
      "  Fetching partition 32/113: Year=1931...\n",
      "  Fetching row 40/113...\n",
      "  Fetching partition 33/113: Year=1932...\n",
      "  Fetching row 41/113...\n",
      "  Fetching partition 34/113: Year=1933...\n",
      "  Fetching row 42/113...\n",
      "  Fetching partition 35/113: Year=1934...\n",
      "  Fetching row 43/113...\n",
      "  Fetching partition 36/113: Year=1935...\n",
      "  Fetching row 44/113...\n",
      "  Fetching row 45/113...\n",
      "  Fetching partition 37/113: Year=1936...\n",
      "  Fetching row 46/113...\n",
      "  Fetching partition 38/113: Year=1937...\n",
      "  Fetching row 47/113...\n",
      "  Fetching partition 39/113: Year=1938...\n",
      "  Fetching row 48/113...\n",
      "  Fetching partition 40/113: Year=1939...\n",
      "  Fetching row 49/113...\n",
      "  Fetching partition 41/113: Year=1940...\n",
      "  Fetching row 50/113...\n",
      "  Fetching row 51/113...\n",
      "  Fetching partition 42/113: Year=1941...\n",
      "  Fetching partition 43/113: Year=1942...\n",
      "  Fetching partition 44/113: Year=1943...\n",
      "  Fetching row 52/113...\n",
      "  Fetching partition 45/113: Year=1944...\n",
      "  Fetching row 53/113...\n",
      "  Fetching partition 46/113: Year=1945...\n",
      "  Fetching row 54/113...\n",
      "  Fetching row 55/113...\n",
      "  Fetching partition 47/113: Year=1946...\n",
      "  Fetching row 56/113...\n",
      "  Fetching partition 48/113: Year=1947...\n",
      "  Fetching row 57/113...\n",
      "  Fetching row 58/113...\n",
      "  Fetching row 59/113...\n",
      "  Fetching partition 49/113: Year=1948...\n",
      "  Fetching row 60/113...\n",
      "  Fetching row 61/113...\n",
      "  Fetching row 62/113...\n",
      "  Fetching partition 50/113: Year=1949...\n",
      "  Fetching row 63/113...\n",
      "  Fetching partition 51/113: Year=1950...\n",
      "  Fetching row 64/113...\n",
      "  Fetching partition 52/113: Year=1951...\n",
      "  Fetching row 65/113...\n",
      "  Fetching row 66/113...\n",
      "  Fetching partition 53/113: Year=1952...\n",
      "  Fetching row 67/113...\n",
      "  Fetching partition 54/113: Year=1953...\n",
      "  Fetching row 68/113...\n",
      "  Fetching partition 55/113: Year=1954...\n",
      "  Fetching row 69/113...\n",
      "  Fetching row 70/113...\n",
      "  Fetching row 71/113...\n",
      "  Fetching partition 56/113: Year=1955...\n",
      "  Fetching row 72/113...\n",
      "  Fetching row 73/113...\n",
      "  Fetching partition 57/113: Year=1956...\n",
      "  Fetching row 74/113...\n",
      "  Fetching partition 58/113: Year=1957...\n",
      "  Fetching row 75/113...\n",
      "  Fetching partition 59/113: Year=1958...\n",
      "  Fetching row 76/113...\n",
      "  Fetching row 77/113...\n",
      "  Fetching partition 60/113: Year=1959...\n",
      "  Fetching row 78/113...\n",
      "  Fetching partition 61/113: Year=1960...\n",
      "  Fetching row 79/113...\n",
      "  Fetching row 80/113...\n",
      "  Fetching partition 62/113: Year=1961...\n",
      "  Fetching row 81/113...\n",
      "  Fetching partition 63/113: Year=1962...\n",
      "  Fetching row 82/113...\n",
      "  Fetching partition 64/113: Year=1963...\n",
      "  Fetching row 83/113...\n",
      "  Fetching partition 65/113: Year=1964...\n",
      "  Fetching row 84/113...\n",
      "  Fetching partition 66/113: Year=1965...\n",
      "  Fetching row 85/113...\n",
      "  Fetching row 86/113...\n",
      "  Fetching partition 67/113: Year=1966...\n",
      "  Fetching row 87/113...\n",
      "  Fetching partition 68/113: Year=1967...\n",
      "  Fetching row 88/113...\n",
      "  Fetching row 89/113...\n",
      "  Fetching partition 69/113: Year=1968...\n",
      "  Fetching partition 70/113: Year=1969...\n",
      "  Fetching row 90/113...\n",
      "  Fetching row 91/113...\n",
      "  Fetching partition 71/113: Year=1970...\n",
      "  Fetching row 92/113...\n",
      "  Fetching row 93/113...\n",
      "  Fetching partition 72/113: Year=1971...\n",
      "  Fetching row 94/113...\n",
      "  Fetching partition 73/113: Year=1972...\n",
      "  Fetching row 95/113...\n",
      "  Fetching partition 74/113: Year=1973...\n",
      "  Fetching row 96/113...\n",
      "  Fetching partition 75/113: Year=1974...\n",
      "  Fetching row 97/113...\n",
      "  Fetching partition 76/113: Year=1975...\n",
      "  Fetching row 98/113...\n",
      "  Fetching partition 77/113: Year=1976...\n",
      "  Fetching row 99/113...\n",
      "  Fetching row 100/113...\n",
      "  Fetching partition 78/113: Year=1977...\n",
      "  Fetching row 101/113...\n",
      "  Fetching partition 79/113: Year=1978...\n",
      "  Fetching row 102/113...\n",
      "  Fetching partition 80/113: Year=1979...\n",
      "  Fetching row 103/113...\n",
      "  Fetching partition 81/113: Year=1980...\n",
      "  Fetching row 104/113...\n",
      "  Fetching row 105/113...\n",
      "  Fetching partition 82/113: Year=1981...\n",
      "  Fetching row 106/113...\n",
      "  Fetching row 107/113...\n",
      "  Fetching partition 83/113: Year=1982...\n",
      "  Fetching row 108/113...\n",
      "  Fetching partition 84/113: Year=1983...\n",
      "  Fetching row 109/113...\n",
      "  Fetching partition 85/113: Year=1984...\n",
      "  Fetching row 110/113...\n",
      "  Fetching partition 86/113: Year=1985...\n",
      "  Fetching row 111/113...\n",
      "  Fetching partition 87/113: Year=1986...\n",
      "  Fetching partition 88/113: Year=1987...\n",
      "  Fetching row 112/113...\n",
      "  Fetching partition 89/113: Year=1988...\n",
      "  Fetching row 113/113...\n",
      "  Fetching partition 90/113: Year=1989...\n",
      "  ✓ row_by_row/29_tennessee_vanderbilt_rivalry_1900_2012: 35 rows, 100926 tokens, 1753.70s\n",
      "  Fetching partition 91/113: Year=1990...\n",
      "  Fetching partition 92/113: Year=1991...\n",
      "  Fetching partition 93/113: Year=1992...\n",
      "  Fetching partition 94/113: Year=1993...\n",
      "  Fetching partition 95/113: Year=1994...\n",
      "  Fetching partition 96/113: Year=1995...\n",
      "  Fetching partition 97/113: Year=1996...\n",
      "  Fetching partition 98/113: Year=1997...\n",
      "  Fetching partition 99/113: Year=1998...\n",
      "  Fetching partition 100/113: Year=1999...\n",
      "  Fetching partition 101/113: Year=2000...\n",
      "  Fetching partition 102/113: Year=2001...\n",
      "  Fetching partition 103/113: Year=2002...\n",
      "  Fetching partition 104/113: Year=2003...\n",
      "  Fetching partition 105/113: Year=2004...\n",
      "  Fetching partition 106/113: Year=2005...\n",
      "  Fetching partition 107/113: Year=2006...\n",
      "  Fetching partition 108/113: Year=2007...\n",
      "  Fetching partition 109/113: Year=2008...\n",
      "  Fetching partition 110/113: Year=2009...\n",
      "  Fetching partition 111/113: Year=2010...\n",
      "  Fetching partition 112/113: Year=2011...\n",
      "  Fetching partition 113/113: Year=2012...\n",
      "  ✓ attribute_based/29_tennessee_vanderbilt_rivalry_1900_2012: 71 rows, 136095 tokens, 2241.19s\n",
      "\n",
      "======================================================================\n",
      "[8/30] Processing table: 2_belgium_demographics_1900_2011\n",
      "======================================================================\n",
      "Strategies: full_table, row_by_row, attribute_based, classic_pagination, range_based\n",
      "  Fetching full table...\n",
      "  Fetching row 1/112...\n",
      "  Fetching partition 1/12: Year=1900...\n",
      "  Fetching page 1 (offset 0, size 10)...\n",
      "  Fetching range 1/12: Year [1900, 1910)...\n",
      "  Fetching range 2/12: Year [1910, 1920)...\n",
      "  Stopping: Empty result at offset 0\n",
      "  ⚠ classic_pagination/2_belgium_demographics_1900_2011: No rows to save\n",
      "  ✓ full_table/2_belgium_demographics_1900_2011: 1 rows, 1105 tokens, 14.57s\n",
      "  Fetching partition 2/12: Year=1910...\n",
      "  Fetching row 2/112...\n",
      "  Fetching range 3/12: Year [1920, 1930)...\n",
      "  Fetching range 4/12: Year [1930, 1940)...\n",
      "  Fetching row 3/112...\n",
      "  Fetching partition 3/12: Year=1920...\n",
      "  Fetching row 4/112...\n",
      "  Fetching range 5/12: Year [1940, 1950)...\n",
      "  Fetching row 5/112...\n",
      "  Fetching range 6/12: Year [1950, 1960)...\n",
      "  Fetching row 6/112...\n",
      "  Fetching partition 4/12: Year=1930...\n",
      "  Fetching range 7/12: Year [1960, 1970)...\n",
      "  Fetching partition 5/12: Year=1940...\n",
      "  Fetching row 7/112...\n",
      "  Fetching range 8/12: Year [1970, 1980)...\n",
      "  Fetching partition 6/12: Year=1950...\n",
      "  Fetching row 8/112...\n",
      "  Fetching range 9/12: Year [1980, 1990)...\n",
      "  Fetching row 9/112...\n",
      "  Fetching range 10/12: Year [1990, 2000)...\n",
      "  Fetching row 10/112...\n",
      "  Fetching partition 7/12: Year=1960...\n",
      "  Fetching partition 8/12: Year=1970...\n",
      "  Fetching row 11/112...\n",
      "  Fetching row 12/112...\n",
      "  Fetching partition 9/12: Year=1980...\n",
      "  Fetching range 11/12: Year [2000, 2010)...\n",
      "  Fetching row 13/112...\n",
      "  Fetching range 12/12: Year [2010, 2012)...\n",
      "  Fetching partition 10/12: Year=1990...\n",
      "  Fetching row 14/112...\n",
      "  Fetching partition 11/12: Year=2000...\n",
      "  Fetching row 15/112...\n",
      "  Fetching partition 12/12: Year=2011...\n",
      "  Fetching row 16/112...\n",
      "  ✓ range_based/2_belgium_demographics_1900_2011: 23 rows, 14695 tokens, 201.30s\n",
      "  Fetching row 17/112...\n",
      "  Fetching row 18/112...\n",
      "  ✓ attribute_based/2_belgium_demographics_1900_2011: 9 rows, 14697 tokens, 221.70s\n",
      "  Fetching row 19/112...\n",
      "  Fetching row 20/112...\n",
      "  Fetching row 21/112...\n",
      "  Fetching row 22/112...\n",
      "  Fetching row 23/112...\n",
      "  Fetching row 24/112...\n",
      "  Fetching row 25/112...\n",
      "  Fetching row 26/112...\n",
      "  Fetching row 27/112...\n",
      "  Fetching row 28/112...\n",
      "  Fetching row 29/112...\n",
      "  Fetching row 30/112...\n",
      "  Fetching row 31/112...\n",
      "  Fetching row 32/112...\n",
      "  Fetching row 33/112...\n",
      "  Fetching row 34/112...\n",
      "  Fetching row 35/112...\n",
      "  Fetching row 36/112...\n",
      "  Fetching row 37/112...\n",
      "  Fetching row 38/112...\n",
      "  Fetching row 39/112...\n",
      "  Fetching row 40/112...\n",
      "  Fetching row 41/112...\n",
      "  Fetching row 42/112...\n",
      "  Fetching row 43/112...\n",
      "  Fetching row 44/112...\n",
      "  Fetching row 45/112...\n",
      "  Fetching row 46/112...\n",
      "  Fetching row 47/112...\n",
      "  Fetching row 48/112...\n",
      "  Fetching row 49/112...\n",
      "  Fetching row 50/112...\n",
      "  Fetching row 51/112...\n",
      "  Fetching row 52/112...\n",
      "  Fetching row 53/112...\n",
      "  Fetching row 54/112...\n",
      "  Fetching row 55/112...\n",
      "  Fetching row 56/112...\n",
      "  Fetching row 57/112...\n",
      "  Fetching row 58/112...\n",
      "  Fetching row 59/112...\n",
      "  Fetching row 60/112...\n",
      "  Fetching row 61/112...\n",
      "  Fetching row 62/112...\n",
      "  Fetching row 63/112...\n",
      "  Fetching row 64/112...\n",
      "  Fetching row 65/112...\n",
      "  Fetching row 66/112...\n",
      "  Fetching row 67/112...\n",
      "  Fetching row 68/112...\n",
      "  Fetching row 69/112...\n",
      "  Fetching row 70/112...\n",
      "  Fetching row 71/112...\n",
      "  Fetching row 72/112...\n",
      "  Fetching row 73/112...\n",
      "  Fetching row 74/112...\n",
      "  Fetching row 75/112...\n",
      "  Fetching row 76/112...\n",
      "  Fetching row 77/112...\n",
      "  Fetching row 78/112...\n",
      "  Fetching row 79/112...\n",
      "  Fetching row 80/112...\n",
      "  Fetching row 81/112...\n",
      "  Fetching row 82/112...\n",
      "  Fetching row 83/112...\n",
      "  Fetching row 84/112...\n",
      "  Fetching row 85/112...\n",
      "  Fetching row 86/112...\n",
      "  Fetching row 87/112...\n",
      "  Fetching row 88/112...\n",
      "  Fetching row 89/112...\n",
      "  Fetching row 90/112...\n",
      "  Fetching row 91/112...\n",
      "  Fetching row 92/112...\n",
      "  Fetching row 93/112...\n",
      "  Fetching row 94/112...\n",
      "  Fetching row 95/112...\n",
      "  Fetching row 96/112...\n",
      "  Fetching row 97/112...\n",
      "  Fetching row 98/112...\n",
      "  Fetching row 99/112...\n",
      "  Fetching row 100/112...\n",
      "  Fetching row 101/112...\n",
      "  Fetching row 102/112...\n",
      "  Fetching row 103/112...\n",
      "  Fetching row 104/112...\n",
      "  Fetching row 105/112...\n",
      "  Fetching row 106/112...\n",
      "  Fetching row 107/112...\n",
      "  Fetching row 108/112...\n",
      "  Fetching row 109/112...\n",
      "  Fetching row 110/112...\n",
      "  Fetching row 111/112...\n",
      "  Fetching row 112/112...\n",
      "  ✓ row_by_row/2_belgium_demographics_1900_2011: 79 rows, 110282 tokens, 1700.78s\n",
      "\n",
      "======================================================================\n",
      "[9/30] Processing table: 30_classic_100_ten_years_on\n",
      "======================================================================\n",
      "Strategies: full_table, row_by_row, attribute_based, classic_pagination, range_based\n",
      "  Fetching full table...\n",
      "  Fetching row 1/10...\n",
      "  Fetching partition 1/27: Composer=Bach...\n",
      "  Fetching page 1 (offset 0, size 10)...\n",
      "  Fetching range 1/10: Rank [1, 11)...\n",
      "  Stopping: Empty result at offset 0\n",
      "  ⚠ classic_pagination/30_classic_100_ten_years_on: No rows to save\n",
      "  ⚠ full_table/30_classic_100_ten_years_on: No rows to save\n",
      "  Fetching row 2/10...\n",
      "  Fetching range 2/10: Rank [11, 21)...\n",
      "  Fetching partition 2/27: Composer=Beethoven...\n",
      "  Fetching range 3/10: Rank [21, 31)...\n",
      "  Fetching partition 3/27: Composer=Brahms...\n",
      "  Fetching row 3/10...\n",
      "  Fetching partition 4/27: Composer=Chopin...\n",
      "  Fetching range 4/10: Rank [31, 41)...\n",
      "  Fetching range 5/10: Rank [41, 51)...\n",
      "  Fetching partition 5/27: Composer=Debussy...\n",
      "  Fetching row 4/10...\n",
      "  Fetching range 6/10: Rank [51, 61)...\n",
      "  Fetching partition 6/27: Composer=Dvořák...\n",
      "  Fetching range 7/10: Rank [61, 71)...\n",
      "  Fetching row 5/10...\n",
      "  Fetching row 6/10...\n",
      "  Fetching range 8/10: Rank [71, 81)...\n",
      "  Fetching partition 7/27: Composer=Elgar...\n",
      "  Fetching range 9/10: Rank [81, 91)...\n",
      "  Fetching row 7/10...\n",
      "  Fetching range 10/10: Rank [91, 101)...\n",
      "  Fetching partition 8/27: Composer=Gershwin...\n",
      "  Fetching row 8/10...\n",
      "  ✓ range_based/30_classic_100_ten_years_on: 3 rows, 9461 tokens, 175.57s\n",
      "  Fetching partition 9/27: Composer=Grieg...\n",
      "  Fetching partition 10/27: Composer=Handel...\n",
      "  Fetching row 9/10...\n",
      "  Fetching row 10/10...\n",
      "  Fetching partition 11/27: Composer=Haydn...\n",
      "  ✓ row_by_row/30_classic_100_ten_years_on: 5 rows, 12092 tokens, 268.39s\n",
      "  Fetching partition 12/27: Composer=Holst...\n",
      "  Fetching partition 13/27: Composer=Liszt...\n",
      "  Fetching partition 14/27: Composer=Mendelssohn...\n",
      "  Fetching partition 15/27: Composer=Mozart...\n",
      "  Fetching partition 16/27: Composer=Puccini...\n",
      "  Fetching partition 17/27: Composer=Rachmaninoff...\n",
      "  Fetching partition 18/27: Composer=Ravel...\n",
      "  Fetching partition 19/27: Composer=Saint-Saëns...\n",
      "  Fetching partition 20/27: Composer=Schubert...\n",
      "  Fetching partition 21/27: Composer=Schumann...\n",
      "  Fetching partition 22/27: Composer=Shostakovich...\n",
      "  Fetching partition 23/27: Composer=Sibelius...\n",
      "  Fetching partition 24/27: Composer=Strauss...\n",
      "  Fetching partition 25/27: Composer=Tchaikovsky...\n",
      "  Fetching partition 26/27: Composer=Vivaldi...\n",
      "  Fetching partition 27/27: Composer=Wagner...\n",
      "  ✓ attribute_based/30_classic_100_ten_years_on: 9 rows, 32162 tokens, 624.32s\n",
      "\n",
      "======================================================================\n",
      "[10/30] Processing table: 31_udaykumar_films\n",
      "======================================================================\n",
      "Strategies: full_table, row_by_row, attribute_based, classic_pagination, range_based\n",
      "  Fetching full table...\n",
      "  Fetching row 1/20...\n",
      "  Fetching partition 1/30: Year=1956...\n",
      "  Fetching page 1 (offset 0, size 10)...\n",
      "  Fetching range 1/4: year [1950, 1960)...\n",
      "  ⚠ full_table/31_udaykumar_films: No rows to save\n",
      "  Fetching range 2/4: year [1960, 1970)...\n",
      "  Fetching partition 2/30: Year=1957...\n",
      "  Fetching row 2/20...\n",
      "  Stopping: Empty result at offset 0\n",
      "  ⚠ classic_pagination/31_udaykumar_films: No rows to save\n",
      "  Fetching range 3/4: year [1970, 1980)...\n",
      "  Fetching row 3/20...\n",
      "  Fetching partition 3/30: Year=1958...\n",
      "  Fetching row 4/20...\n",
      "  Fetching range 4/4: year [1980, 1990)...\n",
      "  Fetching partition 4/30: Year=1959...\n",
      "  Fetching row 5/20...\n",
      "  ✓ range_based/31_udaykumar_films: 1 rows, 3389 tokens, 55.46s\n",
      "  Fetching partition 5/30: Year=1960...\n",
      "  Fetching row 6/20...\n",
      "  Fetching partition 6/30: Year=1961...\n",
      "  Fetching row 7/20...\n",
      "  Fetching partition 7/30: Year=1962...\n",
      "  Fetching row 8/20...\n",
      "  Fetching row 9/20...\n",
      "  Fetching partition 8/30: Year=1963...\n",
      "  Fetching row 10/20...\n",
      "  Fetching partition 9/30: Year=1964...\n",
      "  Fetching row 11/20...\n",
      "  Fetching partition 10/30: Year=1965...\n",
      "  Fetching row 12/20...\n",
      "  Fetching partition 11/30: Year=1966...\n",
      "  Fetching row 13/20...\n",
      "  Fetching partition 12/30: Year=1967...\n",
      "  Fetching row 14/20...\n",
      "  Fetching partition 13/30: Year=1968...\n",
      "  Fetching row 15/20...\n",
      "  Fetching partition 14/30: Year=1969...\n",
      "  Fetching row 16/20...\n",
      "  Fetching row 17/20...\n",
      "  Fetching partition 15/30: Year=1970...\n",
      "  Fetching row 18/20...\n",
      "  Fetching partition 16/30: Year=1971...\n",
      "  Fetching row 19/20...\n",
      "  Fetching partition 17/30: Year=1972...\n",
      "  Fetching row 20/20...\n",
      "  Fetching partition 18/30: Year=1973...\n",
      "  ✓ row_by_row/31_udaykumar_films: 10 rows, 16610 tokens, 253.60s\n",
      "  Fetching partition 19/30: Year=1974...\n",
      "  Fetching partition 20/30: Year=1975...\n",
      "  Fetching partition 21/30: Year=1976...\n",
      "  Fetching partition 22/30: Year=1977...\n",
      "  Fetching partition 23/30: Year=1978...\n",
      "  Fetching partition 24/30: Year=1979...\n",
      "  Fetching partition 25/30: Year=1980...\n",
      "  Fetching partition 26/30: Year=1981...\n",
      "  Fetching partition 27/30: Year=1982...\n",
      "  Fetching partition 28/30: Year=1983...\n",
      "  Fetching partition 29/30: Year=1984...\n",
      "  Fetching partition 30/30: Year=1985...\n",
      "  ✓ attribute_based/31_udaykumar_films: 4 rows, 25418 tokens, 421.63s\n",
      "\n",
      "======================================================================\n",
      "[11/30] Processing table: 34_ramsar_convention_parties\n",
      "======================================================================\n",
      "Strategies: full_table, row_by_row, attribute_based, classic_pagination, range_based\n",
      "  Fetching full table...\n",
      "  Fetching row 1/188...\n",
      "  Fetching partition 1/40: Entry date=01 January 1975...\n",
      "  Fetching page 1 (offset 0, size 10)...\n",
      "  Fetching range 1/38: Entry date [1975, 1976)...\n",
      "  ⚠ full_table/34_ramsar_convention_parties: No rows to save\n",
      "  Fetching row 2/188...\n",
      "  Fetching range 2/38: Entry date [1976, 1977)...\n",
      "  Stopping: Empty result at offset 0\n",
      "  ⚠ classic_pagination/34_ramsar_convention_parties: No rows to save\n",
      "  Fetching partition 2/40: Entry date=01 February 1976...\n",
      "  Fetching row 3/188...\n",
      "  Fetching partition 3/40: Entry date=01 March 1977...\n",
      "  Fetching range 3/38: Entry date [1977, 1978)...\n",
      "  Fetching row 4/188...\n",
      "  Fetching partition 4/40: Entry date=01 April 1978...\n",
      "  Fetching range 4/38: Entry date [1978, 1979)...\n",
      "  Fetching partition 5/40: Entry date=01 May 1979...\n",
      "  Fetching range 5/38: Entry date [1979, 1980)...\n",
      "  Fetching row 5/188...\n",
      "  Fetching range 6/38: Entry date [1980, 1981)...\n",
      "  Fetching row 6/188...\n",
      "  Fetching partition 6/40: Entry date=01 June 1980...\n",
      "  Fetching row 7/188...\n",
      "  Fetching range 7/38: Entry date [1981, 1982)...\n",
      "  Fetching partition 7/40: Entry date=01 July 1981...\n",
      "  Fetching row 8/188...\n",
      "  Fetching range 8/38: Entry date [1982, 1983)...\n",
      "  Fetching partition 8/40: Entry date=01 August 1982...\n",
      "  Fetching row 9/188...\n",
      "  Fetching range 9/38: Entry date [1983, 1984)...\n",
      "  Fetching partition 9/40: Entry date=01 September 1983...\n",
      "  Fetching row 10/188...\n",
      "  Fetching range 10/38: Entry date [1984, 1985)...\n",
      "  Fetching row 11/188...\n",
      "  Fetching partition 10/40: Entry date=01 October 1984...\n",
      "  Fetching range 11/38: Entry date [1985, 1986)...\n",
      "  Fetching partition 11/40: Entry date=01 November 1985...\n",
      "  Fetching row 12/188...\n",
      "  Fetching range 12/38: Entry date [1986, 1987)...\n",
      "  Fetching row 13/188...\n",
      "  Fetching partition 12/40: Entry date=01 December 1986...\n",
      "  Fetching range 13/38: Entry date [1987, 1988)...\n",
      "  Fetching row 14/188...\n",
      "  Fetching partition 13/40: Entry date=01 January 1987...\n",
      "  Fetching range 14/38: Entry date [1988, 1989)...\n",
      "  Fetching row 15/188...\n",
      "  Fetching partition 14/40: Entry date=01 February 1988...\n",
      "  Fetching range 15/38: Entry date [1989, 1990)...\n",
      "  Fetching partition 15/40: Entry date=01 March 1989...\n",
      "  Fetching row 16/188...\n",
      "  Fetching range 16/38: Entry date [1990, 1991)...\n",
      "  Fetching partition 16/40: Entry date=01 April 1990...\n",
      "  Fetching partition 17/40: Entry date=01 May 1991...\n",
      "  Fetching row 17/188...\n",
      "  Fetching range 17/38: Entry date [1991, 1992)...\n",
      "  Fetching partition 18/40: Entry date=01 June 1992...\n",
      "  Fetching range 18/38: Entry date [1992, 1993)...\n",
      "  Fetching row 18/188...\n",
      "  Fetching range 19/38: Entry date [1993, 1994)...\n",
      "  Fetching partition 19/40: Entry date=01 July 1993...\n",
      "  Fetching row 19/188...\n",
      "  Fetching partition 20/40: Entry date=01 August 1994...\n",
      "  Fetching range 20/38: Entry date [1994, 1995)...\n",
      "  Fetching row 20/188...\n",
      "  Fetching partition 21/40: Entry date=01 September 1995...\n",
      "  Fetching partition 22/40: Entry date=01 October 1996...\n",
      "  Fetching range 21/38: Entry date [1995, 1996)...\n",
      "  Fetching row 21/188...\n",
      "  Fetching partition 23/40: Entry date=01 November 1997...\n",
      "  Fetching range 22/38: Entry date [1996, 1997)...\n",
      "  Fetching row 22/188...\n",
      "  Fetching partition 24/40: Entry date=01 December 1998...\n",
      "  Fetching range 23/38: Entry date [1997, 1998)...\n",
      "  Fetching row 23/188...\n",
      "  Fetching row 24/188...\n",
      "  Fetching partition 25/40: Entry date=01 January 1999...\n",
      "  Fetching range 24/38: Entry date [1998, 1999)...\n",
      "  Fetching row 25/188...\n",
      "  Fetching range 25/38: Entry date [1999, 2000)...\n",
      "  Fetching partition 26/40: Entry date=01 February 2000...\n",
      "  Fetching row 26/188...\n",
      "  Fetching range 26/38: Entry date [2000, 2001)...\n",
      "  Fetching partition 27/40: Entry date=01 March 2001...\n",
      "  Fetching range 27/38: Entry date [2001, 2002)...\n",
      "  Fetching row 27/188...\n",
      "  Fetching partition 28/40: Entry date=01 April 2002...\n",
      "  Fetching range 28/38: Entry date [2002, 2003)...\n",
      "  Fetching row 28/188...\n",
      "  Fetching partition 29/40: Entry date=01 May 2003...\n",
      "  Fetching range 29/38: Entry date [2003, 2004)...\n",
      "  Fetching row 29/188...\n",
      "  Fetching partition 30/40: Entry date=01 June 2004...\n",
      "  Fetching row 30/188...\n",
      "  Fetching range 30/38: Entry date [2004, 2005)...\n",
      "  Fetching partition 31/40: Entry date=01 July 2005...\n",
      "  Fetching row 31/188...\n",
      "  Fetching range 31/38: Entry date [2005, 2006)...\n",
      "  Fetching partition 32/40: Entry date=01 August 2006...\n",
      "  Fetching row 32/188...\n",
      "  Fetching partition 33/40: Entry date=01 September 2007...\n",
      "  Fetching range 32/38: Entry date [2006, 2007)...\n",
      "  Fetching partition 34/40: Entry date=01 October 2008...\n",
      "  Fetching row 33/188...\n",
      "  Fetching partition 35/40: Entry date=01 November 2009...\n",
      "  Fetching range 33/38: Entry date [2007, 2008)...\n",
      "  Fetching row 34/188...\n",
      "  Fetching partition 36/40: Entry date=01 December 2010...\n",
      "  Fetching range 34/38: Entry date [2008, 2009)...\n",
      "  Fetching row 35/188...\n",
      "  Fetching partition 37/40: Entry date=01 January 2011...\n",
      "  Fetching range 35/38: Entry date [2009, 2010)...\n",
      "  Fetching row 36/188...\n",
      "  Fetching partition 38/40: Entry date=01 February 2012...\n",
      "  Fetching range 36/38: Entry date [2010, 2011)...\n",
      "  Fetching row 37/188...\n",
      "  Fetching partition 39/40: Entry date=01 March 2012...\n",
      "  Fetching row 38/188...\n",
      "  Fetching partition 40/40: Entry date=31 December 2012...\n",
      "  Fetching range 37/38: Entry date [2011, 2012)...\n",
      "  Fetching row 39/188...\n",
      "  ✓ attribute_based/34_ramsar_convention_parties: 3 rows, 37232 tokens, 688.30s\n",
      "  Fetching range 38/38: Entry date [2012, 2013)...\n",
      "  Fetching row 40/188...\n",
      "  Fetching row 41/188...\n",
      "  ✓ range_based/34_ramsar_convention_parties: 4 rows, 40363 tokens, 709.62s\n",
      "  Fetching row 42/188...\n",
      "  Fetching row 43/188...\n",
      "  Fetching row 44/188...\n",
      "  Fetching row 45/188...\n",
      "  Fetching row 46/188...\n",
      "  Fetching row 47/188...\n",
      "  Fetching row 48/188...\n",
      "  Fetching row 49/188...\n",
      "  Fetching row 50/188...\n",
      "  Fetching row 51/188...\n",
      "  Fetching row 52/188...\n",
      "  Fetching row 53/188...\n",
      "  Fetching row 54/188...\n",
      "  Fetching row 55/188...\n",
      "  Fetching row 56/188...\n",
      "  Fetching row 57/188...\n",
      "  Fetching row 58/188...\n",
      "  Fetching row 59/188...\n",
      "  Fetching row 60/188...\n",
      "  Fetching row 61/188...\n",
      "  Fetching row 62/188...\n",
      "  Fetching row 63/188...\n",
      "  Fetching row 64/188...\n",
      "  Fetching row 65/188...\n",
      "  Fetching row 66/188...\n",
      "  Fetching row 67/188...\n",
      "  Fetching row 68/188...\n",
      "  Fetching row 69/188...\n",
      "  Fetching row 70/188...\n",
      "  Fetching row 71/188...\n",
      "  Fetching row 72/188...\n",
      "  Fetching row 73/188...\n",
      "  Fetching row 74/188...\n",
      "  Fetching row 75/188...\n",
      "  Fetching row 76/188...\n",
      "  Fetching row 77/188...\n",
      "  Fetching row 78/188...\n",
      "  Fetching row 79/188...\n",
      "  Fetching row 80/188...\n",
      "  Fetching row 81/188...\n",
      "  Fetching row 82/188...\n",
      "  Fetching row 83/188...\n",
      "  Fetching row 84/188...\n",
      "  Fetching row 85/188...\n",
      "  Fetching row 86/188...\n",
      "  Fetching row 87/188...\n",
      "  Fetching row 88/188...\n",
      "  Fetching row 89/188...\n",
      "  Fetching row 90/188...\n",
      "  Fetching row 91/188...\n",
      "  Fetching row 92/188...\n",
      "  Fetching row 93/188...\n",
      "  Fetching row 94/188...\n",
      "  Fetching row 95/188...\n",
      "  Fetching row 96/188...\n",
      "  Fetching row 97/188...\n",
      "  Fetching row 98/188...\n",
      "  Fetching row 99/188...\n",
      "  Fetching row 100/188...\n",
      "  Fetching row 101/188...\n",
      "  Fetching row 102/188...\n",
      "  Fetching row 103/188...\n",
      "  Fetching row 104/188...\n",
      "  Fetching row 105/188...\n",
      "  Fetching row 106/188...\n",
      "  Fetching row 107/188...\n",
      "  Fetching row 108/188...\n",
      "  Fetching row 109/188...\n",
      "  Fetching row 110/188...\n",
      "  Fetching row 111/188...\n",
      "  Fetching row 112/188...\n",
      "  Fetching row 113/188...\n",
      "  Fetching row 114/188...\n",
      "  Fetching row 115/188...\n",
      "  Fetching row 116/188...\n",
      "  Fetching row 117/188...\n",
      "  Fetching row 118/188...\n",
      "  Fetching row 119/188...\n",
      "  Fetching row 120/188...\n",
      "  Fetching row 121/188...\n",
      "  Fetching row 122/188...\n",
      "  Fetching row 123/188...\n",
      "  Fetching row 124/188...\n",
      "  Fetching row 125/188...\n",
      "  Fetching row 126/188...\n",
      "  Fetching row 127/188...\n",
      "  Fetching row 128/188...\n",
      "  Fetching row 129/188...\n",
      "  Fetching row 130/188...\n",
      "  Fetching row 131/188...\n",
      "  Fetching row 132/188...\n",
      "  Fetching row 133/188...\n",
      "  Fetching row 134/188...\n",
      "  Fetching row 135/188...\n",
      "  Fetching row 136/188...\n",
      "  Fetching row 137/188...\n",
      "  Fetching row 138/188...\n",
      "  Fetching row 139/188...\n",
      "  Fetching row 140/188...\n",
      "  Fetching row 141/188...\n",
      "  Fetching row 142/188...\n",
      "  Fetching row 143/188...\n",
      "  Fetching row 144/188...\n",
      "  Fetching row 145/188...\n",
      "  Fetching row 146/188...\n",
      "  Fetching row 147/188...\n",
      "  Fetching row 148/188...\n",
      "  Fetching row 149/188...\n",
      "  Fetching row 150/188...\n",
      "  Fetching row 151/188...\n",
      "  Fetching row 152/188...\n",
      "  Fetching row 153/188...\n",
      "  Fetching row 154/188...\n",
      "  Fetching row 155/188...\n",
      "  Fetching row 156/188...\n",
      "  Fetching row 157/188...\n",
      "  Fetching row 158/188...\n",
      "  Fetching row 159/188...\n",
      "  Fetching row 160/188...\n",
      "  Fetching row 161/188...\n",
      "  Fetching row 162/188...\n",
      "  Fetching row 163/188...\n",
      "  Fetching row 164/188...\n",
      "  Fetching row 165/188...\n",
      "  Fetching row 166/188...\n",
      "  Fetching row 167/188...\n",
      "  Fetching row 168/188...\n",
      "  Fetching row 169/188...\n",
      "  Fetching row 170/188...\n",
      "  Fetching row 171/188...\n",
      "  Fetching row 172/188...\n",
      "  Fetching row 173/188...\n",
      "  Fetching row 174/188...\n",
      "  Fetching row 175/188...\n",
      "  Fetching row 176/188...\n",
      "  Fetching row 177/188...\n",
      "  Fetching row 178/188...\n",
      "  Fetching row 179/188...\n",
      "  Fetching row 180/188...\n",
      "  Fetching row 181/188...\n",
      "  Fetching row 182/188...\n",
      "  Fetching row 183/188...\n",
      "  Fetching row 184/188...\n",
      "  Fetching row 185/188...\n",
      "  Fetching row 186/188...\n",
      "  Fetching row 187/188...\n",
      "  Fetching row 188/188...\n",
      "  ✓ row_by_row/34_ramsar_convention_parties: 47 rows, 191648 tokens, 3747.88s\n",
      "\n",
      "======================================================================\n",
      "[12/30] Processing table: 35_guitar_hero_5_songs\n",
      "======================================================================\n",
      "Strategies: full_table, row_by_row, attribute_based, classic_pagination, range_based\n",
      "  Fetching full table...\n",
      "  Fetching row 1/76...\n",
      "  Fetching partition 1/40: Year=1970...\n",
      "  Fetching page 1 (offset 0, size 10)...\n",
      "  Fetching range 1/6: Year [1950, 1960)...\n",
      "  Fetching row 2/76...\n",
      "  ⚠ full_table/35_guitar_hero_5_songs: No rows to save\n",
      "  Fetching partition 2/40: Year=1971...\n",
      "  Stopping: Empty result at offset 0\n",
      "  ⚠ classic_pagination/35_guitar_hero_5_songs: No rows to save\n",
      "  Fetching range 2/6: Year [1960, 1970)...\n",
      "  Fetching row 3/76...\n",
      "  Fetching partition 3/40: Year=1972...\n",
      "  Fetching range 3/6: Year [1970, 1980)...\n",
      "  Fetching row 4/76...\n",
      "  Fetching range 4/6: Year [1980, 1990)...\n",
      "  Fetching partition 4/40: Year=1973...\n",
      "  Fetching row 5/76...\n",
      "  Fetching range 5/6: Year [1990, 2000)...\n",
      "  Fetching row 6/76...\n",
      "  Fetching range 6/6: Year [2000, 2010)...\n",
      "  Fetching row 7/76...\n",
      "  Fetching partition 5/40: Year=1974...\n",
      "  ✓ range_based/35_guitar_hero_5_songs: 2 rows, 6907 tokens, 109.09s\n",
      "  Fetching row 8/76...\n",
      "  Fetching partition 6/40: Year=1975...\n",
      "  Fetching row 9/76...\n",
      "  Fetching partition 7/40: Year=1976...\n",
      "  Fetching row 10/76...\n",
      "  Fetching partition 8/40: Year=1977...\n",
      "  Fetching row 11/76...\n",
      "  Fetching partition 9/40: Year=1978...\n",
      "  Fetching row 12/76...\n",
      "  Fetching row 13/76...\n",
      "  Fetching partition 10/40: Year=1979...\n",
      "  Fetching row 14/76...\n",
      "  Fetching partition 11/40: Year=1980...\n",
      "  Fetching row 15/76...\n",
      "  Fetching partition 12/40: Year=1981...\n",
      "  Fetching row 16/76...\n",
      "  Fetching partition 13/40: Year=1982...\n",
      "  Fetching row 17/76...\n",
      "  Fetching partition 14/40: Year=1983...\n",
      "  Fetching row 18/76...\n",
      "  Fetching partition 15/40: Year=1984...\n",
      "  Fetching row 19/76...\n",
      "  Fetching row 20/76...\n",
      "  Fetching partition 16/40: Year=1985...\n",
      "  Fetching row 21/76...\n",
      "  Fetching partition 17/40: Year=1986...\n",
      "  Fetching row 22/76...\n",
      "  Fetching partition 18/40: Year=1987...\n",
      "  Fetching row 23/76...\n",
      "  Fetching partition 19/40: Year=1988...\n",
      "  Fetching row 24/76...\n",
      "  Fetching partition 20/40: Year=1989...\n",
      "  Fetching row 25/76...\n",
      "  Fetching partition 21/40: Year=1990...\n",
      "  Fetching row 26/76...\n",
      "  Fetching partition 22/40: Year=1991...\n",
      "  Fetching row 27/76...\n",
      "  Fetching partition 23/40: Year=1992...\n",
      "  Fetching row 28/76...\n",
      "  Fetching row 29/76...\n",
      "  Fetching partition 24/40: Year=1993...\n",
      "  Fetching partition 25/40: Year=1994...\n",
      "  Fetching row 30/76...\n",
      "  Fetching partition 26/40: Year=1995...\n",
      "  Fetching row 31/76...\n",
      "  Fetching partition 27/40: Year=1996...\n",
      "  Fetching row 32/76...\n",
      "  Fetching partition 28/40: Year=1997...\n",
      "  Fetching row 33/76...\n",
      "  Fetching partition 29/40: Year=1998...\n",
      "  Fetching partition 30/40: Year=1999...\n",
      "  Fetching row 34/76...\n",
      "  Fetching row 35/76...\n",
      "  Fetching partition 31/40: Year=2000...\n",
      "  Fetching row 36/76...\n",
      "  Fetching partition 32/40: Year=2001...\n",
      "  Fetching row 37/76...\n",
      "  Fetching partition 33/40: Year=2002...\n",
      "  Fetching row 38/76...\n",
      "  Fetching partition 34/40: Year=2003...\n",
      "  Fetching row 39/76...\n",
      "  Fetching partition 35/40: Year=2004...\n",
      "  Fetching row 40/76...\n",
      "  Fetching row 41/76...\n",
      "  Fetching partition 36/40: Year=2005...\n",
      "  Fetching row 42/76...\n",
      "  Fetching partition 37/40: Year=2006...\n",
      "  Fetching row 43/76...\n",
      "  Fetching partition 38/40: Year=2007...\n",
      "  Fetching row 44/76...\n",
      "  Fetching partition 39/40: Year=2008...\n",
      "  Fetching partition 40/40: Year=2009...\n",
      "  Fetching row 45/76...\n",
      "  Fetching row 46/76...\n",
      "  ✓ attribute_based/35_guitar_hero_5_songs: 8 rows, 53984 tokens, 943.74s\n",
      "  Fetching row 47/76...\n",
      "  Fetching row 48/76...\n",
      "  Fetching row 49/76...\n",
      "  Fetching row 50/76...\n",
      "  Fetching row 51/76...\n",
      "  Fetching row 52/76...\n",
      "  Fetching row 53/76...\n",
      "  Fetching row 54/76...\n",
      "  Fetching row 55/76...\n",
      "  Fetching row 56/76...\n",
      "  Fetching row 57/76...\n",
      "  Fetching row 58/76...\n",
      "  Fetching row 59/76...\n",
      "  Fetching row 60/76...\n",
      "  Fetching row 61/76...\n",
      "  Fetching row 62/76...\n",
      "  Fetching row 63/76...\n",
      "  Fetching row 64/76...\n",
      "  Fetching row 65/76...\n",
      "  Fetching row 66/76...\n",
      "  Fetching row 67/76...\n",
      "  Fetching row 68/76...\n",
      "  Fetching row 69/76...\n",
      "  Fetching row 70/76...\n",
      "  Fetching row 71/76...\n",
      "  Fetching row 72/76...\n",
      "  Fetching row 73/76...\n",
      "  Fetching row 74/76...\n",
      "  Fetching row 75/76...\n",
      "  Fetching row 76/76...\n",
      "  ✓ row_by_row/35_guitar_hero_5_songs: 16 rows, 88372 tokens, 1608.20s\n",
      "\n",
      "======================================================================\n",
      "[13/30] Processing table: 37_dublin_maternity_hospital_mortality_rates_1784_1849\n",
      "======================================================================\n",
      "Strategies: full_table, row_by_row, attribute_based, classic_pagination, range_based\n",
      "  Fetching full table...\n",
      "  Fetching row 1/66...\n",
      "  Fetching partition 1/66: Year=1784...\n",
      "  Fetching page 1 (offset 0, size 10)...\n",
      "  Fetching range 1/7: year [1780, 1790)...\n",
      "  ⚠ full_table/37_dublin_maternity_hospital_mortality_rates_1784_1849: No rows to save\n",
      "  Stopping: Empty result at offset 0\n",
      "  ⚠ classic_pagination/37_dublin_maternity_hospital_mortality_rates_1784_1849: No rows to save\n",
      "  Fetching row 2/66...\n",
      "  Fetching partition 2/66: Year=1785...\n",
      "  Fetching range 2/7: year [1790, 1800)...\n",
      "  Fetching range 3/7: year [1800, 1810)...\n",
      "  Fetching partition 3/66: Year=1786...\n",
      "  Fetching row 3/66...\n",
      "  Fetching range 4/7: year [1810, 1820)...\n",
      "  Fetching partition 4/66: Year=1787...\n",
      "  Fetching range 5/7: year [1820, 1830)...\n",
      "  Fetching partition 5/66: Year=1788...\n",
      "  Fetching row 4/66...\n",
      "  Fetching partition 6/66: Year=1789...\n",
      "  Fetching range 6/7: year [1830, 1840)...\n",
      "  Fetching row 5/66...\n",
      "  Fetching partition 7/66: Year=1790...\n",
      "  Fetching row 6/66...\n",
      "  Fetching range 7/7: year [1840, 1850)...\n",
      "  Fetching partition 8/66: Year=1791...\n",
      "  Fetching row 7/66...\n",
      "  ✓ range_based/37_dublin_maternity_hospital_mortality_rates_1784_1849: 2 rows, 5105 tokens, 85.71s\n",
      "  Fetching partition 9/66: Year=1792...\n",
      "  Fetching row 8/66...\n",
      "  Fetching partition 10/66: Year=1793...\n",
      "  Fetching row 9/66...\n",
      "  Fetching partition 11/66: Year=1794...\n",
      "  Fetching row 10/66...\n",
      "  Fetching row 11/66...\n",
      "  Fetching partition 12/66: Year=1795...\n",
      "  Fetching partition 13/66: Year=1796...\n",
      "  Fetching row 12/66...\n",
      "  Fetching partition 14/66: Year=1797...\n",
      "  Fetching partition 15/66: Year=1798...\n",
      "  Fetching row 13/66...\n",
      "  Fetching partition 16/66: Year=1799...\n",
      "  Fetching partition 17/66: Year=1800...\n",
      "  Fetching row 14/66...\n",
      "  Fetching partition 18/66: Year=1801...\n",
      "  Fetching row 15/66...\n",
      "  Fetching partition 19/66: Year=1802...\n",
      "  Fetching row 16/66...\n",
      "  Fetching partition 20/66: Year=1803...\n",
      "  Fetching row 17/66...\n",
      "  Fetching partition 21/66: Year=1804...\n",
      "  Fetching row 18/66...\n",
      "  Fetching partition 22/66: Year=1805...\n",
      "  Fetching row 19/66...\n",
      "  Fetching partition 23/66: Year=1806...\n",
      "  Fetching row 20/66...\n",
      "  Fetching partition 24/66: Year=1807...\n",
      "  Fetching row 21/66...\n",
      "  Fetching partition 25/66: Year=1808...\n",
      "  Fetching row 22/66...\n",
      "  Fetching partition 26/66: Year=1809...\n",
      "  Fetching row 23/66...\n",
      "  Fetching row 24/66...\n",
      "  Fetching partition 27/66: Year=1810...\n",
      "  Fetching row 25/66...\n",
      "  Fetching partition 28/66: Year=1811...\n",
      "  Fetching partition 29/66: Year=1812...\n",
      "  Fetching row 26/66...\n",
      "  Fetching row 27/66...\n",
      "  Fetching partition 30/66: Year=1813...\n",
      "  Fetching row 28/66...\n",
      "  Fetching partition 31/66: Year=1814...\n",
      "  Fetching row 29/66...\n",
      "  Fetching partition 32/66: Year=1815...\n",
      "  Fetching row 30/66...\n",
      "  Fetching partition 33/66: Year=1816...\n",
      "  Fetching row 31/66...\n",
      "  Fetching partition 34/66: Year=1817...\n",
      "  Fetching row 32/66...\n",
      "  Fetching partition 35/66: Year=1818...\n",
      "  Fetching row 33/66...\n",
      "  Fetching partition 36/66: Year=1819...\n",
      "  Fetching row 34/66...\n",
      "  Fetching partition 37/66: Year=1820...\n",
      "  Fetching row 35/66...\n",
      "  Fetching partition 38/66: Year=1821...\n",
      "  Fetching row 36/66...\n",
      "  Fetching partition 39/66: Year=1822...\n",
      "  Fetching row 37/66...\n",
      "  Fetching partition 40/66: Year=1823...\n",
      "  Fetching row 38/66...\n",
      "  Fetching row 39/66...\n",
      "  Fetching partition 41/66: Year=1824...\n",
      "  Fetching partition 42/66: Year=1825...\n",
      "  Fetching row 40/66...\n",
      "  Fetching partition 43/66: Year=1826...\n",
      "  Fetching row 41/66...\n",
      "  Fetching partition 44/66: Year=1827...\n",
      "  Fetching row 42/66...\n",
      "  Fetching partition 45/66: Year=1828...\n",
      "  Fetching row 43/66...\n",
      "  Fetching partition 46/66: Year=1829...\n",
      "  Fetching partition 47/66: Year=1830...\n",
      "  Fetching row 44/66...\n",
      "  Fetching partition 48/66: Year=1831...\n",
      "  Fetching row 45/66...\n",
      "  Fetching partition 49/66: Year=1832...\n",
      "  Fetching row 46/66...\n",
      "  Fetching partition 50/66: Year=1833...\n",
      "  Fetching row 47/66...\n",
      "  Fetching partition 51/66: Year=1834...\n",
      "  Fetching row 48/66...\n",
      "  Fetching partition 52/66: Year=1835...\n",
      "  Fetching row 49/66...\n",
      "  Fetching partition 53/66: Year=1836...\n",
      "  Fetching row 50/66...\n",
      "  Fetching partition 54/66: Year=1837...\n",
      "  Fetching row 51/66...\n",
      "  Fetching partition 55/66: Year=1838...\n",
      "  Fetching row 52/66...\n",
      "  Fetching partition 56/66: Year=1839...\n",
      "  Fetching partition 57/66: Year=1840...\n",
      "  Fetching row 53/66...\n",
      "  Fetching partition 58/66: Year=1841...\n",
      "  Fetching row 54/66...\n",
      "  Fetching partition 59/66: Year=1842...\n",
      "  Fetching row 55/66...\n",
      "  Fetching partition 60/66: Year=1843...\n",
      "  Fetching row 56/66...\n",
      "  Fetching partition 61/66: Year=1844...\n",
      "  Fetching partition 62/66: Year=1845...\n",
      "  Fetching row 57/66...\n",
      "  Fetching partition 63/66: Year=1846...\n",
      "  Fetching row 58/66...\n",
      "  Fetching row 59/66...\n",
      "  Fetching partition 64/66: Year=1847...\n",
      "  Fetching row 60/66...\n",
      "  Fetching row 61/66...\n",
      "  Fetching partition 65/66: Year=1848...\n",
      "  Fetching row 62/66...\n",
      "  Fetching partition 66/66: Year=1849...\n",
      "  ✓ attribute_based/37_dublin_maternity_hospital_mortality_rates_1784_1849: 11 rows, 48378 tokens, 978.00s\n",
      "  Fetching row 63/66...\n",
      "  Fetching row 64/66...\n",
      "  Fetching row 65/66...\n",
      "  Fetching row 66/66...\n",
      "  ✓ row_by_row/37_dublin_maternity_hospital_mortality_rates_1784_1849: 62 rows, 49197 tokens, 1031.89s\n",
      "\n",
      "======================================================================\n",
      "[14/30] Processing table: 3_australia_demographics_1900_2010\n",
      "======================================================================\n",
      "Strategies: full_table, row_by_row, attribute_based, classic_pagination, range_based\n",
      "  Fetching full table...\n",
      "  Fetching row 1/12...\n",
      "  Fetching partition 1/12: Year=1900...\n",
      "  Fetching page 1 (offset 0, size 10)...\n",
      "  Fetching range 1/11: Year [1900, 1910)...\n",
      "  Stopping: Empty result at offset 0\n",
      "  ⚠ classic_pagination/3_australia_demographics_1900_2010: No rows to save\n",
      "  Fetching range 2/11: Year [1910, 1920)...\n",
      "  Fetching partition 2/12: Year=1910...\n",
      "  Fetching range 3/11: Year [1920, 1930)...\n",
      "  ✓ full_table/3_australia_demographics_1900_2010: 1 rows, 1460 tokens, 28.38s\n",
      "  Fetching row 2/12...\n",
      "  Fetching range 4/11: Year [1930, 1940)...\n",
      "  Fetching row 3/12...\n",
      "  Fetching partition 3/12: Year=1920...\n",
      "  Fetching row 4/12...\n",
      "  Fetching range 5/11: Year [1940, 1950)...\n",
      "  Fetching row 5/12...\n",
      "  Fetching partition 4/12: Year=1930...\n",
      "  Fetching row 6/12...\n",
      "  Fetching partition 5/12: Year=1940...\n",
      "  Fetching range 6/11: Year [1950, 1960)...\n",
      "  Fetching row 7/12...\n",
      "  Fetching partition 6/12: Year=1950...\n",
      "  Fetching range 7/11: Year [1960, 1970)...\n",
      "  Fetching partition 7/12: Year=1960...\n",
      "  Fetching row 8/12...\n",
      "  Fetching partition 8/12: Year=1970...\n",
      "  Fetching row 9/12...\n",
      "  Fetching range 8/11: Year [1970, 1980)...\n",
      "  Fetching partition 9/12: Year=1980...\n",
      "  Fetching row 10/12...\n",
      "  Fetching row 11/12...\n",
      "  Fetching partition 10/12: Year=1990...\n",
      "  Fetching range 9/11: Year [1980, 1990)...\n",
      "  Fetching row 12/12...\n",
      "  Fetching range 10/11: Year [1990, 2000)...\n",
      "  Fetching partition 11/12: Year=2000...\n",
      "  ✓ row_by_row/3_australia_demographics_1900_2010: 4 rows, 11387 tokens, 203.73s\n",
      "  Fetching partition 12/12: Year=2010...\n",
      "  ✓ attribute_based/3_australia_demographics_1900_2010: 9 rows, 15026 tokens, 253.61s\n",
      "  Fetching range 11/11: Year [2000, 2010)...\n",
      "  ✓ range_based/3_australia_demographics_1900_2010: 31 rows, 16701 tokens, 302.96s\n",
      "\n",
      "======================================================================\n",
      "[15/30] Processing table: 40_fukushima_plant_operating_history_1970_2009\n",
      "======================================================================\n",
      "Strategies: full_table, row_by_row, attribute_based, classic_pagination, range_based\n",
      "  Fetching full table...\n",
      "  Fetching row 1/40...\n",
      "  Fetching partition 1/40: Year=1970...\n",
      "  Fetching page 1 (offset 0, size 10)...\n",
      "  Fetching range 1/4: year [1970, 1980)...\n",
      "  Fetching row 2/40...\n",
      "  Fetching range 2/4: year [1980, 1990)...\n",
      "  Fetching partition 2/40: Year=1971...\n",
      "  Stopping: Empty result at offset 0\n",
      "  ⚠ classic_pagination/40_fukushima_plant_operating_history_1970_2009: No rows to save\n",
      "  Fetching row 3/40...\n",
      "  Fetching range 3/4: year [1990, 2000)...\n",
      "  Fetching row 4/40...\n",
      "  Fetching partition 3/40: Year=1972...\n",
      "  Fetching range 4/4: year [2000, 2010)...\n",
      "  ✓ range_based/40_fukushima_plant_operating_history_1970_2009: 11 rows, 4358 tokens, 74.83s\n",
      "  ✓ full_table/40_fukushima_plant_operating_history_1970_2009: 40 rows, 5181 tokens, 82.19s\n",
      "  Fetching row 5/40...\n",
      "  Fetching partition 4/40: Year=1973...\n",
      "  Fetching row 6/40...\n",
      "  Fetching partition 5/40: Year=1974...\n",
      "  Fetching partition 6/40: Year=1975...\n",
      "  Fetching row 7/40...\n",
      "  Fetching partition 7/40: Year=1976...\n",
      "  Fetching row 8/40...\n",
      "  Fetching partition 8/40: Year=1977...\n",
      "  Fetching partition 9/40: Year=1978...\n",
      "  Fetching row 9/40...\n",
      "  Fetching partition 10/40: Year=1979...\n",
      "  Fetching row 10/40...\n",
      "  Fetching partition 11/40: Year=1980...\n",
      "  Fetching row 11/40...\n",
      "  Fetching partition 12/40: Year=1981...\n",
      "  Fetching row 12/40...\n",
      "  Fetching row 13/40...\n",
      "  Fetching partition 13/40: Year=1982...\n",
      "  Fetching row 14/40...\n",
      "  Fetching partition 14/40: Year=1983...\n",
      "  Fetching row 15/40...\n",
      "  Fetching row 16/40...\n",
      "  Fetching partition 15/40: Year=1984...\n",
      "  Fetching partition 16/40: Year=1985...\n",
      "  Fetching row 17/40...\n",
      "  Fetching partition 17/40: Year=1986...\n",
      "  Fetching row 18/40...\n",
      "  Fetching partition 18/40: Year=1987...\n",
      "  Fetching row 19/40...\n",
      "  Fetching row 20/40...\n",
      "  Fetching partition 19/40: Year=1988...\n",
      "  Fetching partition 20/40: Year=1989...\n",
      "  Fetching row 21/40...\n",
      "  Fetching row 22/40...\n",
      "  Fetching partition 21/40: Year=1990...\n",
      "  Fetching row 23/40...\n",
      "  Fetching partition 22/40: Year=1991...\n",
      "  Fetching row 24/40...\n",
      "  Fetching partition 23/40: Year=1992...\n",
      "  Fetching row 25/40...\n",
      "  Fetching partition 24/40: Year=1993...\n",
      "  Fetching row 26/40...\n",
      "  Fetching partition 25/40: Year=1994...\n",
      "  Fetching row 27/40...\n",
      "  Fetching partition 26/40: Year=1995...\n",
      "  Fetching row 28/40...\n",
      "  Fetching partition 27/40: Year=1996...\n",
      "  Fetching row 29/40...\n",
      "  Fetching partition 28/40: Year=1997...\n",
      "  Fetching partition 29/40: Year=1998...\n",
      "  Fetching row 30/40...\n",
      "  Fetching partition 30/40: Year=1999...\n",
      "  Fetching row 31/40...\n",
      "  Fetching partition 31/40: Year=2000...\n",
      "  Fetching row 32/40...\n",
      "  Fetching partition 32/40: Year=2001...\n",
      "  Fetching row 33/40...\n",
      "  Fetching partition 33/40: Year=2002...\n",
      "  Fetching row 34/40...\n",
      "  Fetching partition 34/40: Year=2003...\n",
      "  Fetching row 35/40...\n",
      "  Fetching partition 35/40: Year=2004...\n",
      "  Fetching row 36/40...\n",
      "  Fetching partition 36/40: Year=2005...\n",
      "  Fetching row 37/40...\n",
      "  Fetching partition 37/40: Year=2006...\n",
      "  Fetching row 38/40...\n",
      "  Fetching partition 38/40: Year=2007...\n",
      "  Fetching row 39/40...\n",
      "  Fetching row 40/40...\n",
      "  Fetching partition 39/40: Year=2008...\n",
      "  ✓ row_by_row/40_fukushima_plant_operating_history_1970_2009: 32 rows, 48344 tokens, 896.95s\n",
      "  Fetching partition 40/40: Year=2009...\n",
      "  ✓ attribute_based/40_fukushima_plant_operating_history_1970_2009: 29 rows, 50608 tokens, 929.43s\n",
      "\n",
      "======================================================================\n",
      "[16/30] Processing table: 41_new_zealand_football_results_1922_2012\n",
      "======================================================================\n",
      "Strategies: full_table, row_by_row, attribute_based, classic_pagination, range_based\n",
      "  Fetching full table...\n",
      "  Fetching row 1/91...\n",
      "  Fetching partition 1/54: Year=1922...\n",
      "  Fetching page 1 (offset 0, size 10)...\n",
      "  Fetching range 1/10: year [1920, 1930)...\n",
      "  Stopping: Empty result at offset 0\n",
      "  ⚠ classic_pagination/41_new_zealand_football_results_1922_2012: No rows to save\n",
      "  Fetching partition 2/54: Year=1923...\n",
      "  ⚠ full_table/41_new_zealand_football_results_1922_2012: No rows to save\n",
      "  Fetching range 2/10: year [1930, 1940)...\n",
      "  Fetching row 2/91...\n",
      "  Fetching range 3/10: year [1940, 1950)...\n",
      "  Fetching row 3/91...\n",
      "  Fetching partition 3/54: Year=1927...\n",
      "  Fetching range 4/10: year [1950, 1960)...\n",
      "  Fetching row 4/91...\n",
      "  Fetching partition 4/54: Year=1929...\n",
      "  Fetching row 5/91...\n",
      "  Fetching range 5/10: year [1960, 1970)...\n",
      "  Fetching row 6/91...\n",
      "  Fetching partition 5/54: Year=1933...\n",
      "  Fetching range 6/10: year [1970, 1980)...\n",
      "  Fetching row 7/91...\n",
      "  Fetching partition 6/54: Year=1936...\n",
      "  Fetching range 7/10: year [1980, 1990)...\n",
      "  Fetching row 8/91...\n",
      "  Fetching range 8/10: year [1990, 2000)...\n",
      "  Fetching partition 7/54: Year=1937...\n",
      "  Fetching row 9/91...\n",
      "  Fetching range 9/10: year [2000, 2010)...\n",
      "  Fetching row 10/91...\n",
      "  Fetching range 10/10: year [2010, 2020)...\n",
      "  Fetching partition 8/54: Year=1947...\n",
      "  Fetching row 11/91...\n",
      "  Fetching partition 9/54: Year=1951...\n",
      "  ✓ range_based/41_new_zealand_football_results_1922_2012: 11 rows, 9302 tokens, 198.10s\n",
      "  Fetching row 12/91...\n",
      "  Fetching partition 10/54: Year=1954...\n",
      "  Fetching row 13/91...\n",
      "  Fetching partition 11/54: Year=1958...\n",
      "  Fetching row 14/91...\n",
      "  Fetching row 15/91...\n",
      "  Fetching partition 12/54: Year=1960...\n",
      "  Fetching row 16/91...\n",
      "  Fetching partition 13/54: Year=1962...\n",
      "  Fetching row 17/91...\n",
      "  Fetching partition 14/54: Year=1967...\n",
      "  Fetching row 18/91...\n",
      "  Fetching partition 15/54: Year=1968...\n",
      "  Fetching row 19/91...\n",
      "  Fetching row 20/91...\n",
      "  Fetching partition 16/54: Year=1971...\n",
      "  Fetching row 21/91...\n",
      "  Fetching row 22/91...\n",
      "  Fetching partition 17/54: Year=1972...\n",
      "  Fetching row 23/91...\n",
      "  Fetching partition 18/54: Year=1973...\n",
      "  Fetching row 24/91...\n",
      "  Fetching partition 19/54: Year=1975...\n",
      "  Fetching row 25/91...\n",
      "  Fetching partition 20/54: Year=1977...\n",
      "  Fetching row 26/91...\n",
      "  Fetching partition 21/54: Year=1979...\n",
      "  Fetching row 27/91...\n",
      "  Fetching partition 22/54: Year=1980...\n",
      "  Fetching row 28/91...\n",
      "  Fetching row 29/91...\n",
      "  Fetching partition 23/54: Year=1981...\n",
      "  Fetching partition 24/54: Year=1982...\n",
      "  Fetching row 30/91...\n",
      "  Fetching partition 25/54: Year=1983...\n",
      "  Fetching row 31/91...\n",
      "  Fetching partition 26/54: Year=1984...\n",
      "  Fetching row 32/91...\n",
      "  Fetching row 33/91...\n",
      "  Fetching partition 27/54: Year=1985...\n",
      "  Fetching row 34/91...\n",
      "  Fetching partition 28/54: Year=1986...\n",
      "  Fetching row 35/91...\n",
      "  Fetching row 36/91...\n",
      "  Fetching partition 29/54: Year=1987...\n",
      "  Fetching row 37/91...\n",
      "  Fetching partition 30/54: Year=1988...\n",
      "  Fetching row 38/91...\n",
      "  Fetching partition 31/54: Year=1989...\n",
      "  Fetching row 39/91...\n",
      "  Fetching partition 32/54: Year=1990...\n",
      "  Fetching row 40/91...\n",
      "  Fetching row 41/91...\n",
      "  Fetching partition 33/54: Year=1991...\n",
      "  Fetching row 42/91...\n",
      "  Fetching partition 34/54: Year=1992...\n",
      "  Fetching row 43/91...\n",
      "  Fetching partition 35/54: Year=1993...\n",
      "  Fetching row 44/91...\n",
      "  Fetching row 45/91...\n",
      "  Fetching partition 36/54: Year=1994...\n",
      "  Fetching partition 37/54: Year=1995...\n",
      "  Fetching row 46/91...\n",
      "  Fetching partition 38/54: Year=1996...\n",
      "  Fetching row 47/91...\n",
      "  Fetching partition 39/54: Year=1997...\n",
      "  Fetching row 48/91...\n",
      "  Fetching partition 40/54: Year=1998...\n",
      "  Fetching partition 41/54: Year=1999...\n",
      "  Fetching row 49/91...\n",
      "  Fetching partition 42/54: Year=2000...\n",
      "  Fetching row 50/91...\n",
      "  Fetching partition 43/54: Year=2001...\n",
      "  Fetching row 51/91...\n",
      "  Fetching row 52/91...\n",
      "  Fetching partition 44/54: Year=2002...\n",
      "  Fetching row 53/91...\n",
      "  Fetching partition 45/54: Year=2003...\n",
      "  Fetching row 54/91...\n",
      "  Fetching partition 46/54: Year=2004...\n",
      "  Fetching row 55/91...\n",
      "  Fetching row 56/91...\n",
      "  Fetching partition 47/54: Year=2005...\n",
      "  Fetching row 57/91...\n",
      "  Fetching partition 48/54: Year=2006...\n",
      "  Fetching row 58/91...\n",
      "  Fetching row 59/91...\n",
      "  Fetching row 60/91...\n",
      "  Fetching partition 49/54: Year=2007...\n",
      "  Fetching row 61/91...\n",
      "  Fetching partition 50/54: Year=2008...\n",
      "  Fetching row 62/91...\n",
      "  Fetching row 63/91...\n",
      "  Fetching partition 51/54: Year=2009...\n",
      "  Fetching row 64/91...\n",
      "  Fetching partition 52/54: Year=2010...\n",
      "  Fetching row 65/91...\n",
      "  Fetching partition 53/54: Year=2011...\n",
      "  Fetching row 66/91...\n",
      "  Fetching partition 54/54: Year=2012...\n",
      "  Fetching row 67/91...\n",
      "  Fetching row 68/91...\n",
      "  ✓ attribute_based/41_new_zealand_football_results_1922_2012: 4 rows, 56745 tokens, 1144.80s\n",
      "  Fetching row 69/91...\n",
      "  Fetching row 70/91...\n",
      "  Fetching row 71/91...\n",
      "  Fetching row 72/91...\n",
      "  Fetching row 73/91...\n",
      "  Fetching row 74/91...\n",
      "  Fetching row 75/91...\n",
      "  Fetching row 76/91...\n",
      "  Fetching row 77/91...\n",
      "  Fetching row 78/91...\n",
      "  Fetching row 79/91...\n",
      "  Fetching row 80/91...\n",
      "  Fetching row 81/91...\n",
      "  Fetching row 82/91...\n",
      "  Fetching row 83/91...\n",
      "  Fetching row 84/91...\n",
      "  Fetching row 85/91...\n",
      "  Fetching row 86/91...\n",
      "  Fetching row 87/91...\n",
      "  Fetching row 88/91...\n",
      "  Fetching row 89/91...\n",
      "  Fetching row 90/91...\n",
      "  Fetching row 91/91...\n",
      "  ✓ row_by_row/41_new_zealand_football_results_1922_2012: 45 rows, 77478 tokens, 1496.63s\n",
      "\n",
      "======================================================================\n",
      "[17/30] Processing table: 42_jack_nicklaus_achievements_1962_2005\n",
      "======================================================================\n",
      "Strategies: full_table, row_by_row, attribute_based, classic_pagination, range_based\n",
      "  Fetching full table...\n",
      "  Fetching row 1/44...\n",
      "  Fetching partition 1/44: Year=1962...\n",
      "  Fetching page 1 (offset 0, size 10)...\n",
      "  Fetching range 1/5: Year [1960, 1970)...\n",
      "  Stopping: Empty result at offset 0\n",
      "  ⚠ classic_pagination/42_jack_nicklaus_achievements_1962_2005: No rows to save\n",
      "  ⚠ full_table/42_jack_nicklaus_achievements_1962_2005: No rows to save\n",
      "  Fetching range 2/5: Year [1970, 1980)...\n",
      "  Fetching partition 2/44: Year=1963...\n",
      "  Fetching row 2/44...\n",
      "  Fetching row 3/44...\n",
      "  Fetching partition 3/44: Year=1964...\n",
      "  Fetching row 4/44...\n",
      "  Fetching range 3/5: Year [1980, 1990)...\n",
      "  Fetching partition 4/44: Year=1965...\n",
      "  Fetching row 5/44...\n",
      "  Fetching row 6/44...\n",
      "  Fetching range 4/5: Year [1990, 2000)...\n",
      "  Fetching partition 5/44: Year=1966...\n",
      "  Fetching row 7/44...\n",
      "  Fetching range 5/5: Year [2000, 2010)...\n",
      "  Fetching row 8/44...\n",
      "  Fetching row 9/44...\n",
      "  Fetching partition 6/44: Year=1967...\n",
      "  ✓ range_based/42_jack_nicklaus_achievements_1962_2005: 10 rows, 5868 tokens, 101.91s\n",
      "  Fetching row 10/44...\n",
      "  Fetching row 11/44...\n",
      "  Fetching partition 7/44: Year=1968...\n",
      "  Fetching row 12/44...\n",
      "  Fetching row 13/44...\n",
      "  Fetching partition 8/44: Year=1969...\n",
      "  Fetching row 14/44...\n",
      "  Fetching partition 9/44: Year=1970...\n",
      "  Fetching row 15/44...\n",
      "  Fetching partition 10/44: Year=1971...\n",
      "  Fetching row 16/44...\n",
      "  Fetching row 17/44...\n",
      "  Fetching partition 11/44: Year=1972...\n",
      "  Fetching row 18/44...\n",
      "  Fetching row 19/44...\n",
      "  Fetching partition 12/44: Year=1973...\n",
      "  Fetching row 20/44...\n",
      "  Fetching row 21/44...\n",
      "  Fetching partition 13/44: Year=1974...\n",
      "  Fetching row 22/44...\n",
      "  Fetching partition 14/44: Year=1975...\n",
      "  Fetching row 23/44...\n",
      "  Fetching partition 15/44: Year=1976...\n",
      "  Fetching row 24/44...\n",
      "  Fetching partition 16/44: Year=1977...\n",
      "  Fetching partition 17/44: Year=1978...\n",
      "  Fetching row 25/44...\n",
      "  Fetching partition 18/44: Year=1979...\n",
      "  Fetching row 26/44...\n",
      "  Fetching row 27/44...\n",
      "  Fetching partition 19/44: Year=1980...\n",
      "  Fetching row 28/44...\n",
      "  Fetching row 29/44...\n",
      "  Fetching partition 20/44: Year=1981...\n",
      "  Fetching row 30/44...\n",
      "  Fetching row 31/44...\n",
      "  Fetching partition 21/44: Year=1982...\n",
      "  Fetching row 32/44...\n",
      "  Fetching partition 22/44: Year=1983...\n",
      "  Fetching row 33/44...\n",
      "  Fetching partition 23/44: Year=1984...\n",
      "  Fetching row 34/44...\n",
      "  Fetching row 35/44...\n",
      "  Fetching partition 24/44: Year=1985...\n",
      "  Fetching row 36/44...\n",
      "  Fetching row 37/44...\n",
      "  Fetching partition 25/44: Year=1986...\n",
      "  Fetching row 38/44...\n",
      "  Fetching partition 26/44: Year=1987...\n",
      "  Fetching row 39/44...\n",
      "  Fetching row 40/44...\n",
      "  Fetching row 41/44...\n",
      "  Fetching partition 27/44: Year=1988...\n",
      "  Fetching row 42/44...\n",
      "  Fetching partition 28/44: Year=1989...\n",
      "  Fetching row 43/44...\n",
      "  Fetching partition 29/44: Year=1990...\n",
      "  Fetching row 44/44...\n",
      "  Fetching partition 30/44: Year=1991...\n",
      "  ✓ row_by_row/42_jack_nicklaus_achievements_1962_2005: 10 rows, 40775 tokens, 578.52s\n",
      "  Fetching partition 31/44: Year=1992...\n",
      "  Fetching partition 32/44: Year=1993...\n",
      "  Fetching partition 33/44: Year=1994...\n",
      "  Fetching partition 34/44: Year=1995...\n",
      "  Fetching partition 35/44: Year=1996...\n",
      "  Fetching partition 36/44: Year=1997...\n",
      "  Fetching partition 37/44: Year=1998...\n",
      "  Fetching partition 38/44: Year=1999...\n",
      "  Fetching partition 39/44: Year=2000...\n",
      "  Fetching partition 40/44: Year=2001...\n",
      "  Fetching partition 41/44: Year=2002...\n",
      "  Fetching partition 42/44: Year=2003...\n",
      "  Fetching partition 43/44: Year=2004...\n",
      "  Fetching partition 44/44: Year=2005...\n",
      "  ✓ attribute_based/42_jack_nicklaus_achievements_1962_2005: 11 rows, 57478 tokens, 826.99s\n",
      "\n",
      "======================================================================\n",
      "[18/30] Processing table: 47_european_countries_gdp_2007_2012\n",
      "======================================================================\n",
      "Strategies: full_table, row_by_row, attribute_based, classic_pagination, range_based\n",
      "  Fetching full table...\n",
      "  Fetching row 1/50...\n",
      "  Fetching partition 1/100: 2012 Rank=1...\n",
      "  Fetching page 1 (offset 0, size 10)...\n",
      "  Fetching range 1/3: 2012 Rank [1, 11)...\n",
      "  Fetching row 2/50...\n",
      "  Fetching range 2/3: 2012 Rank [11, 21)...\n",
      "  Fetching row 3/50...\n",
      "  Stopping: Empty result at offset 0\n",
      "  ⚠ classic_pagination/47_european_countries_gdp_2007_2012: No rows to save\n",
      "  Fetching row 4/50...\n",
      "  Fetching partition 2/100: 2012 Rank=2...\n",
      "  Fetching range 3/3: 2012 Rank [21, 31)...\n",
      "  ✓ full_table/47_european_countries_gdp_2007_2012: 10 rows, 3565 tokens, 45.43s\n",
      "  Fetching row 5/50...\n",
      "  Fetching row 6/50...\n",
      "  ✓ range_based/47_european_countries_gdp_2007_2012: 10 rows, 4473 tokens, 64.85s\n",
      "  Fetching partition 3/100: 2012 Rank=3...\n",
      "  Fetching row 7/50...\n",
      "  Fetching partition 4/100: 2012 Rank=4...\n",
      "  Fetching row 8/50...\n",
      "  Fetching row 9/50...\n",
      "  Fetching row 10/50...\n",
      "  Fetching row 11/50...\n",
      "  Fetching partition 5/100: 2012 Rank=5...\n",
      "  Fetching row 12/50...\n",
      "  Fetching row 13/50...\n",
      "  Fetching row 14/50...\n",
      "  Fetching partition 6/100: 2012 Rank=6...\n",
      "  Fetching row 15/50...\n",
      "  Fetching row 16/50...\n",
      "  Fetching partition 7/100: 2012 Rank=7...\n",
      "  Fetching row 17/50...\n",
      "  Fetching row 18/50...\n",
      "  Fetching partition 8/100: 2012 Rank=8...\n",
      "  Fetching row 19/50...\n",
      "  Fetching row 20/50...\n",
      "  Fetching row 21/50...\n",
      "  Fetching partition 9/100: 2012 Rank=9...\n",
      "  Fetching row 22/50...\n",
      "  Fetching partition 10/100: 2012 Rank=10...\n",
      "  Fetching row 23/50...\n",
      "  Fetching row 24/50...\n",
      "  Fetching row 25/50...\n",
      "  Fetching partition 11/100: 2012 Rank=11...\n",
      "  Fetching row 26/50...\n",
      "  Fetching row 27/50...\n",
      "  Fetching row 28/50...\n",
      "  Fetching partition 12/100: 2012 Rank=12...\n",
      "  Fetching row 29/50...\n",
      "  Fetching row 30/50...\n",
      "  Fetching partition 13/100: 2012 Rank=13...\n",
      "  Fetching row 31/50...\n",
      "  Fetching row 32/50...\n",
      "  Fetching row 33/50...\n",
      "  Fetching row 34/50...\n",
      "  Fetching partition 14/100: 2012 Rank=14...\n",
      "  Fetching row 35/50...\n",
      "  Fetching partition 15/100: 2012 Rank=15...\n",
      "  Fetching row 36/50...\n",
      "  Fetching row 37/50...\n",
      "  Fetching row 38/50...\n",
      "  Fetching partition 16/100: 2012 Rank=16...\n",
      "  Fetching row 39/50...\n",
      "  Fetching partition 17/100: 2012 Rank=17...\n",
      "  Fetching row 40/50...\n",
      "  Fetching row 41/50...\n",
      "  Fetching partition 18/100: 2012 Rank=18...\n",
      "  Fetching row 42/50...\n",
      "  Fetching row 43/50...\n",
      "  Fetching partition 19/100: 2012 Rank=19...\n",
      "  Fetching row 44/50...\n",
      "  Fetching row 45/50...\n",
      "  Fetching row 46/50...\n",
      "  Fetching row 47/50...\n",
      "  Fetching partition 20/100: 2012 Rank=20...\n",
      "  Fetching row 48/50...\n",
      "  Fetching partition 21/100: 2012 Rank=21...\n",
      "  Fetching row 49/50...\n",
      "  Fetching partition 22/100: 2012 Rank=22...\n",
      "  Fetching row 50/50...\n",
      "  ✓ row_by_row/47_european_countries_gdp_2007_2012: 3 rows, 44920 tokens, 793.56s\n",
      "  Fetching partition 23/100: 2012 Rank=23...\n",
      "  Fetching partition 24/100: 2012 Rank=24...\n",
      "  Fetching partition 25/100: 2012 Rank=25...\n",
      "  Fetching partition 26/100: 2012 Rank=26...\n",
      "  Fetching partition 27/100: 2012 Rank=27...\n",
      "  Fetching partition 28/100: 2012 Rank=28...\n",
      "  Fetching partition 29/100: 2012 Rank=29...\n",
      "  Fetching partition 30/100: 2012 Rank=30...\n",
      "  Fetching partition 31/100: 2012 Rank=31...\n",
      "  Fetching partition 32/100: 2012 Rank=32...\n",
      "  Fetching partition 33/100: 2012 Rank=33...\n",
      "  Fetching partition 34/100: 2012 Rank=34...\n",
      "  Fetching partition 35/100: 2012 Rank=35...\n",
      "  Fetching partition 36/100: 2012 Rank=36...\n",
      "  Fetching partition 37/100: 2012 Rank=37...\n",
      "  Fetching partition 38/100: 2012 Rank=38...\n",
      "  Fetching partition 39/100: 2012 Rank=39...\n",
      "  Fetching partition 40/100: 2012 Rank=40...\n",
      "  Fetching partition 41/100: 2012 Rank=41...\n",
      "  Fetching partition 42/100: 2012 Rank=42...\n",
      "  Fetching partition 43/100: 2012 Rank=43...\n",
      "  Fetching partition 44/100: 2012 Rank=44...\n",
      "  Fetching partition 45/100: 2012 Rank=45...\n",
      "  Fetching partition 46/100: 2012 Rank=46...\n",
      "  Fetching partition 47/100: 2012 Rank=47...\n",
      "  Fetching partition 48/100: 2012 Rank=48...\n",
      "  Fetching partition 49/100: 2012 Rank=49...\n",
      "  Fetching partition 50/100: 2012 Rank=50...\n",
      "  Fetching partition 51/100: 2012 Rank=51...\n",
      "  Fetching partition 52/100: 2012 Rank=52...\n",
      "  Fetching partition 53/100: 2012 Rank=53...\n",
      "  Fetching partition 54/100: 2012 Rank=54...\n",
      "  Fetching partition 55/100: 2012 Rank=55...\n",
      "  Fetching partition 56/100: 2012 Rank=56...\n",
      "  Fetching partition 57/100: 2012 Rank=57...\n",
      "  Fetching partition 58/100: 2012 Rank=58...\n",
      "  Fetching partition 59/100: 2012 Rank=59...\n",
      "  Fetching partition 60/100: 2012 Rank=60...\n",
      "  Fetching partition 61/100: 2012 Rank=61...\n",
      "  Fetching partition 62/100: 2012 Rank=62...\n",
      "  Fetching partition 63/100: 2012 Rank=63...\n",
      "  Fetching partition 64/100: 2012 Rank=64...\n",
      "  Fetching partition 65/100: 2012 Rank=65...\n",
      "  Fetching partition 66/100: 2012 Rank=66...\n",
      "  Fetching partition 67/100: 2012 Rank=67...\n",
      "  Fetching partition 68/100: 2012 Rank=68...\n",
      "  Fetching partition 69/100: 2012 Rank=69...\n",
      "  Fetching partition 70/100: 2012 Rank=70...\n",
      "  Fetching partition 71/100: 2012 Rank=71...\n",
      "  Fetching partition 72/100: 2012 Rank=72...\n",
      "  Fetching partition 73/100: 2012 Rank=73...\n",
      "  Fetching partition 74/100: 2012 Rank=74...\n",
      "  Fetching partition 75/100: 2012 Rank=75...\n",
      "  Fetching partition 76/100: 2012 Rank=76...\n",
      "  Fetching partition 77/100: 2012 Rank=77...\n",
      "  Fetching partition 78/100: 2012 Rank=78...\n",
      "  Fetching partition 79/100: 2012 Rank=79...\n",
      "  Fetching partition 80/100: 2012 Rank=80...\n",
      "  Fetching partition 81/100: 2012 Rank=81...\n",
      "  Fetching partition 82/100: 2012 Rank=82...\n",
      "  Fetching partition 83/100: 2012 Rank=83...\n",
      "  Fetching partition 84/100: 2012 Rank=84...\n",
      "  Fetching partition 85/100: 2012 Rank=85...\n",
      "  Fetching partition 86/100: 2012 Rank=86...\n",
      "  Fetching partition 87/100: 2012 Rank=87...\n",
      "  Fetching partition 88/100: 2012 Rank=88...\n",
      "  Fetching partition 89/100: 2012 Rank=89...\n",
      "  Fetching partition 90/100: 2012 Rank=90...\n",
      "  Fetching partition 91/100: 2012 Rank=91...\n",
      "  Fetching partition 92/100: 2012 Rank=92...\n",
      "  Fetching partition 93/100: 2012 Rank=93...\n",
      "  Fetching partition 94/100: 2012 Rank=94...\n",
      "  Fetching partition 95/100: 2012 Rank=95...\n",
      "  Fetching partition 96/100: 2012 Rank=96...\n",
      "  Fetching partition 97/100: 2012 Rank=97...\n",
      "  Fetching partition 98/100: 2012 Rank=98...\n",
      "  Fetching partition 99/100: 2012 Rank=99...\n",
      "  Fetching partition 100/100: 2012 Rank=100...\n",
      "  ✓ attribute_based/47_european_countries_gdp_2007_2012: 28 rows, 180148 tokens, 2930.14s\n",
      "\n",
      "======================================================================\n",
      "[19/30] Processing table: 48_royal_dulton_figurines_HN4100_HN4199\n",
      "======================================================================\n",
      "Strategies: full_table, row_by_row, attribute_based, classic_pagination, range_based\n",
      "  Fetching full table...\n",
      "  Fetching row 1/100...\n",
      "  Fetching partition 1/100: HN Number=HN4100...\n",
      "  Fetching page 1 (offset 0, size 10)...\n",
      "  Fetching range 1/10: HN Number [HN4100, HN4110)...\n",
      "  Stopping: Empty result at offset 0\n",
      "  ⚠ classic_pagination/48_royal_dulton_figurines_HN4100_HN4199: No rows to save\n",
      "  Fetching row 2/100...\n",
      "  ⚠ full_table/48_royal_dulton_figurines_HN4100_HN4199: No rows to save\n",
      "  Fetching range 2/10: HN Number [HN4110, HN4120)...\n",
      "  Fetching partition 2/100: HN Number=HN4101...\n",
      "  Fetching range 3/10: HN Number [HN4120, HN4130)...\n",
      "  Fetching row 3/100...\n",
      "  Fetching partition 3/100: HN Number=HN4102...\n",
      "  Fetching range 4/10: HN Number [HN4130, HN4140)...\n",
      "  Fetching row 4/100...\n",
      "  Fetching partition 4/100: HN Number=HN4103...\n",
      "  Fetching range 5/10: HN Number [HN4140, HN4150)...\n",
      "  Fetching partition 5/100: HN Number=HN4104...\n",
      "  Fetching row 5/100...\n",
      "  Fetching range 6/10: HN Number [HN4150, HN4160)...\n",
      "  Fetching partition 6/100: HN Number=HN4105...\n",
      "  Fetching row 6/100...\n",
      "  Fetching range 7/10: HN Number [HN4160, HN4170)...\n",
      "  Fetching row 7/100...\n",
      "  Fetching range 8/10: HN Number [HN4170, HN4180)...\n",
      "  Fetching partition 7/100: HN Number=HN4106...\n",
      "  Fetching partition 8/100: HN Number=HN4107...\n",
      "  Fetching row 8/100...\n",
      "  Fetching range 9/10: HN Number [HN4180, HN4190)...\n",
      "  Fetching range 10/10: HN Number [HN4190, HN4200)...\n",
      "  Fetching row 9/100...\n",
      "  Fetching partition 9/100: HN Number=HN4108...\n",
      "  Fetching partition 10/100: HN Number=HN4109...\n",
      "  Fetching row 10/100...\n",
      "  Fetching partition 11/100: HN Number=HN4110...\n",
      "  ⚠ range_based/48_royal_dulton_figurines_HN4100_HN4199: No rows to save\n",
      "  Fetching row 11/100...\n",
      "  Fetching row 12/100...\n",
      "  Fetching partition 12/100: HN Number=HN4111...\n",
      "  Fetching row 13/100...\n",
      "  Fetching partition 13/100: HN Number=HN4112...\n",
      "  Fetching row 14/100...\n",
      "  Fetching partition 14/100: HN Number=HN4113...\n",
      "  Fetching row 15/100...\n",
      "  Fetching partition 15/100: HN Number=HN4114...\n",
      "  Fetching row 16/100...\n",
      "  Fetching partition 16/100: HN Number=HN4115...\n",
      "  Fetching row 17/100...\n",
      "  Fetching partition 17/100: HN Number=HN4116...\n",
      "  Fetching row 18/100...\n",
      "  Fetching partition 18/100: HN Number=HN4117...\n",
      "  Fetching row 19/100...\n",
      "  Fetching partition 19/100: HN Number=HN4118...\n",
      "  Fetching row 20/100...\n",
      "  Fetching row 21/100...\n",
      "  Fetching row 22/100...\n",
      "  Fetching partition 20/100: HN Number=HN4119...\n",
      "  Fetching row 23/100...\n",
      "  Fetching partition 21/100: HN Number=HN4120...\n",
      "  Fetching row 24/100...\n",
      "  Fetching partition 22/100: HN Number=HN4121...\n",
      "  Fetching row 25/100...\n",
      "  Fetching partition 23/100: HN Number=HN4122...\n",
      "  Fetching row 26/100...\n",
      "  Fetching partition 24/100: HN Number=HN4123...\n",
      "  Fetching row 27/100...\n",
      "  Fetching partition 25/100: HN Number=HN4124...\n",
      "  Fetching row 28/100...\n",
      "  Fetching partition 26/100: HN Number=HN4125...\n",
      "  Fetching row 29/100...\n",
      "  Fetching partition 27/100: HN Number=HN4126...\n",
      "  Fetching row 30/100...\n",
      "  Fetching partition 28/100: HN Number=HN4127...\n",
      "  Fetching row 31/100...\n",
      "  Fetching partition 29/100: HN Number=HN4128...\n",
      "  Fetching row 32/100...\n",
      "  Fetching partition 30/100: HN Number=HN4129...\n",
      "  Fetching row 33/100...\n",
      "  Fetching partition 31/100: HN Number=HN4130...\n",
      "  Fetching partition 32/100: HN Number=HN4131...\n",
      "  Fetching row 34/100...\n",
      "  Fetching row 35/100...\n",
      "  Fetching partition 33/100: HN Number=HN4132...\n",
      "  Fetching row 36/100...\n",
      "  Fetching partition 34/100: HN Number=HN4133...\n",
      "  Fetching row 37/100...\n",
      "  Fetching partition 35/100: HN Number=HN4134...\n",
      "  Fetching row 38/100...\n",
      "  Fetching partition 36/100: HN Number=HN4135...\n",
      "  Fetching row 39/100...\n",
      "  Fetching row 40/100...\n",
      "  Fetching partition 37/100: HN Number=HN4136...\n",
      "  Fetching row 41/100...\n",
      "  Fetching partition 38/100: HN Number=HN4137...\n",
      "  Fetching row 42/100...\n",
      "  Fetching partition 39/100: HN Number=HN4138...\n",
      "  Fetching row 43/100...\n",
      "  Fetching partition 40/100: HN Number=HN4139...\n",
      "  Fetching row 44/100...\n",
      "  Fetching partition 41/100: HN Number=HN4140...\n",
      "  Fetching row 45/100...\n",
      "  Fetching partition 42/100: HN Number=HN4141...\n",
      "  Fetching row 46/100...\n",
      "  Fetching partition 43/100: HN Number=HN4142...\n",
      "  Fetching row 47/100...\n",
      "  Fetching partition 44/100: HN Number=HN4143...\n",
      "  Fetching row 48/100...\n",
      "  Fetching row 49/100...\n",
      "  Fetching partition 45/100: HN Number=HN4144...\n",
      "  Fetching row 50/100...\n",
      "  Fetching partition 46/100: HN Number=HN4145...\n",
      "  Fetching row 51/100...\n",
      "  Fetching partition 47/100: HN Number=HN4146...\n",
      "  Fetching row 52/100...\n",
      "  Fetching partition 48/100: HN Number=HN4147...\n",
      "  Fetching row 53/100...\n",
      "  Fetching partition 49/100: HN Number=HN4148...\n",
      "  Fetching row 54/100...\n",
      "  Fetching partition 50/100: HN Number=HN4149...\n",
      "  Fetching partition 51/100: HN Number=HN4150...\n",
      "  Fetching row 55/100...\n",
      "  Fetching partition 52/100: HN Number=HN4151...\n",
      "  Fetching row 56/100...\n",
      "  Fetching partition 53/100: HN Number=HN4152...\n",
      "  Fetching row 57/100...\n",
      "  Fetching row 58/100...\n",
      "  Fetching partition 54/100: HN Number=HN4153...\n",
      "  Fetching row 59/100...\n",
      "  Fetching partition 55/100: HN Number=HN4154...\n",
      "  Fetching row 60/100...\n",
      "  Fetching partition 56/100: HN Number=HN4155...\n",
      "  Fetching row 61/100...\n",
      "  Fetching row 62/100...\n",
      "  Fetching partition 57/100: HN Number=HN4156...\n",
      "  Fetching row 63/100...\n",
      "  Fetching partition 58/100: HN Number=HN4157...\n",
      "  Fetching row 64/100...\n",
      "  Fetching row 65/100...\n",
      "  Fetching partition 59/100: HN Number=HN4158...\n",
      "  Fetching row 66/100...\n",
      "  Fetching partition 60/100: HN Number=HN4159...\n",
      "  Fetching row 67/100...\n",
      "  Fetching partition 61/100: HN Number=HN4160...\n",
      "  Fetching row 68/100...\n",
      "  Fetching partition 62/100: HN Number=HN4161...\n",
      "  Fetching row 69/100...\n",
      "  Fetching row 70/100...\n",
      "  Fetching partition 63/100: HN Number=HN4162...\n",
      "  Fetching row 71/100...\n",
      "  Fetching partition 64/100: HN Number=HN4163...\n",
      "  Fetching row 72/100...\n",
      "  Fetching row 73/100...\n",
      "  Fetching partition 65/100: HN Number=HN4164...\n",
      "  Fetching row 74/100...\n",
      "  Fetching partition 66/100: HN Number=HN4165...\n",
      "  Fetching row 75/100...\n",
      "  Fetching partition 67/100: HN Number=HN4166...\n",
      "  Fetching partition 68/100: HN Number=HN4167...\n",
      "  Fetching row 76/100...\n",
      "  Fetching partition 69/100: HN Number=HN4168...\n",
      "  Fetching row 77/100...\n",
      "  Fetching row 78/100...\n",
      "  Fetching partition 70/100: HN Number=HN4169...\n",
      "  Fetching row 79/100...\n",
      "  Fetching partition 71/100: HN Number=HN4170...\n",
      "  Fetching row 80/100...\n",
      "  Fetching partition 72/100: HN Number=HN4171...\n",
      "  Fetching partition 73/100: HN Number=HN4172...\n",
      "  Fetching row 81/100...\n",
      "  Fetching partition 74/100: HN Number=HN4173...\n",
      "  Fetching row 82/100...\n",
      "  Fetching partition 75/100: HN Number=HN4174...\n",
      "  Fetching row 83/100...\n",
      "  Fetching row 84/100...\n",
      "  Fetching partition 76/100: HN Number=HN4175...\n",
      "  Fetching partition 77/100: HN Number=HN4176...\n",
      "  Fetching partition 78/100: HN Number=HN4177...\n",
      "  Fetching row 85/100...\n",
      "  Fetching partition 79/100: HN Number=HN4178...\n",
      "  Fetching row 86/100...\n",
      "  Fetching row 87/100...\n",
      "  Fetching partition 80/100: HN Number=HN4179...\n",
      "  Fetching row 88/100...\n",
      "  Fetching partition 81/100: HN Number=HN4180...\n",
      "  Fetching row 89/100...\n",
      "  Fetching partition 82/100: HN Number=HN4181...\n",
      "  Fetching row 90/100...\n",
      "  Fetching row 91/100...\n",
      "  Fetching partition 83/100: HN Number=HN4182...\n",
      "  Fetching row 92/100...\n",
      "  Fetching partition 84/100: HN Number=HN4183...\n",
      "  Fetching row 93/100...\n",
      "  Fetching partition 85/100: HN Number=HN4184...\n",
      "  Fetching partition 86/100: HN Number=HN4185...\n",
      "  Fetching row 94/100...\n",
      "  Fetching row 95/100...\n",
      "  Fetching partition 87/100: HN Number=HN4186...\n",
      "  Fetching row 96/100...\n",
      "  Fetching partition 88/100: HN Number=HN4187...\n",
      "  Fetching row 97/100...\n",
      "  Fetching partition 89/100: HN Number=HN4188...\n",
      "  Fetching row 98/100...\n",
      "  Fetching partition 90/100: HN Number=HN4189...\n",
      "  Fetching partition 91/100: HN Number=HN4190...\n",
      "  Fetching row 99/100...\n",
      "  Fetching partition 92/100: HN Number=HN4191...\n",
      "  Fetching row 100/100...\n",
      "  Fetching partition 93/100: HN Number=HN4192...\n",
      "  ✓ row_by_row/48_royal_dulton_figurines_HN4100_HN4199: 84 rows, 76870 tokens, 1403.19s\n",
      "  Fetching partition 94/100: HN Number=HN4193...\n",
      "  Fetching partition 95/100: HN Number=HN4194...\n",
      "  Fetching partition 96/100: HN Number=HN4195...\n",
      "  Fetching partition 97/100: HN Number=HN4196...\n",
      "  Fetching partition 98/100: HN Number=HN4197...\n",
      "  Fetching partition 99/100: HN Number=HN4198...\n",
      "  Fetching partition 100/100: HN Number=HN4199...\n",
      "  ✓ attribute_based/48_royal_dulton_figurines_HN4100_HN4199: 20 rows, 76724 tokens, 1507.54s\n",
      "\n",
      "======================================================================\n",
      "[20/30] Processing table: 49_adaalat_episodes_2012\n",
      "======================================================================\n",
      "Strategies: full_table, row_by_row, attribute_based, classic_pagination, range_based\n",
      "  Fetching full table...\n",
      "  Fetching row 1/60...\n",
      "  Fetching partition 1/50: Year Case No=2012 Case No 1...\n",
      "  Fetching page 1 (offset 0, size 10)...\n",
      "  Fetching range 1/12: Original Air Date [2012-01-01, 2012-02-01)...\n",
      "  Stopping: Empty result at offset 0\n",
      "  ⚠ classic_pagination/49_adaalat_episodes_2012: No rows to save\n",
      "  Fetching range 2/12: Original Air Date [2012-02-01, 2012-03-01)...\n",
      "  ⚠ full_table/49_adaalat_episodes_2012: No rows to save\n",
      "  Fetching range 3/12: Original Air Date [2012-03-01, 2012-04-01)...\n",
      "  Fetching partition 2/50: Year Case No=2012 Case No 2...\n",
      "  Fetching row 2/60...\n",
      "  Fetching partition 3/50: Year Case No=2012 Case No 3...\n",
      "  Fetching range 4/12: Original Air Date [2012-04-01, 2012-05-01)...\n",
      "  Fetching row 3/60...\n",
      "  Fetching range 5/12: Original Air Date [2012-05-01, 2012-06-01)...\n",
      "  Fetching partition 4/50: Year Case No=2012 Case No 4...\n",
      "  Fetching row 4/60...\n",
      "  Fetching range 6/12: Original Air Date [2012-06-01, 2012-07-01)...\n",
      "  Fetching row 5/60...\n",
      "  Fetching partition 5/50: Year Case No=2012 Case No 5...\n",
      "  Fetching range 7/12: Original Air Date [2012-07-01, 2012-08-01)...\n",
      "  Fetching partition 6/50: Year Case No=2012 Case No 6...\n",
      "  Fetching range 8/12: Original Air Date [2012-08-01, 2012-09-01)...\n",
      "  Fetching row 6/60...\n",
      "  Fetching range 9/12: Original Air Date [2012-09-01, 2012-10-01)...\n",
      "  Fetching partition 7/50: Year Case No=2012 Case No 7...\n",
      "  Fetching range 10/12: Original Air Date [2012-10-01, 2012-11-01)...\n",
      "  Fetching partition 8/50: Year Case No=2012 Case No 8...\n",
      "  Fetching row 7/60...\n",
      "  Fetching partition 9/50: Year Case No=2012 Case No 9...\n",
      "  Fetching range 11/12: Original Air Date [2012-11-01, 2012-12-01)...\n",
      "  Fetching row 8/60...\n",
      "  Fetching range 12/12: Original Air Date [2012-12-01, 2013-01-01)...\n",
      "  Fetching row 9/60...\n",
      "  Fetching partition 10/50: Year Case No=2012 Case No 10...\n",
      "  ⚠ range_based/49_adaalat_episodes_2012: No rows to save\n",
      "  Fetching row 10/60...\n",
      "  Fetching partition 11/50: Year Case No=2012 Case No 11...\n",
      "  Fetching partition 12/50: Year Case No=2012 Case No 12...\n",
      "  Fetching row 11/60...\n",
      "  Fetching row 12/60...\n",
      "  Fetching partition 13/50: Year Case No=2012 Case No 13...\n",
      "  Fetching row 13/60...\n",
      "  Fetching partition 14/50: Year Case No=2012 Case No 14...\n",
      "  Fetching row 14/60...\n",
      "  Fetching partition 15/50: Year Case No=2012 Case No 15...\n",
      "  Fetching row 15/60...\n",
      "  Fetching partition 16/50: Year Case No=2012 Case No 16...\n",
      "  Fetching row 16/60...\n",
      "  Fetching partition 17/50: Year Case No=2012 Case No 17...\n",
      "  Fetching row 17/60...\n",
      "  Fetching partition 18/50: Year Case No=2012 Case No 18...\n",
      "  Fetching row 18/60...\n",
      "  Fetching partition 19/50: Year Case No=2012 Case No 19...\n",
      "  Fetching partition 20/50: Year Case No=2012 Case No 20...\n",
      "  Fetching row 19/60...\n",
      "  Fetching partition 21/50: Year Case No=2012 Case No 21...\n",
      "  Fetching row 20/60...\n",
      "  Fetching partition 22/50: Year Case No=2012 Case No 22...\n",
      "  Fetching row 21/60...\n",
      "  Fetching partition 23/50: Year Case No=2012 Case No 23...\n",
      "  Fetching partition 24/50: Year Case No=2012 Case No 24...\n",
      "  Fetching row 22/60...\n",
      "  Fetching row 23/60...\n",
      "  Fetching partition 25/50: Year Case No=2012 Case No 25...\n",
      "  Fetching row 24/60...\n",
      "  Fetching partition 26/50: Year Case No=2012 Case No 26...\n",
      "  Fetching partition 27/50: Year Case No=2012 Case No 27...\n",
      "  Fetching row 25/60...\n",
      "  Fetching partition 28/50: Year Case No=2012 Case No 28...\n",
      "  Fetching row 26/60...\n",
      "  Fetching partition 29/50: Year Case No=2012 Case No 29...\n",
      "  Fetching row 27/60...\n",
      "  Fetching partition 30/50: Year Case No=2012 Case No 30...\n",
      "  Fetching partition 31/50: Year Case No=2012 Case No 31...\n",
      "  Fetching row 28/60...\n",
      "  Fetching partition 32/50: Year Case No=2012 Case No 32...\n",
      "  Fetching row 29/60...\n",
      "  Fetching partition 33/50: Year Case No=2012 Case No 33...\n",
      "  Fetching partition 34/50: Year Case No=2012 Case No 34...\n",
      "  Fetching row 30/60...\n",
      "  Fetching row 31/60...\n",
      "  Fetching partition 35/50: Year Case No=2012 Case No 35...\n",
      "  Fetching partition 36/50: Year Case No=2012 Case No 36...\n",
      "  Fetching row 32/60...\n",
      "  Fetching partition 37/50: Year Case No=2012 Case No 37...\n",
      "  Fetching row 33/60...\n",
      "  Fetching partition 38/50: Year Case No=2012 Case No 38...\n",
      "  Fetching row 34/60...\n",
      "  Fetching partition 39/50: Year Case No=2012 Case No 39...\n",
      "  Fetching row 35/60...\n",
      "  Fetching partition 40/50: Year Case No=2012 Case No 40...\n",
      "  Fetching partition 41/50: Year Case No=2012 Case No 41...\n",
      "  Fetching row 36/60...\n",
      "  Fetching partition 42/50: Year Case No=2012 Case No 42...\n",
      "  Fetching row 37/60...\n",
      "  Fetching partition 43/50: Year Case No=2012 Case No 43...\n",
      "  Fetching partition 44/50: Year Case No=2012 Case No 44...\n",
      "  Fetching partition 45/50: Year Case No=2012 Case No 45...\n",
      "  Fetching row 38/60...\n",
      "  Fetching partition 46/50: Year Case No=2012 Case No 46...\n",
      "  Fetching row 39/60...\n",
      "  Fetching row 40/60...\n",
      "  Fetching partition 47/50: Year Case No=2012 Case No 47...\n",
      "  Fetching partition 48/50: Year Case No=2012 Case No 48...\n",
      "  Fetching row 41/60...\n",
      "  Fetching partition 49/50: Year Case No=2012 Case No 49...\n",
      "  Fetching row 42/60...\n",
      "  Fetching partition 50/50: Year Case No=2012 Case No 50...\n",
      "  Fetching row 43/60...\n",
      "  ⚠ attribute_based/49_adaalat_episodes_2012: No rows to save\n",
      "  Fetching row 44/60...\n",
      "  Fetching row 45/60...\n",
      "  Fetching row 46/60...\n",
      "  Fetching row 47/60...\n",
      "  Fetching row 48/60...\n",
      "  Fetching row 49/60...\n",
      "  Fetching row 50/60...\n",
      "  Fetching row 51/60...\n",
      "  Fetching row 52/60...\n",
      "  Fetching row 53/60...\n",
      "  Fetching row 54/60...\n",
      "  Fetching row 55/60...\n",
      "  Fetching row 56/60...\n",
      "  Fetching row 57/60...\n",
      "  Fetching row 58/60...\n",
      "  Fetching row 59/60...\n",
      "  Fetching row 60/60...\n",
      "  ✓ row_by_row/49_adaalat_episodes_2012: 43 rows, 51067 tokens, 757.57s\n",
      "\n",
      "======================================================================\n",
      "[21/30] Processing table: 4_new_brunswick_parishes_2006_2011\n",
      "======================================================================\n",
      "Strategies: full_table, row_by_row, attribute_based, classic_pagination, range_based\n",
      "  Fetching full table...\n",
      "  Fetching row 1/43...\n",
      "  Fetching partition 1/16: County=Albert...\n",
      "  Fetching page 1 (offset 0, size 10)...\n",
      "  Fetching range 1/20: Population (2011) [0, 500)...\n",
      "  ✓ full_table/4_new_brunswick_parishes_2006_2011: 1 rows, 890 tokens, 13.81s\n",
      "  Fetching partition 2/16: County=Carleton...\n",
      "  Fetching row 2/43...\n",
      "  Fetching range 2/20: Population (2011) [500, 1000)...\n",
      "  Stopping: Empty result at offset 0\n",
      "  ⚠ classic_pagination/4_new_brunswick_parishes_2006_2011: No rows to save\n",
      "  Fetching row 3/43...\n",
      "  Fetching range 3/20: Population (2011) [1000, 1500)...\n",
      "  Fetching partition 3/16: County=Charlotte...\n",
      "  Fetching row 4/43...\n",
      "  Fetching range 4/20: Population (2011) [1500, 2000)...\n",
      "  Fetching partition 4/16: County=Gloucester...\n",
      "  Fetching partition 5/16: County=Kent...\n",
      "  Fetching row 5/43...\n",
      "  Fetching partition 6/16: County=Kings...\n",
      "  Fetching range 5/20: Population (2011) [2000, 2500)...\n",
      "  Fetching row 6/43...\n",
      "  Fetching row 7/43...\n",
      "  Fetching range 6/20: Population (2011) [2500, 3000)...\n",
      "  Fetching partition 7/16: County=Madawaska...\n",
      "  Fetching row 8/43...\n",
      "  Fetching range 7/20: Population (2011) [3000, 3500)...\n",
      "  Fetching row 9/43...\n",
      "  Fetching partition 8/16: County=Maddox...\n",
      "  Fetching row 10/43...\n",
      "  Fetching range 8/20: Population (2011) [3500, 4000)...\n",
      "  Fetching partition 9/16: County=Northumberland...\n",
      "  Fetching range 9/20: Population (2011) [4000, 4500)...\n",
      "  Fetching row 11/43...\n",
      "  Fetching range 10/20: Population (2011) [4500, 5000)...\n",
      "  Fetching partition 10/16: County=Queens...\n",
      "  Fetching row 12/43...\n",
      "  Fetching range 11/20: Population (2011) [5000, 5500)...\n",
      "  Fetching row 13/43...\n",
      "  Fetching partition 11/16: County=Restigouche...\n",
      "  Fetching partition 12/16: County=Saint John...\n",
      "  Fetching range 12/20: Population (2011) [5500, 6000)...\n",
      "  Fetching row 14/43...\n",
      "  Fetching partition 13/16: County=Sunbury...\n",
      "  Fetching range 13/20: Population (2011) [6000, 6500)...\n",
      "  Fetching row 15/43...\n",
      "  Fetching range 14/20: Population (2011) [6500, 7000)...\n",
      "  Fetching row 16/43...\n",
      "  Fetching partition 14/16: County=Victoria...\n",
      "  Fetching range 15/20: Population (2011) [7000, 7500)...\n",
      "  Fetching row 17/43...\n",
      "  Fetching partition 15/16: County=Westmorland...\n",
      "  Fetching row 18/43...\n",
      "  Fetching range 16/20: Population (2011) [7500, 8000)...\n",
      "  Fetching partition 16/16: County=York...\n",
      "  Fetching row 19/43...\n",
      "  Fetching range 17/20: Population (2011) [8000, 8500)...\n",
      "  Fetching row 20/43...\n",
      "  ✓ attribute_based/4_new_brunswick_parishes_2006_2011: 3 rows, 17095 tokens, 327.86s\n",
      "  Fetching range 18/20: Population (2011) [8500, 9000)...\n",
      "  Fetching row 21/43...\n",
      "  Fetching range 19/20: Population (2011) [9000, 9500)...\n",
      "  Fetching row 22/43...\n",
      "  Fetching range 20/20: Population (2011) [9500, 10000)...\n",
      "  ✓ range_based/4_new_brunswick_parishes_2006_2011: 5 rows, 19583 tokens, 378.54s\n",
      "  Fetching row 23/43...\n",
      "  Fetching row 24/43...\n",
      "  Fetching row 25/43...\n",
      "  Fetching row 26/43...\n",
      "  Fetching row 27/43...\n",
      "  Fetching row 28/43...\n",
      "  Fetching row 29/43...\n",
      "  Fetching row 30/43...\n",
      "  Fetching row 31/43...\n",
      "  Fetching row 32/43...\n",
      "  Fetching row 33/43...\n",
      "  Fetching row 34/43...\n",
      "  Fetching row 35/43...\n",
      "  Fetching row 36/43...\n",
      "  Fetching row 37/43...\n",
      "  Fetching row 38/43...\n",
      "  Fetching row 39/43...\n",
      "  Fetching row 40/43...\n",
      "  Fetching row 41/43...\n",
      "  Fetching row 42/43...\n",
      "  Fetching row 43/43...\n",
      "  ✓ row_by_row/4_new_brunswick_parishes_2006_2011: 14 rows, 40363 tokens, 729.96s\n",
      "\n",
      "======================================================================\n",
      "[22/30] Processing table: 52_cross_country_junior_women_1996\n",
      "======================================================================\n",
      "Strategies: full_table, row_by_row, attribute_based, classic_pagination, range_based\n",
      "  Fetching full table...\n",
      "  Fetching row 1/10...\n",
      "  Fetching partition 1/25: Country=Ethiopia...\n",
      "  Fetching page 1 (offset 0, size 10)...\n",
      "  Fetching range 1/10: Rank [1, 11)...\n",
      "  ⚠ full_table/52_cross_country_junior_women_1996: No rows to save\n",
      "  Fetching partition 2/25: Country=Kenya...\n",
      "  Fetching range 2/10: Rank [11, 21)...\n",
      "  Fetching row 2/10...\n",
      "  Stopping: Empty result at offset 0\n",
      "  ⚠ classic_pagination/52_cross_country_junior_women_1996: No rows to save\n",
      "  Fetching partition 3/25: Country=Japan...\n",
      "  Fetching range 3/10: Rank [21, 31)...\n",
      "  Fetching row 3/10...\n",
      "  Fetching partition 4/25: Country=Portugal...\n",
      "  Fetching row 4/10...\n",
      "  Fetching range 4/10: Rank [31, 41)...\n",
      "  Fetching row 5/10...\n",
      "  Fetching partition 5/25: Country=Morocco...\n",
      "  Fetching range 5/10: Rank [41, 51)...\n",
      "  Fetching row 6/10...\n",
      "  Fetching partition 6/25: Country=Spain...\n",
      "  Fetching row 7/10...\n",
      "  Fetching range 6/10: Rank [51, 61)...\n",
      "  Fetching partition 7/25: Country=France...\n",
      "  Fetching row 8/10...\n",
      "  Fetching range 7/10: Rank [61, 71)...\n",
      "  Fetching partition 8/25: Country=Great Britain...\n",
      "  Fetching range 8/10: Rank [71, 81)...\n",
      "  Fetching row 9/10...\n",
      "  Fetching range 9/10: Rank [81, 91)...\n",
      "  Fetching partition 9/25: Country=United States...\n",
      "  Fetching row 10/10...\n",
      "  Fetching range 10/10: Rank [91, 101)...\n",
      "  ✓ row_by_row/52_cross_country_junior_women_1996: 4 rows, 8049 tokens, 105.94s\n",
      "  Fetching partition 10/25: Country=Italy...\n",
      "  ✓ range_based/52_cross_country_junior_women_1996: 2 rows, 6442 tokens, 119.57s\n",
      "  Fetching partition 11/25: Country=Germany...\n",
      "  Fetching partition 12/25: Country=Ireland...\n",
      "  Fetching partition 13/25: Country=Australia...\n",
      "  Fetching partition 14/25: Country=Canada...\n",
      "  Fetching partition 15/25: Country=New Zealand...\n",
      "  Fetching partition 16/25: Country=Norway...\n",
      "  Fetching partition 17/25: Country=Sweden...\n",
      "  Fetching partition 18/25: Country=Finland...\n",
      "  Fetching partition 19/25: Country=Belgium...\n",
      "  Fetching partition 20/25: Country=Netherlands...\n",
      "  Fetching partition 21/25: Country=Czech Republic...\n",
      "  Fetching partition 22/25: Country=Poland...\n",
      "  Fetching partition 23/25: Country=Russia...\n",
      "  Fetching partition 24/25: Country=Switzerland...\n",
      "  Fetching partition 25/25: Country=South Africa...\n",
      "  ✓ attribute_based/52_cross_country_junior_women_1996: 2 rows, 19385 tokens, 339.12s\n",
      "\n",
      "======================================================================\n",
      "[23/30] Processing table: 54_kasparov_kramnik_1993_2004\n",
      "======================================================================\n",
      "Strategies: full_table, row_by_row, attribute_based, classic_pagination, range_based\n",
      "  Fetching full table...\n",
      "  Fetching row 1/40...\n",
      "  Fetching partition 1/12: Year=1993...\n",
      "  Fetching page 1 (offset 0, size 10)...\n",
      "  Fetching range 1/12: year [1993, 1994)...\n",
      "  Fetching range 2/12: year [1994, 1995)...\n",
      "  Fetching row 2/40...\n",
      "  Fetching partition 2/12: Year=1994...\n",
      "  Stopping: Empty result at offset 0\n",
      "  ⚠ classic_pagination/54_kasparov_kramnik_1993_2004: No rows to save\n",
      "  Fetching range 3/12: year [1995, 1996)...\n",
      "  Fetching row 3/40...\n",
      "  Fetching partition 3/12: Year=1995...\n",
      "  Fetching range 4/12: year [1996, 1997)...\n",
      "  Fetching row 4/40...\n",
      "  Fetching partition 4/12: Year=1996...\n",
      "  ⚠ full_table/54_kasparov_kramnik_1993_2004: No rows to save\n",
      "  Fetching row 5/40...\n",
      "  Fetching range 5/12: year [1997, 1998)...\n",
      "  Fetching partition 5/12: Year=1997...\n",
      "  Fetching range 6/12: year [1998, 1999)...\n",
      "  Fetching row 6/40...\n",
      "  Fetching partition 6/12: Year=1998...\n",
      "  Fetching row 7/40...\n",
      "  Fetching range 7/12: year [1999, 2000)...\n",
      "  Fetching row 8/40...\n",
      "  Fetching partition 7/12: Year=1999...\n",
      "  Fetching range 8/12: year [2000, 2001)...\n",
      "  Fetching partition 8/12: Year=2000...\n",
      "  Fetching row 9/40...\n",
      "  Fetching row 10/40...\n",
      "  Fetching row 11/40...\n",
      "  Fetching range 9/12: year [2001, 2002)...\n",
      "  Fetching partition 9/12: Year=2001...\n",
      "  Fetching range 10/12: year [2002, 2003)...\n",
      "  Fetching row 12/40...\n",
      "  Fetching row 13/40...\n",
      "  Fetching partition 10/12: Year=2002...\n",
      "  Fetching range 11/12: year [2003, 2004)...\n",
      "  Fetching partition 11/12: Year=2003...\n",
      "  Fetching row 14/40...\n",
      "  Fetching row 15/40...\n",
      "  Fetching range 12/12: year [2004, 2005)...\n",
      "  Fetching partition 12/12: Year=2004...\n",
      "  ✓ attribute_based/54_kasparov_kramnik_1993_2004: 2 rows, 13844 tokens, 208.34s\n",
      "  Fetching row 16/40...\n",
      "  ✓ range_based/54_kasparov_kramnik_1993_2004: 1 rows, 12186 tokens, 217.24s\n",
      "  Fetching row 17/40...\n",
      "  Fetching row 18/40...\n",
      "  Fetching row 19/40...\n",
      "  Fetching row 20/40...\n",
      "  Fetching row 21/40...\n",
      "  Fetching row 22/40...\n",
      "  Fetching row 23/40...\n",
      "  Fetching row 24/40...\n",
      "  Fetching row 25/40...\n",
      "  Fetching row 26/40...\n",
      "  Fetching row 27/40...\n",
      "  Fetching row 28/40...\n",
      "  Fetching row 29/40...\n",
      "  Fetching row 30/40...\n",
      "  Fetching row 31/40...\n",
      "  Fetching row 32/40...\n",
      "  Fetching row 33/40...\n",
      "  Fetching row 34/40...\n",
      "  Fetching row 35/40...\n",
      "  Fetching row 36/40...\n",
      "  Fetching row 37/40...\n",
      "  Fetching row 38/40...\n",
      "  Fetching row 39/40...\n",
      "  Fetching row 40/40...\n",
      "  ✓ row_by_row/54_kasparov_kramnik_1993_2004: 2 rows, 33768 tokens, 524.99s\n",
      "\n",
      "======================================================================\n",
      "[24/30] Processing table: 55_decathlon_top50_1999\n",
      "======================================================================\n",
      "Strategies: full_table, row_by_row, attribute_based, classic_pagination, range_based\n",
      "  Fetching full table...\n",
      "  Fetching row 1/48...\n",
      "  Fetching partition 1/12: Venue=Götzis...\n",
      "  Fetching page 1 (offset 0, size 10)...\n",
      "  Fetching range 1/15: Points [7000, 7100)...\n",
      "  Fetching range 2/15: Points [7100, 7200)...\n",
      "  Fetching partition 2/12: Venue=Talence...\n",
      "  Fetching range 3/15: Points [7200, 7300)...\n",
      "  Stopping: Empty result at offset 0\n",
      "  ⚠ classic_pagination/55_decathlon_top50_1999: No rows to save\n",
      "  ✓ full_table/55_decathlon_top50_1999: 1 rows, 827 tokens, 12.44s\n",
      "  Fetching row 2/48...\n",
      "  Fetching range 4/15: Points [7300, 7400)...\n",
      "  Fetching partition 3/12: Venue=Athens...\n",
      "  Fetching range 5/15: Points [7400, 7500)...\n",
      "  Fetching row 3/48...\n",
      "  Fetching partition 4/12: Venue=Desenzano del Garda...\n",
      "  Fetching range 6/15: Points [7500, 7600)...\n",
      "  Fetching range 7/15: Points [7600, 7700)...\n",
      "  Fetching partition 5/12: Venue=Helsinki...\n",
      "  Fetching row 4/48...\n",
      "  Fetching range 8/15: Points [7700, 7800)...\n",
      "  Fetching partition 6/12: Venue=Tallinn...\n",
      "  Fetching row 5/48...\n",
      "  Fetching range 9/15: Points [7800, 7900)...\n",
      "  Fetching partition 7/12: Venue=Kladno...\n",
      "  Fetching row 6/48...\n",
      "  Fetching range 10/15: Points [7900, 8000)...\n",
      "  Fetching partition 8/12: Venue=Birmingham...\n",
      "  Fetching range 11/15: Points [8000, 8100)...\n",
      "  Fetching row 7/48...\n",
      "  Fetching range 12/15: Points [8100, 8200)...\n",
      "  Fetching partition 9/12: Venue=Lappeenranta...\n",
      "  Fetching row 8/48...\n",
      "  Fetching range 13/15: Points [8200, 8300)...\n",
      "  Fetching row 9/48...\n",
      "  Fetching partition 10/12: Venue=Kaiserslautern...\n",
      "  Fetching row 10/48...\n",
      "  Fetching range 14/15: Points [8300, 8400)...\n",
      "  Fetching range 15/15: Points [8400, 8500)...\n",
      "  Fetching partition 11/12: Venue=Bergen...\n",
      "  Fetching row 11/48...\n",
      "  ✓ range_based/55_decathlon_top50_1999: 2 rows, 9952 tokens, 139.49s\n",
      "  Fetching partition 12/12: Venue=Helsinki (FIN)...\n",
      "  Fetching row 12/48...\n",
      "  Fetching row 13/48...\n",
      "  ✓ attribute_based/55_decathlon_top50_1999: 1 rows, 9656 tokens, 163.92s\n",
      "  Fetching row 14/48...\n",
      "  Fetching row 15/48...\n",
      "  Fetching row 16/48...\n",
      "  Fetching row 17/48...\n",
      "  Fetching row 18/48...\n",
      "  Fetching row 19/48...\n",
      "  Fetching row 20/48...\n",
      "  Fetching row 21/48...\n",
      "  Fetching row 22/48...\n",
      "  Fetching row 23/48...\n",
      "  Fetching row 24/48...\n",
      "  Fetching row 25/48...\n",
      "  Fetching row 26/48...\n",
      "  Fetching row 27/48...\n",
      "  Fetching row 28/48...\n",
      "  Fetching row 29/48...\n",
      "  Fetching row 30/48...\n",
      "  Fetching row 31/48...\n",
      "  Fetching row 32/48...\n",
      "  Fetching row 33/48...\n",
      "  Fetching row 34/48...\n",
      "  Fetching row 35/48...\n",
      "  Fetching row 36/48...\n",
      "  Fetching row 37/48...\n",
      "  Fetching row 38/48...\n",
      "  Fetching row 39/48...\n",
      "  Fetching row 40/48...\n",
      "  Fetching row 41/48...\n",
      "  Fetching row 42/48...\n",
      "  Fetching row 43/48...\n",
      "  Fetching row 44/48...\n",
      "  Fetching row 45/48...\n",
      "  Fetching row 46/48...\n",
      "  Fetching row 47/48...\n",
      "  Fetching row 48/48...\n",
      "  ✓ row_by_row/55_decathlon_top50_1999: 19 rows, 40296 tokens, 581.73s\n",
      "\n",
      "======================================================================\n",
      "[25/30] Processing table: 56_minor_planets_152601_152700\n",
      "======================================================================\n",
      "Strategies: full_table, row_by_row, attribute_based, classic_pagination, range_based\n",
      "  Fetching full table...\n",
      "  Fetching row 1/100...\n",
      "  Fetching partition 1/23: Discovery date=September 7, 1999...\n",
      "  Fetching page 1 (offset 0, size 10)...\n",
      "  Fetching range 1/10: Name [152601, 152611)...\n",
      "  Stopping: Empty result at offset 0\n",
      "  ⚠ classic_pagination/56_minor_planets_152601_152700: No rows to save\n",
      "  Fetching row 2/100...\n",
      "  ⚠ full_table/56_minor_planets_152601_152700: No rows to save\n",
      "  Fetching partition 2/23: Discovery date=September 8, 1999...\n",
      "  Fetching range 2/10: Name [152611, 152621)...\n",
      "  Fetching row 3/100...\n",
      "  Fetching partition 3/23: Discovery date=September 9, 1999...\n",
      "  Fetching row 4/100...\n",
      "  Fetching partition 4/23: Discovery date=September 10, 1999...\n",
      "  Fetching range 3/10: Name [152621, 152631)...\n",
      "  Fetching row 5/100...\n",
      "  Fetching partition 5/23: Discovery date=September 11, 1999...\n",
      "  Fetching range 4/10: Name [152631, 152641)...\n",
      "  Fetching row 6/100...\n",
      "  Fetching partition 6/23: Discovery date=September 12, 1999...\n",
      "  Fetching range 5/10: Name [152641, 152651)...\n",
      "  Fetching row 7/100...\n",
      "  Fetching partition 7/23: Discovery date=September 13, 1999...\n",
      "  Fetching row 8/100...\n",
      "  Fetching partition 8/23: Discovery date=September 14, 1999...\n",
      "  Fetching range 6/10: Name [152651, 152661)...\n",
      "  Fetching row 9/100...\n",
      "  Fetching range 7/10: Name [152661, 152671)...\n",
      "  Fetching partition 9/23: Discovery date=September 15, 1999...\n",
      "  Fetching row 10/100...\n",
      "  Fetching range 8/10: Name [152671, 152681)...\n",
      "  Fetching partition 10/23: Discovery date=September 16, 1999...\n",
      "  Fetching row 11/100...\n",
      "  Fetching row 12/100...\n",
      "  Fetching partition 11/23: Discovery date=September 17, 1999...\n",
      "  Fetching row 13/100...\n",
      "  Fetching range 9/10: Name [152681, 152691)...\n",
      "  Fetching range 10/10: Name [152691, 152701)...\n",
      "  Fetching partition 12/23: Discovery date=September 18, 1999...\n",
      "  Fetching row 14/100...\n",
      "  Fetching partition 13/23: Discovery date=September 20, 1999...\n",
      "  Fetching row 15/100...\n",
      "  ⚠ range_based/56_minor_planets_152601_152700: No rows to save\n",
      "  Fetching partition 14/23: Discovery date=September 21, 1999...\n",
      "  Fetching partition 15/23: Discovery date=September 22, 1999...\n",
      "  Fetching row 16/100...\n",
      "  Fetching partition 16/23: Discovery date=September 23, 1999...\n",
      "  Fetching row 17/100...\n",
      "  Fetching partition 17/23: Discovery date=September 24, 1999...\n",
      "  Fetching row 18/100...\n",
      "  Fetching partition 18/23: Discovery date=September 25, 1999...\n",
      "  Fetching row 19/100...\n",
      "  Fetching partition 19/23: Discovery date=September 26, 1999...\n",
      "  Fetching row 20/100...\n",
      "  Fetching partition 20/23: Discovery date=September 27, 1999...\n",
      "  Fetching partition 21/23: Discovery date=September 28, 1999...\n",
      "  Fetching row 21/100...\n",
      "  Fetching row 22/100...\n",
      "  Fetching partition 22/23: Discovery date=September 29, 1999...\n",
      "  Fetching row 23/100...\n",
      "  Fetching partition 23/23: Discovery date=September 30, 1999...\n",
      "  Fetching row 24/100...\n",
      "  ⚠ attribute_based/56_minor_planets_152601_152700: No rows to save\n",
      "  Fetching row 25/100...\n",
      "  Fetching row 26/100...\n",
      "  Fetching row 27/100...\n",
      "  Fetching row 28/100...\n",
      "  Fetching row 29/100...\n",
      "  Fetching row 30/100...\n",
      "  Fetching row 31/100...\n",
      "  Fetching row 32/100...\n",
      "  Fetching row 33/100...\n",
      "  Fetching row 34/100...\n",
      "  Fetching row 35/100...\n",
      "  Fetching row 36/100...\n",
      "  Fetching row 37/100...\n",
      "  Fetching row 38/100...\n",
      "  Fetching row 39/100...\n",
      "  Fetching row 40/100...\n",
      "  Fetching row 41/100...\n",
      "  Fetching row 42/100...\n",
      "  Fetching row 43/100...\n",
      "  Fetching row 44/100...\n",
      "  Fetching row 45/100...\n",
      "  Fetching row 46/100...\n",
      "  Fetching row 47/100...\n",
      "  Fetching row 48/100...\n",
      "  Fetching row 49/100...\n",
      "  Fetching row 50/100...\n",
      "  Fetching row 51/100...\n",
      "  Fetching row 52/100...\n",
      "  Fetching row 53/100...\n",
      "  Fetching row 54/100...\n",
      "  Fetching row 55/100...\n",
      "  Fetching row 56/100...\n",
      "  Fetching row 57/100...\n",
      "  Fetching row 58/100...\n",
      "  Fetching row 59/100...\n",
      "  Fetching row 60/100...\n",
      "  Fetching row 61/100...\n",
      "  Fetching row 62/100...\n",
      "  Fetching row 63/100...\n",
      "  Fetching row 64/100...\n",
      "  Fetching row 65/100...\n",
      "  Fetching row 66/100...\n",
      "  Fetching row 67/100...\n",
      "  Fetching row 68/100...\n",
      "  Fetching row 69/100...\n",
      "  Fetching row 70/100...\n",
      "  Fetching row 71/100...\n",
      "  Fetching row 72/100...\n",
      "  Fetching row 73/100...\n",
      "  Fetching row 74/100...\n",
      "  Fetching row 75/100...\n",
      "  Fetching row 76/100...\n",
      "  Fetching row 77/100...\n",
      "  Fetching row 78/100...\n",
      "  Fetching row 79/100...\n",
      "  Fetching row 80/100...\n",
      "  Fetching row 81/100...\n",
      "  Fetching row 82/100...\n",
      "  Fetching row 83/100...\n",
      "  Fetching row 84/100...\n",
      "  Fetching row 85/100...\n",
      "  Fetching row 86/100...\n",
      "  Fetching row 87/100...\n",
      "  Fetching row 88/100...\n",
      "  Fetching row 89/100...\n",
      "  Fetching row 90/100...\n",
      "  Fetching row 91/100...\n",
      "  Fetching row 92/100...\n",
      "  Fetching row 93/100...\n",
      "  Fetching row 94/100...\n",
      "  Fetching row 95/100...\n",
      "  Fetching row 96/100...\n",
      "  Fetching row 97/100...\n",
      "  Fetching row 98/100...\n",
      "  Fetching row 99/100...\n",
      "  Fetching row 100/100...\n",
      "  ✓ row_by_row/56_minor_planets_152601_152700: 62 rows, 88671 tokens, 1586.23s\n",
      "\n",
      "======================================================================\n",
      "[26/30] Processing table: 59_miss_new_york_usa_delegates_2012\n",
      "======================================================================\n",
      "Strategies: full_table, row_by_row, attribute_based, classic_pagination, range_based\n",
      "  Fetching full table...\n",
      "  Fetching row 1/34...\n",
      "  Fetching partition 1/62: Represents=Albany...\n",
      "  Fetching page 1 (offset 0, size 10)...\n",
      "  Fetching range 1/26: Candidate [A, B)...\n",
      "  Stopping: Empty result at offset 0\n",
      "  ⚠ classic_pagination/59_miss_new_york_usa_delegates_2012: No rows to save\n",
      "  ⚠ full_table/59_miss_new_york_usa_delegates_2012: No rows to save\n",
      "  Fetching range 2/26: Candidate [B, C)...\n",
      "  Fetching row 2/34...\n",
      "  Fetching partition 2/62: Represents=Allegany...\n",
      "  Fetching range 3/26: Candidate [C, D)...\n",
      "  Fetching row 3/34...\n",
      "  Fetching partition 3/62: Represents=Bronx...\n",
      "  Fetching row 4/34...\n",
      "  Fetching range 4/26: Candidate [D, E)...\n",
      "  Fetching row 5/34...\n",
      "  Fetching partition 4/62: Represents=Broome...\n",
      "  Fetching range 5/26: Candidate [E, F)...\n",
      "  Fetching row 6/34...\n",
      "  Fetching partition 5/62: Represents=Cattaraugus...\n",
      "  Fetching row 7/34...\n",
      "  Fetching range 6/26: Candidate [F, G)...\n",
      "  Fetching partition 6/62: Represents=Cayuga...\n",
      "  Fetching row 8/34...\n",
      "  Fetching range 7/26: Candidate [G, H)...\n",
      "  Fetching partition 7/62: Represents=Chautauqua...\n",
      "  Fetching row 9/34...\n",
      "  Fetching range 8/26: Candidate [H, I)...\n",
      "  Fetching partition 8/62: Represents=Chemung...\n",
      "  Fetching row 10/34...\n",
      "  Fetching row 11/34...\n",
      "  Fetching partition 9/62: Represents=Chenango...\n",
      "  Fetching range 9/26: Candidate [I, J)...\n",
      "  Fetching row 12/34...\n",
      "  Fetching partition 10/62: Represents=Clinton...\n",
      "  Fetching row 13/34...\n",
      "  Fetching range 10/26: Candidate [J, K)...\n",
      "  Fetching row 14/34...\n",
      "  Fetching partition 11/62: Represents=Columbia...\n",
      "  Fetching row 15/34...\n",
      "  Fetching row 16/34...\n",
      "  Fetching range 11/26: Candidate [K, L)...\n",
      "  Fetching partition 12/62: Represents=Cortland...\n",
      "  Fetching row 17/34...\n",
      "  Fetching range 12/26: Candidate [L, M)...\n",
      "  Fetching partition 13/62: Represents=Delaware...\n",
      "  Fetching row 18/34...\n",
      "  Fetching row 19/34...\n",
      "  Fetching range 13/26: Candidate [M, N)...\n",
      "  Fetching row 20/34...\n",
      "  Fetching range 14/26: Candidate [N, O)...\n",
      "  Fetching partition 14/62: Represents=Dutchess...\n",
      "  Fetching row 21/34...\n",
      "  Fetching row 22/34...\n",
      "  Fetching row 23/34...\n",
      "  Fetching range 15/26: Candidate [O, P)...\n",
      "  Fetching partition 15/62: Represents=Erie...\n",
      "  Fetching row 24/34...\n",
      "  Fetching row 25/34...\n",
      "  Fetching partition 16/62: Represents=Essex...\n",
      "  Fetching range 16/26: Candidate [P, Q)...\n",
      "  Fetching row 26/34...\n",
      "  Fetching row 27/34...\n",
      "  Fetching range 17/26: Candidate [Q, R)...\n",
      "  Fetching partition 17/62: Represents=Franklin...\n",
      "  Fetching range 18/26: Candidate [R, S)...\n",
      "  Fetching row 28/34...\n",
      "  Fetching partition 18/62: Represents=Fulton...\n",
      "  Fetching row 29/34...\n",
      "  Fetching range 19/26: Candidate [S, T)...\n",
      "  Fetching row 30/34...\n",
      "  Fetching partition 19/62: Represents=Genesee...\n",
      "  Fetching range 20/26: Candidate [T, U)...\n",
      "  Fetching row 31/34...\n",
      "  Fetching partition 20/62: Represents=Greene...\n",
      "  Fetching range 21/26: Candidate [U, V)...\n",
      "  Fetching row 32/34...\n",
      "  Fetching partition 21/62: Represents=Hamilton...\n",
      "  Fetching row 33/34...\n",
      "  Fetching partition 22/62: Represents=Herkimer...\n",
      "  Fetching range 22/26: Candidate [V, W)...\n",
      "  Fetching row 34/34...\n",
      "  Fetching partition 23/62: Represents=Jefferson...\n",
      "  ✓ row_by_row/59_miss_new_york_usa_delegates_2012: 20 rows, 24188 tokens, 301.52s\n",
      "  Fetching range 23/26: Candidate [W, X)...\n",
      "  Fetching partition 24/62: Represents=Kings...\n",
      "  Fetching partition 25/62: Represents=Lewis...\n",
      "  Fetching range 24/26: Candidate [X, Y)...\n",
      "  Fetching range 25/26: Candidate [Y, Z)...\n",
      "  Fetching partition 26/62: Represents=Livingston...\n",
      "  Fetching partition 27/62: Represents=Madison...\n",
      "  Fetching range 26/26: Candidate [Z, [)...\n",
      "  ✓ range_based/59_miss_new_york_usa_delegates_2012: 8 rows, 23039 tokens, 352.05s\n",
      "  Fetching partition 28/62: Represents=Monroe...\n",
      "  Fetching partition 29/62: Represents=Montgomery...\n",
      "  Fetching partition 30/62: Represents=Nassau...\n",
      "  Fetching partition 31/62: Represents=New York City...\n",
      "  Fetching partition 32/62: Represents=Niagara...\n",
      "  Fetching partition 33/62: Represents=Oneida...\n",
      "  Fetching partition 34/62: Represents=Onondaga...\n",
      "  Fetching partition 35/62: Represents=Ontario...\n",
      "  Fetching partition 36/62: Represents=Orange...\n",
      "  Fetching partition 37/62: Represents=Orleans...\n",
      "  Fetching partition 38/62: Represents=Oswego...\n",
      "  Fetching partition 39/62: Represents=Otsego...\n",
      "  Fetching partition 40/62: Represents=Putnam...\n",
      "  Fetching partition 41/62: Represents=Queens...\n",
      "  Fetching partition 42/62: Represents=Rensselaer...\n",
      "  Fetching partition 43/62: Represents=Richmond...\n",
      "  Fetching partition 44/62: Represents=Rockland...\n",
      "  Fetching partition 45/62: Represents=Saratoga...\n",
      "  Fetching partition 46/62: Represents=Schenectady...\n",
      "  Fetching partition 47/62: Represents=Schoharie...\n",
      "  Fetching partition 48/62: Represents=Schuyler...\n",
      "  Fetching partition 49/62: Represents=Seneca...\n",
      "  Fetching partition 50/62: Represents=St. Lawrence...\n",
      "  Fetching partition 51/62: Represents=Steuben...\n",
      "  Fetching partition 52/62: Represents=Suffolk...\n",
      "  Fetching partition 53/62: Represents=Sullivan...\n",
      "  Fetching partition 54/62: Represents=Tioga...\n",
      "  Fetching partition 55/62: Represents=Tompkins...\n",
      "  Fetching partition 56/62: Represents=Ulster...\n",
      "  Fetching partition 57/62: Represents=Warren...\n",
      "  Fetching partition 58/62: Represents=Washington...\n",
      "  Fetching partition 59/62: Represents=Wayne...\n",
      "  Fetching partition 60/62: Represents=Westchester...\n",
      "  Fetching partition 61/62: Represents=Wyoming...\n",
      "  Fetching partition 62/62: Represents=Yates...\n",
      "  ✓ attribute_based/59_miss_new_york_usa_delegates_2012: 5 rows, 51085 tokens, 755.12s\n",
      "\n",
      "======================================================================\n",
      "[27/30] Processing table: 78_bafta_best_actor_leading_role_2000s\n",
      "======================================================================\n",
      "Strategies: full_table, row_by_row, attribute_based, classic_pagination, range_based\n",
      "  Fetching full table...\n",
      "  Fetching row 1/14...\n",
      "  Fetching partition 1/10: Year=2000...\n",
      "  Fetching page 1 (offset 0, size 10)...\n",
      "  Fetching range 1/10: year [2000, 2001)...\n",
      "  Fetching row 2/14...\n",
      "  ⚠ full_table/78_bafta_best_actor_leading_role_2000s: No rows to save\n",
      "  Stopping: Empty result at offset 0\n",
      "  ⚠ classic_pagination/78_bafta_best_actor_leading_role_2000s: No rows to save\n",
      "  Fetching partition 2/10: Year=2001...\n",
      "  Fetching range 2/10: year [2001, 2002)...\n",
      "  Fetching row 3/14...\n",
      "  Fetching row 4/14...\n",
      "  Fetching row 5/14...\n",
      "  Fetching range 3/10: year [2002, 2003)...\n",
      "  Fetching partition 3/10: Year=2002...\n",
      "  Fetching row 6/14...\n",
      "  Fetching row 7/14...\n",
      "  Fetching range 4/10: year [2003, 2004)...\n",
      "  Fetching row 8/14...\n",
      "  Fetching partition 4/10: Year=2003...\n",
      "  Fetching row 9/14...\n",
      "  Fetching row 10/14...\n",
      "  Fetching range 5/10: year [2004, 2005)...\n",
      "  Fetching row 11/14...\n",
      "  Fetching partition 5/10: Year=2004...\n",
      "  Fetching row 12/14...\n",
      "  Fetching row 13/14...\n",
      "  Fetching range 6/10: year [2005, 2006)...\n",
      "  Fetching row 14/14...\n",
      "  ✓ row_by_row/78_bafta_best_actor_leading_role_2000s: 14 rows, 12142 tokens, 153.97s\n",
      "  Fetching range 7/10: year [2006, 2007)...\n",
      "  Fetching partition 6/10: Year=2005...\n",
      "  Fetching range 8/10: year [2007, 2008)...\n",
      "  Fetching partition 7/10: Year=2006...\n",
      "  Fetching range 9/10: year [2008, 2009)...\n",
      "  Fetching partition 8/10: Year=2007...\n",
      "  Fetching partition 9/10: Year=2008...\n",
      "  Fetching range 10/10: year [2009, 2010)...\n",
      "  Fetching partition 10/10: Year=2009...\n",
      "  ✓ range_based/78_bafta_best_actor_leading_role_2000s: 34 rows, 20646 tokens, 290.09s\n",
      "  ✓ attribute_based/78_bafta_best_actor_leading_role_2000s: 31 rows, 21368 tokens, 302.23s\n",
      "\n",
      "======================================================================\n",
      "[28/30] Processing table: 7_anaheim_ducks_draft_picks_1998_2013\n",
      "======================================================================\n",
      "Strategies: full_table, row_by_row, attribute_based, classic_pagination, range_based\n",
      "  Fetching full table...\n",
      "  Fetching row 1/30...\n",
      "  Fetching partition 1/16: Draft=1998...\n",
      "  Fetching page 1 (offset 0, size 10)...\n",
      "  Fetching range 1/16: Draft [1998, 1999)...\n",
      "  Fetching row 2/30...\n",
      "  Stopping: Empty result at offset 0\n",
      "  ⚠ classic_pagination/7_anaheim_ducks_draft_picks_1998_2013: No rows to save\n",
      "  Fetching range 2/16: Draft [1999, 2000)...\n",
      "  Fetching partition 2/16: Draft=1999...\n",
      "  Fetching row 3/30...\n",
      "  Fetching row 4/30...\n",
      "  Fetching partition 3/16: Draft=2000...\n",
      "  Fetching range 3/16: Draft [2000, 2001)...\n",
      "  ✓ full_table/7_anaheim_ducks_draft_picks_1998_2013: 9 rows, 4017 tokens, 44.11s\n",
      "  Fetching partition 4/16: Draft=2001...\n",
      "  Fetching row 5/30...\n",
      "  Fetching range 4/16: Draft [2001, 2002)...\n",
      "  Fetching row 6/30...\n",
      "  Fetching partition 5/16: Draft=2002...\n",
      "  Fetching range 5/16: Draft [2002, 2003)...\n",
      "  Fetching row 7/30...\n",
      "  Fetching partition 6/16: Draft=2003...\n",
      "  Fetching range 6/16: Draft [2003, 2004)...\n",
      "  Fetching row 8/30...\n",
      "  Fetching range 7/16: Draft [2004, 2005)...\n",
      "  Fetching row 9/30...\n",
      "  Fetching partition 7/16: Draft=2004...\n",
      "  Fetching row 10/30...\n",
      "  Fetching range 8/16: Draft [2005, 2006)...\n",
      "  Fetching partition 8/16: Draft=2005...\n",
      "  Fetching row 11/30...\n",
      "  Fetching range 9/16: Draft [2006, 2007)...\n",
      "  Fetching row 12/30...\n",
      "  Fetching row 13/30...\n",
      "  Fetching partition 9/16: Draft=2006...\n",
      "  Fetching range 10/16: Draft [2007, 2008)...\n",
      "  Fetching row 14/30...\n",
      "  Fetching partition 10/16: Draft=2007...\n",
      "  Fetching range 11/16: Draft [2008, 2009)...\n",
      "  Fetching partition 11/16: Draft=2008...\n",
      "  Fetching row 15/30...\n",
      "  Fetching partition 12/16: Draft=2009...\n",
      "  Fetching range 12/16: Draft [2009, 2010)...\n",
      "  Fetching row 16/30...\n",
      "  Fetching partition 13/16: Draft=2010...\n",
      "  Fetching range 13/16: Draft [2010, 2011)...\n",
      "  Fetching row 17/30...\n",
      "  Fetching partition 14/16: Draft=2011...\n",
      "  Fetching range 14/16: Draft [2011, 2012)...\n",
      "  Fetching row 18/30...\n",
      "  Fetching partition 15/16: Draft=2012...\n",
      "  Fetching row 19/30...\n",
      "  Fetching range 15/16: Draft [2012, 2013)...\n",
      "  Fetching row 20/30...\n",
      "  Fetching partition 16/16: Draft=2013...\n",
      "  ✓ attribute_based/7_anaheim_ducks_draft_picks_1998_2013: 6 rows, 23632 tokens, 357.78s\n",
      "  Fetching row 21/30...\n",
      "  Fetching range 16/16: Draft [2013, 2014)...\n",
      "  Fetching row 22/30...\n",
      "  Fetching row 23/30...\n",
      "  ✓ range_based/7_anaheim_ducks_draft_picks_1998_2013: 3 rows, 25976 tokens, 396.69s\n",
      "  Fetching row 24/30...\n",
      "  Fetching row 25/30...\n",
      "  Fetching row 26/30...\n",
      "  Fetching row 27/30...\n",
      "  Fetching row 28/30...\n",
      "  Fetching row 29/30...\n",
      "  Fetching row 30/30...\n",
      "  ✓ row_by_row/7_anaheim_ducks_draft_picks_1998_2013: 23 rows, 37457 tokens, 528.89s\n",
      "\n",
      "======================================================================\n",
      "[29/30] Processing table: 8_south_african_class_15f_4_8_2\n",
      "======================================================================\n",
      "Strategies: full_table, row_by_row, attribute_based, classic_pagination, range_based\n",
      "  Fetching full table...\n",
      "  Fetching row 1/200...\n",
      "  Fetching partition 1/8: Year=1938...\n",
      "  Fetching page 1 (offset 0, size 10)...\n",
      "  Fetching range 1/11: SAR No. [2900, 3000)...\n",
      "  ⚠ full_table/8_south_african_class_15f_4_8_2: No rows to save\n",
      "  Fetching partition 2/8: Year=1939...\n",
      "  Fetching row 2/200...\n",
      "  Stopping: Empty result at offset 0\n",
      "  ⚠ classic_pagination/8_south_african_class_15f_4_8_2: No rows to save\n",
      "  Fetching range 2/11: SAR No. [3000, 3100)...\n",
      "  Fetching partition 3/8: Year=1940...\n",
      "  Fetching row 3/200...\n",
      "  Fetching range 3/11: SAR No. [3100, 3200)...\n",
      "  Fetching partition 4/8: Year=1941...\n",
      "  Fetching row 4/200...\n",
      "  Fetching range 4/11: SAR No. [3200, 3300)...\n",
      "  Fetching partition 5/8: Year=1942...\n",
      "  Fetching row 5/200...\n",
      "  Fetching range 5/11: SAR No. [3300, 3400)...\n",
      "  Fetching partition 6/8: Year=1943...\n",
      "  Fetching row 6/200...\n",
      "  Fetching partition 7/8: Year=1945...\n",
      "  Fetching range 6/11: SAR No. [3400, 3500)...\n",
      "  Fetching row 7/200...\n",
      "  Fetching range 7/11: SAR No. [3500, 3600)...\n",
      "  Fetching partition 8/8: Year=1946...\n",
      "  Fetching row 8/200...\n",
      "  Fetching row 9/200...\n",
      "  Fetching range 8/11: SAR No. [3600, 3700)...\n",
      "  ✓ attribute_based/8_south_african_class_15f_4_8_2: 1 rows, 7099 tokens, 131.01s\n",
      "  Fetching row 10/200...\n",
      "  Fetching row 11/200...\n",
      "  Fetching range 9/11: SAR No. [3700, 3800)...\n",
      "  Fetching row 12/200...\n",
      "  Fetching range 10/11: SAR No. [3800, 3900)...\n",
      "  Fetching row 13/200...\n",
      "  Fetching range 11/11: SAR No. [3900, 4000)...\n",
      "  Fetching row 14/200...\n",
      "  ✓ range_based/8_south_african_class_15f_4_8_2: 2 rows, 11142 tokens, 209.51s\n",
      "  Fetching row 15/200...\n",
      "  Fetching row 16/200...\n",
      "  Fetching row 17/200...\n",
      "  Fetching row 18/200...\n",
      "  Fetching row 19/200...\n",
      "  Fetching row 20/200...\n",
      "  Fetching row 21/200...\n",
      "  Fetching row 22/200...\n",
      "  Fetching row 23/200...\n",
      "  Fetching row 24/200...\n",
      "  Fetching row 25/200...\n",
      "  Fetching row 26/200...\n",
      "  Fetching row 27/200...\n",
      "  Fetching row 28/200...\n",
      "  Fetching row 29/200...\n",
      "  Fetching row 30/200...\n",
      "  Fetching row 31/200...\n",
      "  Fetching row 32/200...\n",
      "  Fetching row 33/200...\n",
      "  Fetching row 34/200...\n",
      "  Fetching row 35/200...\n",
      "  Fetching row 36/200...\n",
      "  Fetching row 37/200...\n",
      "  Fetching row 38/200...\n",
      "  Fetching row 39/200...\n",
      "  Fetching row 40/200...\n",
      "  Fetching row 41/200...\n",
      "  Fetching row 42/200...\n",
      "  Fetching row 43/200...\n",
      "  Fetching row 44/200...\n",
      "  Fetching row 45/200...\n",
      "  Fetching row 46/200...\n",
      "  Fetching row 47/200...\n",
      "  Fetching row 48/200...\n",
      "  Fetching row 49/200...\n",
      "  Fetching row 50/200...\n",
      "  Fetching row 51/200...\n",
      "  Fetching row 52/200...\n",
      "  Fetching row 53/200...\n",
      "  Fetching row 54/200...\n",
      "  Fetching row 55/200...\n",
      "  Fetching row 56/200...\n",
      "  Fetching row 57/200...\n",
      "  Fetching row 58/200...\n",
      "  Fetching row 59/200...\n",
      "  Fetching row 60/200...\n",
      "  Fetching row 61/200...\n",
      "  Fetching row 62/200...\n",
      "  Fetching row 63/200...\n",
      "  Fetching row 64/200...\n",
      "  Fetching row 65/200...\n",
      "  Fetching row 66/200...\n",
      "  Fetching row 67/200...\n",
      "  Fetching row 68/200...\n",
      "  Fetching row 69/200...\n",
      "  Fetching row 70/200...\n",
      "  Fetching row 71/200...\n",
      "  Fetching row 72/200...\n",
      "  Fetching row 73/200...\n",
      "  Fetching row 74/200...\n",
      "  Fetching row 75/200...\n",
      "  Fetching row 76/200...\n",
      "  Fetching row 77/200...\n",
      "  Fetching row 78/200...\n",
      "  Fetching row 79/200...\n",
      "  Fetching row 80/200...\n",
      "  Fetching row 81/200...\n",
      "  Fetching row 82/200...\n",
      "  Fetching row 83/200...\n",
      "  Fetching row 84/200...\n",
      "  Fetching row 85/200...\n",
      "  Fetching row 86/200...\n",
      "  Fetching row 87/200...\n",
      "  Fetching row 88/200...\n",
      "  Fetching row 89/200...\n",
      "  Fetching row 90/200...\n",
      "  Fetching row 91/200...\n",
      "  Fetching row 92/200...\n",
      "  Fetching row 93/200...\n",
      "  Fetching row 94/200...\n",
      "  Fetching row 95/200...\n",
      "  Fetching row 96/200...\n",
      "  Fetching row 97/200...\n",
      "  Fetching row 98/200...\n",
      "  Fetching row 99/200...\n",
      "  Fetching row 100/200...\n",
      "  Fetching row 101/200...\n",
      "  Fetching row 102/200...\n",
      "  Fetching row 103/200...\n",
      "  Fetching row 104/200...\n",
      "  Fetching row 105/200...\n",
      "  Fetching row 106/200...\n",
      "  Fetching row 107/200...\n",
      "  Fetching row 108/200...\n",
      "  Fetching row 109/200...\n",
      "  Fetching row 110/200...\n",
      "  Fetching row 111/200...\n",
      "  Fetching row 112/200...\n",
      "  Fetching row 113/200...\n",
      "  Fetching row 114/200...\n",
      "  Fetching row 115/200...\n",
      "  Fetching row 116/200...\n",
      "  Fetching row 117/200...\n",
      "  Fetching row 118/200...\n",
      "  Fetching row 119/200...\n",
      "  Fetching row 120/200...\n",
      "  Fetching row 121/200...\n",
      "  Fetching row 122/200...\n",
      "  Fetching row 123/200...\n",
      "  Fetching row 124/200...\n",
      "  Fetching row 125/200...\n",
      "  Fetching row 126/200...\n",
      "  Fetching row 127/200...\n",
      "  Fetching row 128/200...\n",
      "  Fetching row 129/200...\n",
      "  Fetching row 130/200...\n",
      "  Fetching row 131/200...\n",
      "  Fetching row 132/200...\n",
      "  Fetching row 133/200...\n",
      "  Fetching row 134/200...\n",
      "  Fetching row 135/200...\n",
      "  Fetching row 136/200...\n",
      "  Fetching row 137/200...\n",
      "  Fetching row 138/200...\n",
      "  Fetching row 139/200...\n",
      "  Fetching row 140/200...\n",
      "  Fetching row 141/200...\n",
      "  Fetching row 142/200...\n",
      "  Fetching row 143/200...\n",
      "  Fetching row 144/200...\n",
      "  Fetching row 145/200...\n",
      "  Fetching row 146/200...\n",
      "  Fetching row 147/200...\n",
      "  Fetching row 148/200...\n",
      "  Fetching row 149/200...\n",
      "  Fetching row 150/200...\n",
      "  Fetching row 151/200...\n",
      "  Fetching row 152/200...\n",
      "  Fetching row 153/200...\n",
      "  Fetching row 154/200...\n",
      "  Fetching row 155/200...\n",
      "  Fetching row 156/200...\n",
      "  Fetching row 157/200...\n",
      "  Fetching row 158/200...\n",
      "  Fetching row 159/200...\n",
      "  Fetching row 160/200...\n",
      "  Fetching row 161/200...\n",
      "  Fetching row 162/200...\n",
      "  Fetching row 163/200...\n",
      "  Fetching row 164/200...\n",
      "  Fetching row 165/200...\n",
      "  Fetching row 166/200...\n",
      "  Fetching row 167/200...\n",
      "  Fetching row 168/200...\n",
      "  Fetching row 169/200...\n",
      "  Fetching row 170/200...\n",
      "  Fetching row 171/200...\n",
      "  Fetching row 172/200...\n",
      "  Fetching row 173/200...\n",
      "  Fetching row 174/200...\n",
      "  Fetching row 175/200...\n",
      "  Fetching row 176/200...\n",
      "  Fetching row 177/200...\n",
      "  Fetching row 178/200...\n",
      "  Fetching row 179/200...\n",
      "  Fetching row 180/200...\n",
      "  Fetching row 181/200...\n",
      "  Fetching row 182/200...\n",
      "  Fetching row 183/200...\n",
      "  Fetching row 184/200...\n",
      "  Fetching row 185/200...\n",
      "  Fetching row 186/200...\n",
      "  Fetching row 187/200...\n",
      "  Fetching row 188/200...\n",
      "  Fetching row 189/200...\n",
      "  Fetching row 190/200...\n",
      "  Fetching row 191/200...\n",
      "  Fetching row 192/200...\n",
      "  Fetching row 193/200...\n",
      "  Fetching row 194/200...\n",
      "  Fetching row 195/200...\n",
      "  Fetching row 196/200...\n",
      "  Fetching row 197/200...\n",
      "  Fetching row 198/200...\n",
      "  Fetching row 199/200...\n",
      "  Fetching row 200/200...\n",
      "  ✓ row_by_row/8_south_african_class_15f_4_8_2: 116 rows, 172482 tokens, 3275.54s\n",
      "\n",
      "======================================================================\n",
      "[30/30] Processing table: 9_tour_de_france_2009\n",
      "======================================================================\n",
      "Strategies: full_table, row_by_row, attribute_based, classic_pagination, range_based\n",
      "  Fetching full table...\n",
      "  Fetching row 1/110...\n",
      "  Fetching partition 1/21: Team=AG2R La Mondiale...\n",
      "  Fetching page 1 (offset 0, size 10)...\n",
      "  Fetching range 1/5: Age [20, 25)...\n",
      "  Fetching row 2/110...\n",
      "  Fetching row 3/110...\n",
      "  Fetching range 2/5: Age [25, 30)...\n",
      "  Fetching partition 2/21: Team=Astana...\n",
      "  Fetching row 4/110...\n",
      "  ⚠ full_table/9_tour_de_france_2009: No rows to save\n",
      "  Fetching partition 3/21: Team=Bbox Bouygues Telecom...\n",
      "  Fetching page 2 (offset 10, size 10)...\n",
      "  Fetching row 5/110...\n",
      "  Fetching range 3/5: Age [30, 35)...\n",
      "  Fetching row 6/110...\n",
      "  Stopping: Empty result at offset 10\n",
      "  ✓ classic_pagination/9_tour_de_france_2009: 1 rows, 2493 tokens, 59.03s\n",
      "  Fetching row 7/110...\n",
      "  Fetching partition 4/21: Team=Caisse d'Epargne...\n",
      "  Fetching row 8/110...\n",
      "  Fetching range 4/5: Age [35, 40)...\n",
      "  Fetching partition 5/21: Team=Cofidis...\n",
      "  Fetching row 9/110...\n",
      "  Fetching row 10/110...\n",
      "  Fetching partition 6/21: Team=Columbia-High Road...\n",
      "  Fetching row 11/110...\n",
      "  Fetching range 5/5: Age [40, 45)...\n",
      "  Fetching row 12/110...\n",
      "  Fetching row 13/110...\n",
      "  Fetching partition 7/21: Team=Credit Agricole...\n",
      "  ✓ range_based/9_tour_de_france_2009: 3 rows, 8551 tokens, 139.67s\n",
      "  Fetching partition 8/21: Team=Euskaltel-Euskadi...\n",
      "  Fetching row 14/110...\n",
      "  Fetching row 15/110...\n",
      "  Fetching partition 9/21: Team=Française des Jeux...\n",
      "  Fetching row 16/110...\n",
      "  Fetching partition 10/21: Team=Garmin-Slipstream...\n",
      "  Fetching row 17/110...\n",
      "  Fetching row 18/110...\n",
      "  Fetching partition 11/21: Team=Lampre-NGC...\n",
      "  Fetching row 19/110...\n",
      "  Fetching row 20/110...\n",
      "  Fetching partition 12/21: Team=Liquigas...\n",
      "  Fetching row 21/110...\n",
      "  Fetching partition 13/21: Team=Milram...\n",
      "  Fetching row 22/110...\n",
      "  Fetching row 23/110...\n",
      "  Fetching partition 14/21: Team=Omega Pharma-Lotto...\n",
      "  Fetching row 24/110...\n",
      "  Fetching partition 15/21: Team=Quick Step...\n",
      "  Fetching row 25/110...\n",
      "  Fetching row 26/110...\n",
      "  Fetching partition 16/21: Team=Rabobank...\n",
      "  Fetching row 27/110...\n",
      "  Fetching row 28/110...\n",
      "  Fetching partition 17/21: Team=Silence-Lotto...\n",
      "  Fetching partition 18/21: Team=Skil-Shimano...\n",
      "  Fetching row 29/110...\n",
      "  Fetching row 30/110...\n",
      "  Fetching row 31/110...\n",
      "  Fetching partition 19/21: Team=Team Saxo Bank...\n",
      "  Fetching row 32/110...\n",
      "  Fetching row 33/110...\n",
      "  Fetching row 34/110...\n",
      "  Fetching partition 20/21: Team=Team Katusha...\n",
      "  Fetching row 35/110...\n",
      "  Fetching partition 21/21: Team=Team Columbia-HTC...\n",
      "  Fetching row 36/110...\n",
      "  Fetching row 37/110...\n",
      "  ✓ attribute_based/9_tour_de_france_2009: 5 rows, 31431 tokens, 473.90s\n",
      "  Fetching row 38/110...\n",
      "  Fetching row 39/110...\n",
      "  Fetching row 40/110...\n",
      "  Fetching row 41/110...\n",
      "  Fetching row 42/110...\n",
      "  Fetching row 43/110...\n",
      "  Fetching row 44/110...\n",
      "  Fetching row 45/110...\n",
      "  Fetching row 46/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 47/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 48/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 49/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 50/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 51/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 52/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 53/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 54/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 55/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 56/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 57/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 58/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 59/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 60/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 61/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 62/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 63/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 64/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 65/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 66/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 67/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 68/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 69/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 70/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 71/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 72/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 73/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 74/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 75/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 76/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 77/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 78/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 79/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 80/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 81/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 82/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 83/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 84/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 85/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 86/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 87/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 88/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 89/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 90/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 91/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 92/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 93/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 94/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 95/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 96/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 97/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 98/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 99/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 100/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 101/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 102/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 103/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 104/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 105/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 106/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 107/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 108/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 109/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Fetching row 110/110...\n",
      "  Retry 1/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 2/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  Retry 3/3 after error: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}\n",
      "  ✓ row_by_row/9_tour_de_france_2009: 43 rows, 41934 tokens, 614.15s\n",
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "Processed: 150 strategy-table combinations\n",
      "Successful: 150\n",
      "Failed: 0\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "output_dir = OUTPUT_ROOT / timestamp\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "\n",
    "# Create subdirectories for each strategy\n",
    "for strategy_name in STRATEGY_FUNCTIONS.keys():\n",
    "    strategy_dir = output_dir / strategy_name\n",
    "    strategy_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Group strategies by table_id for parallel execution\n",
    "from collections import defaultdict\n",
    "tables_with_strategies = defaultdict(list)\n",
    "for strategy_name, plan in strategies_to_process:\n",
    "    table_id = plan['table_id']\n",
    "    tables_with_strategies[table_id].append((strategy_name, plan))\n",
    "\n",
    "print(f\"\\nGrouped into {len(tables_with_strategies)} tables with strategies\")\n",
    "\n",
    "# Process each table with parallel strategy execution\n",
    "results_summary = []\n",
    "\n",
    "\n",
    "def process_strategy(strategy_name: str, plan: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Process a single strategy-table combination.\"\"\"\n",
    "    table_id = plan['table_id']\n",
    "    table_name = plan['table_name']\n",
    "    \n",
    "    try:\n",
    "        # Execute fetching strategy\n",
    "        fetch_func = STRATEGY_FUNCTIONS[strategy_name]\n",
    "        fetch_result = fetch_func(plan)\n",
    "        \n",
    "        pages = fetch_result['pages']\n",
    "        all_rows = fetch_result['all_rows']\n",
    "        \n",
    "        # Calculate aggregated metrics\n",
    "        total_pages = len(pages)\n",
    "        successful_pages = sum(1 for p in pages if p.get('parse_success', False))\n",
    "        failed_pages = total_pages - successful_pages\n",
    "        \n",
    "        total_latency = sum(p.get('latency', 0) for p in pages)\n",
    "        avg_latency = total_latency / total_pages if total_pages > 0 else 0\n",
    "        \n",
    "        total_tokens = sum(p.get('total_tokens', 0) for p in pages)\n",
    "        total_llm_calls = sum(1 + p.get('retry_count', 0) for p in pages)\n",
    "        \n",
    "        total_rows_fetched = len(all_rows)\n",
    "        \n",
    "        # Check for duplicate rows\n",
    "        unique_rows = set()\n",
    "        duplicate_count = 0\n",
    "        for row in all_rows:\n",
    "            row_key = tuple(sorted(row.items()))\n",
    "            if row_key in unique_rows:\n",
    "                duplicate_count += 1\n",
    "            unique_rows.add(row_key)\n",
    "        \n",
    "        # Check column consistency\n",
    "        if all_rows:\n",
    "            column_sets = [set(row.keys()) for row in all_rows]\n",
    "            columns_consistent = all(cs == column_sets[0] for cs in column_sets)\n",
    "        else:\n",
    "            columns_consistent = True\n",
    "        \n",
    "        error_rate = failed_pages / total_pages if total_pages > 0 else 0\n",
    "        \n",
    "        # Build execution summary\n",
    "        execution_summary = {\n",
    "            'table_id': table_id,\n",
    "            'table_name': table_name,\n",
    "            'strategy': strategy_name,\n",
    "            'metadata': plan['metadata'],\n",
    "            'pagination_config': plan['pagination_config'],\n",
    "            'execution_metadata': {\n",
    "                'timestamp': timestamp,\n",
    "                'total_pages': total_pages,\n",
    "                'successful_pages': successful_pages,\n",
    "                'failed_pages': failed_pages,\n",
    "                'total_llm_calls': total_llm_calls,\n",
    "                'total_latency': round(total_latency, 3),\n",
    "                'avg_latency': round(avg_latency, 3),\n",
    "                'total_tokens': total_tokens,\n",
    "                'total_rows_fetched': total_rows_fetched,\n",
    "                'unique_rows': len(unique_rows),\n",
    "                'duplicate_rows': duplicate_count,\n",
    "                'columns_consistent': columns_consistent,\n",
    "                'error_rate': round(error_rate, 4)\n",
    "            },\n",
    "            'pages': pages\n",
    "        }\n",
    "        \n",
    "        # Save JSON log\n",
    "        json_path = output_dir / strategy_name / f\"{table_id}.json\"\n",
    "        with open(json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(execution_summary, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        # Save CSV if we have data (matching B004 approach: normalize columns to match reference)\n",
    "        if all_rows:\n",
    "            try:\n",
    "                # Load reference table to get proper column names\n",
    "                ref_csv_path = LATEST_DATA_DIR / f\"{table_id}.csv\"\n",
    "                df_ref = pd.read_csv(ref_csv_path)\n",
    "                \n",
    "                # Create dataframe from fetched rows\n",
    "                df = pd.DataFrame(all_rows)\n",
    "                \n",
    "                # Normalize fetched column names\n",
    "                df.columns = [normalize_field(col) for col in df.columns]\n",
    "                \n",
    "                # Normalize reference column names to create mapping\n",
    "                norm_ref_cols = [normalize_field(col) for col in df_ref.columns]\n",
    "                \n",
    "                # Ensure fetched df has same columns as reference (reorder and add missing)\n",
    "                missing_cols = [col for col in norm_ref_cols if col not in df.columns]\n",
    "                for col in missing_cols:\n",
    "                    df[col] = None  # Add missing columns with None\n",
    "                \n",
    "                # Reorder to match reference\n",
    "                df = df[norm_ref_cols]\n",
    "                \n",
    "                # Restore original column names from reference\n",
    "                df.columns = df_ref.columns\n",
    "                \n",
    "                # Drop duplicates based on key columns\n",
    "                key_columns = plan['metadata']['key_columns']\n",
    "                if key_columns:\n",
    "                    df = df.drop_duplicates(subset=key_columns)\n",
    "                \n",
    "                csv_path = output_dir / strategy_name / f\"{table_id}.csv\"\n",
    "                df.to_csv(csv_path, index=False, encoding='utf-8')\n",
    "                print(f\"  ✓ {strategy_name}/{table_id}: {len(df)} rows, {total_tokens} tokens, {total_latency:.2f}s\")\n",
    "            except Exception as e:\n",
    "                print(f\"  ✗ {strategy_name}/{table_id}: CSV save failed: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "        else:\n",
    "            print(f\"  ⚠ {strategy_name}/{table_id}: No rows to save\")\n",
    "        \n",
    "        return {\n",
    "            'strategy': strategy_name,\n",
    "            'table_id': table_id,\n",
    "            'success': True,\n",
    "            **execution_summary['execution_metadata']\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ {strategy_name}/{table_id}: Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return {\n",
    "            'strategy': strategy_name,\n",
    "            'table_id': table_id,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "\n",
    "# Process each table with parallel strategies\n",
    "for table_num, (table_id, strategies) in enumerate(tables_with_strategies.items(), 1):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"[{table_num}/{len(tables_with_strategies)}] Processing table: {table_id}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Strategies: {', '.join(s for s, _ in strategies)}\")\n",
    "    \n",
    "    if PARALLEL_STRATEGIES:\n",
    "        # Execute strategies in parallel\n",
    "        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "            futures = {\n",
    "                executor.submit(process_strategy, strategy_name, plan): (strategy_name, plan['table_id'])\n",
    "                for strategy_name, plan in strategies\n",
    "            }\n",
    "            \n",
    "            for future in as_completed(futures):\n",
    "                result = future.result()\n",
    "                results_summary.append(result)\n",
    "    else:\n",
    "        # Sequential execution (for debugging)\n",
    "        for strategy_name, plan in strategies:\n",
    "            print(f\"\\n  {strategy_name.upper()}\")\n",
    "            result = process_strategy(strategy_name, plan)\n",
    "            results_summary.append(result)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Processed: {len(results_summary)} strategy-table combinations\")\n",
    "print(f\"Successful: {sum(1 for r in results_summary if r['success'])}\")\n",
    "print(f\"Failed: {sum(1 for r in results_summary if not r['success'])}\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feb5616",
   "metadata": {},
   "source": [
    "## Save Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9c0ef45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EXECUTION SUMMARY\n",
      "======================================================================\n",
      "Total execution time: 529.39 minutes\n",
      "Tables processed: 30\n",
      "Strategy combinations: 150 successful, 0 failed\n",
      "Total pages fetched: 3168\n",
      "Total LLM calls: 3298\n",
      "Total tokens used: 3,079,505\n",
      "Total rows fetched: 1558\n",
      "Avg latency per page: 16.70s\n",
      "Avg tokens per call: 933.7\n",
      "\n",
      "Final summary saved to processing/2_fetching/20251005_124736/_summary.json\n",
      "All results saved to processing/2_fetching/20251005_124736\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Calculate aggregate statistics across all strategies\n",
    "execution_end_time = datetime.now()\n",
    "# Parse timestamp: format is YYYYMMDD_HHMMSS\n",
    "execution_start_time = datetime.strptime(timestamp, '%Y%m%d_%H%M%S')\n",
    "\n",
    "total_execution_time = (execution_end_time - execution_start_time).total_seconds()\n",
    "\n",
    "# Aggregate metrics\n",
    "total_tables_processed = len(set(r['table_id'] for r in results_summary if r['success']))\n",
    "total_strategies_run = len([r for r in results_summary if r['success']])\n",
    "total_failures = len([r for r in results_summary if not r['success']])\n",
    "\n",
    "successful_results = [r for r in results_summary if r.get('success', False)]\n",
    "\n",
    "total_pages_fetched = sum(r.get('total_pages', 0) for r in successful_results)\n",
    "total_llm_calls_made = sum(r.get('total_llm_calls', 0) for r in successful_results)\n",
    "total_tokens_used = sum(r.get('total_tokens', 0) for r in successful_results)\n",
    "total_latency_seconds = sum(r.get('total_latency', 0) for r in successful_results)\n",
    "total_rows_fetched = sum(r.get('total_rows_fetched', 0) for r in successful_results)\n",
    "\n",
    "# Calculate averages\n",
    "avg_latency_per_page = total_latency_seconds / total_pages_fetched if total_pages_fetched > 0 else 0\n",
    "avg_tokens_per_call = total_tokens_used / total_llm_calls_made if total_llm_calls_made > 0 else 0\n",
    "avg_pages_per_strategy = total_pages_fetched / total_strategies_run if total_strategies_run > 0 else 0\n",
    "\n",
    "# Collect all errors\n",
    "errors_list = [\n",
    "    {\n",
    "        'strategy': r['strategy'],\n",
    "        'table_id': r['table_id'],\n",
    "        'error': r.get('error', 'Unknown error')\n",
    "    }\n",
    "    for r in results_summary if not r.get('success', False)\n",
    "]\n",
    "\n",
    "# Strategy breakdown\n",
    "strategy_breakdown = {}\n",
    "for strategy in STRATEGY_FUNCTIONS.keys():\n",
    "    strategy_results = [r for r in successful_results if r.get('strategy') == strategy]\n",
    "    if strategy_results:\n",
    "        strategy_breakdown[strategy] = {\n",
    "            'tables_processed': len(strategy_results),\n",
    "            'total_pages': sum(r.get('total_pages', 0) for r in strategy_results),\n",
    "            'total_tokens': sum(r.get('total_tokens', 0) for r in strategy_results),\n",
    "            'total_latency': round(sum(r.get('total_latency', 0) for r in strategy_results), 3),\n",
    "            'avg_latency': round(sum(r.get('avg_latency', 0) for r in strategy_results) / len(strategy_results), 3),\n",
    "            'total_rows': sum(r.get('total_rows_fetched', 0) for r in strategy_results),\n",
    "            'error_rate': round(sum(r.get('error_rate', 0) for r in strategy_results) / len(strategy_results), 4)\n",
    "        }\n",
    "\n",
    "# Build comprehensive summary\n",
    "summary = {\n",
    "    'timestamp': timestamp,\n",
    "    'execution_time': {\n",
    "        'start': timestamp,\n",
    "        'end': execution_end_time.strftime('%Y%m%d_%H%M%S'),\n",
    "        'total_seconds': round(total_execution_time, 2),\n",
    "        'total_minutes': round(total_execution_time / 60, 2)\n",
    "    },\n",
    "    'configuration': {\n",
    "        'strategy_directory': str(LATEST_STRATEGY_DIR),\n",
    "        'max_tables': MAX_TABLES,\n",
    "        'max_pages': MAX_PAGES,\n",
    "        'max_retries': MAX_RETRIES,\n",
    "        'max_pagination_pages': MAX_PAGINATION_PAGES,\n",
    "        'model': MODEL\n",
    "    },\n",
    "    'aggregate_metrics': {\n",
    "        'total_tables_processed': total_tables_processed,\n",
    "        'total_strategy_table_combinations': total_strategies_run,\n",
    "        'total_failures': total_failures,\n",
    "        'success_rate': round(total_strategies_run / (total_strategies_run + total_failures), 4) if (total_strategies_run + total_failures) > 0 else 0,\n",
    "        'total_pages_fetched': total_pages_fetched,\n",
    "        'total_llm_calls': total_llm_calls_made,\n",
    "        'total_tokens_used': total_tokens_used,\n",
    "        'total_latency_seconds': round(total_latency_seconds, 2),\n",
    "        'total_rows_fetched': total_rows_fetched,\n",
    "        'avg_latency_per_page': round(avg_latency_per_page, 3),\n",
    "        'avg_tokens_per_call': round(avg_tokens_per_call, 1),\n",
    "        'avg_pages_per_strategy': round(avg_pages_per_strategy, 1)\n",
    "    },\n",
    "    'strategy_breakdown': strategy_breakdown,\n",
    "    'errors': errors_list,\n",
    "    'detailed_results': results_summary\n",
    "}\n",
    "\n",
    "summary_file = output_dir / '_summary.json'\n",
    "with open(summary_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"EXECUTION SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Total execution time: {summary['execution_time']['total_minutes']:.2f} minutes\")\n",
    "print(f\"Tables processed: {total_tables_processed}\")\n",
    "print(f\"Strategy combinations: {total_strategies_run} successful, {total_failures} failed\")\n",
    "print(f\"Total pages fetched: {total_pages_fetched}\")\n",
    "print(f\"Total LLM calls: {total_llm_calls_made}\")\n",
    "print(f\"Total tokens used: {total_tokens_used:,}\")\n",
    "print(f\"Total rows fetched: {total_rows_fetched}\")\n",
    "print(f\"Avg latency per page: {avg_latency_per_page:.2f}s\")\n",
    "print(f\"Avg tokens per call: {avg_tokens_per_call:.1f}\")\n",
    "if errors_list:\n",
    "    print(f\"\\n⚠ {len(errors_list)} errors occurred (see _summary.json for details)\")\n",
    "print(f\"\\nFinal summary saved to {summary_file}\")\n",
    "print(f\"All results saved to {output_dir}\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2496207f",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "The fetched data has been saved to `processing/2_fetching/<timestamp>/`.\n",
    "\n",
    "Each strategy subdirectory contains:\n",
    "- **JSON files**: Detailed execution logs with per-page metrics, prompts, responses, and aggregated statistics\n",
    "- **CSV files**: Aggregated table data ready for metrics calculation\n",
    "\n",
    "### Metrics Available:\n",
    "\n",
    "**Per-page metrics:**\n",
    "- latency, tokens (prompt/completion/total), retry_count\n",
    "- parse_success, rows_returned, JSON extraction position\n",
    "- timestamp, raw_response, parsed_data\n",
    "\n",
    "**Per-table-strategy metrics:**\n",
    "- total_pages, successful/failed_pages, total_llm_calls\n",
    "- total/avg latency, total_tokens\n",
    "- total_rows_fetched, unique_rows, duplicate_rows\n",
    "- columns_consistent, error_rate\n",
    "\n",
    "### To calculate accuracy metrics:\n",
    "Use the CSV files with the evaluation logic from `X101_Calculate_Metrics.ipynb` to compute:\n",
    "- Keys F1, Precision, Recall\n",
    "- Non-keys F1, Precision, Recall\n",
    "- Overall F1, Precision, Recall"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
