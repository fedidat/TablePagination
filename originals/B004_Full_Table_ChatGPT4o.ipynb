{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from dateutil import parser as date_parser\n",
    "from unidecode import unidecode\n",
    "\n",
    "import os\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableGenerator_JSON():\n",
    "    TEMPLATE = \"\"\"\n",
    "    List %s - as many as possible to fit into response.\n",
    "    The response will be formatted as JSON shown below.\n",
    "    Each element of the response will contain %d fields: %s.\n",
    "    Do not output any additional text that is not in JSON format.\n",
    "    \n",
    "    RESPONSE FORMAT:\n",
    "    [{\n",
    "        %s\n",
    "    }]\n",
    "    \"\"\"   \n",
    "    \n",
    "    def _norm_field(self, s):\n",
    "        s = s.lower().replace(\" \",\"_\").replace(\"-\",\"_\").replace(\".\", \"\").replace(\",\",\"_\")\\\n",
    "                .replace(\"(\", \"\").replace(\")\", \"\").replace(\":\", \"\").replace('\"','').replace(\"'\",\"\")\\\n",
    "                .replace(\"/\", \"\")\n",
    "        return re.sub('_+', '_', s)\n",
    "        \n",
    "    def generate_prompts(self, query, fields):\n",
    "        system_msg = \"You are a retriever of facts.\"\n",
    "\n",
    "        num_fields = len(fields)\n",
    "        fields_json = []\n",
    "        fields = [self._norm_field(f) for f in fields]\n",
    "        for field in fields:\n",
    "            fields_json.append('\"%s\": \"%s\"' % ('_'.join(field.replace(\"-\", \" \").split()), field))\n",
    "        response_format = ', '.join(fields_json)\n",
    "        user_msg = self.TEMPLATE % (query, num_fields, fields, response_format)\n",
    "        return system_msg, user_msg        \n",
    "    \n",
    "    def parse_llm_response(self, response): \n",
    "        res = []\n",
    "        try:\n",
    "            if not response.startswith(\"[\") and \"[\" in response:\n",
    "                response = response[response.find(\"[\"):]\n",
    "\n",
    "            if not response.endswith(\"]\") and \"]\" in response:\n",
    "                response = response[:response.rfind(\"]\")+1]\n",
    "\n",
    "            if '[' not in response and ']' not in response and '{' in response and '}' in response:\n",
    "                response = '[' + response + ']'    \n",
    "\n",
    "            response_json = json.loads(response)\n",
    "\n",
    "            if isinstance(response_json, dict) and len(response_json.keys()) == 1:\n",
    "                response_json = list(response_json.values())[0]    \n",
    "        except:  \n",
    "            split_response = response.split(\"{\")\n",
    "            response_json = []\n",
    "            for s in split_response[1:]:\n",
    "                split_s = s.split(\"}\")\n",
    "                if len(split_s) > 1:\n",
    "                    content = split_s[0]\n",
    "                    attributes = content.split(\",\")\n",
    "                    elements = {}\n",
    "                    for attr in attributes:\n",
    "                        knv = attr.split(\":\")   \n",
    "                        if len(knv) > 1:\n",
    "                            parsed_k = \"%s\" % knv[0].replace('\"','').strip()\n",
    "                            parsed_v = \"%s\" % knv[1].replace('\"','').strip()\n",
    "                            elements[parsed_k] = parsed_v\n",
    "\n",
    "                    response_json.append(elements)  \n",
    "\n",
    "        df = pd.DataFrame.from_records(response_json) \n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentRunner():\n",
    "    OPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')\n",
    "    client = openai.OpenAI(\n",
    "        api_key=OPENROUTER_API_KEY,\n",
    "        base_url=\"https://openrouter.ai/api/v1\"# Model to use for LLM queries\n",
    "    )\n",
    "    MODEL = 'x-ai/grok-code-fast-1'  # OpenRouter format: provider/model\n",
    "    NOTE = 'full_table'\n",
    "        \n",
    "    def __init__(self, table_generator, metadata_path):\n",
    "        with open(metadata_path, \"rb\") as f:\n",
    "            self.metadata = json.load(f)\n",
    "            \n",
    "        self.table_generator = table_generator\n",
    "        \n",
    "        self.result_folder = \"DATA/%s_%s_%s\" % (self.MODEL.replace('-', '_'), \n",
    "                                                   self.NOTE,\n",
    "                                                   time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "        \n",
    "        print(\"Experiment result folder: %s\" % self.result_folder)\n",
    "        \n",
    "        os.makedirs(self.result_folder)\n",
    "        os.makedirs(\"%s/Tables\" % self.result_folder)\n",
    "        \n",
    "        self.result = {}\n",
    "        \n",
    "    def fetch_data(self, idx):\n",
    "        task = self.metadata[idx]\n",
    "        \n",
    "        task_name = task['name']        \n",
    "        print(\"Fetching data for %s\" % task_name)\n",
    "        \n",
    "        query, columns = task['table_title'], task['columns']            \n",
    "        print(\"Query: \", query) \n",
    "        \n",
    "        system_msg, user_msg = self.table_generator.generate_prompts(query, columns)        \n",
    "\n",
    "        self.result[idx] = {'system_msg': system_msg, 'user_msg': user_msg}\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.MODEL,\n",
    "            messages=[{\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": user_msg}],\n",
    "            temperature=0\n",
    "        )\n",
    "        response = response.choices[0].message.content.strip()\n",
    "\n",
    "        if 'response' in self.result[idx]:\n",
    "            self.result[idx]['response'].append(response)\n",
    "        else:    \n",
    "            self.result[idx]['response'] = [response]\n",
    "\n",
    "        df = self.table_generator.parse_llm_response(response)          \n",
    "        df_ref = pd.read_csv(task['path'])          \n",
    "        df.columns = df_ref.columns\n",
    "        df = df.drop_duplicates(subset=task['keys'])\n",
    "\n",
    "        table_path = \"%s/Tables/%s.csv\" % (self.result_folder, task_name)\n",
    "        self.result[idx]['table_path'] = table_path                \n",
    "        df.to_csv(table_path, index=False)\n",
    "\n",
    "        print(\"Created table with %d rows\" % len(df))\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def save_result(self):\n",
    "        with open(\"%s/result.json\" % self.result_folder, \"w\") as outfile:\n",
    "            result_json = json.dumps(self.result, indent=4)\n",
    "            outfile.write(result_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment result folder: DATA/x_ai/grok_code_fast_1_full_table_20251005-000106\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 1\n",
      "Fetching data for republican_straw_polls_2012\n",
      "Query:  results of straw polls for the Republican Party presidential primaries, 2012\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'path'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTable # \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m\"\u001b[39m % (i+\u001b[32m1\u001b[39m))\n\u001b[32m      9\u001b[39m     idx = \u001b[33m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m\"\u001b[39m % i\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     table = \u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m====================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m runner.save_result()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mExperimentRunner.fetch_data\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28mself\u001b[39m.result[idx][\u001b[33m'\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m'\u001b[39m] = [response]\n\u001b[32m     53\u001b[39m df = \u001b[38;5;28mself\u001b[39m.table_generator.parse_llm_response(response)          \n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m df_ref = pd.read_csv(\u001b[43mtask\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpath\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m)          \n\u001b[32m     55\u001b[39m df.columns = df_ref.columns\n\u001b[32m     56\u001b[39m df = df.drop_duplicates(subset=task[\u001b[33m'\u001b[39m\u001b[33mkeys\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[31mKeyError\u001b[39m: 'path'"
     ]
    }
   ],
   "source": [
    "tg = TableGenerator_JSON()\n",
    "\n",
    "runner = ExperimentRunner(tg, metadata_path=\"cfg.json\")\n",
    "\n",
    "print(\"\\n====================\\n\")\n",
    "\n",
    "for i in range(100):\n",
    "    print(\"Table # %d\" % (i+1))\n",
    "    idx = \"%d\" % i\n",
    "    table = runner.fetch_data(idx)\n",
    "    print(\"\\n====================\\n\")\n",
    "    \n",
    "runner.save_result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
